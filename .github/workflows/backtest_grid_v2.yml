
name: Backtest-Grid-V2.1
on:
  workflow_dispatch:
    inputs:
      CODE_ZIP:
        description: 'Path or URL to V2 code zip (repo root file name allowed)'
        required: true
        default: strategy_v2_codepack_v2.1.3.zip
      DATA_ZIP:
        description: 'Path or URL to data zip (repo root file name allowed)'
        required: true
        default: ETHUSDT_1min_2020_2025.zip
      CSV_GLOB:
        description: 'CSV glob (e.g. **/*ETHUSDT*1min*2020*2025*.csv)'
        required: false
        default: "**/*ETHUSDT*1min*2020*2025*.csv"
      SL_ATR:
        description: 'exit.sl_atr constant (matrix covers tp_atr only)'
        required: false
        default: "0.5"

jobs:
  grid:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        ofi_thr: [0.15, 0.20, 0.25]
        pthr_tr: [0.60, 0.65]
        tp_atr: [0.70, 0.90]
        r_lo: [0.30, 0.35, 0.40]
        t_hi: [0.60, 0.65, 0.70]
        cooldown: [5, 10]
    steps:
      - name: Install deps (pandas, numpy, pyyaml, numba)
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip || true
          pip install pandas numpy pyyaml numba || true

      - name: Acquire code/data (local / URL / repo raw)
        env:
          CODE_ZIP: "${{ github.event.inputs.CODE_ZIP }}"
          DATA_ZIP: "${{ github.event.inputs.DATA_ZIP }}"
        run: |
          set -euo pipefail
          mkdir -p tmp/trade tmp/data _out_4u/run tools
          # CODE_ZIP
          if [ -f "$CODE_ZIP" ]; then CSRC="$CODE_ZIP";           elif echo "$CODE_ZIP" | grep -qiE '^https?://'; then curl -fL "$CODE_ZIP" -o tmp/trade/code.zip; CSRC="tmp/trade/code.zip";           else RCODE="https://raw.githubusercontent.com/${{ github.repository }}/${{ github.ref_name }}/$CODE_ZIP"; curl -fL "$RCODE" -o tmp/trade/code.zip; CSRC="tmp/trade/code.zip"; fi
          unzip -q "$CSRC" -d tmp/trade
          # DATA_ZIP
          if [ -f "$DATA_ZIP" ]; then DSRC="$DATA_ZIP";           elif echo "$DATA_ZIP" | grep -qiE '^https?://'; then curl -fL "$DATA_ZIP" -o tmp/data/data.zip; DSRC="tmp/data/data.zip";           else RDATA="https://raw.githubusercontent.com/${{ github.repository }}/${{ github.ref_name }}/$DATA_ZIP"; curl -fL "$RDATA" -o tmp/data/data.zip; DSRC="tmp/data/data.zip"; fi
          unzip -q "$DSRC" -d tmp/data
          # guard for namespace packages
          touch tmp/trade/strategy/__init__.py || true
          touch tmp/trade/strategy/v2/__init__.py || true

      - name: Patch params (inline python)
        env:
          OFI_THR: "${{ matrix.ofi_thr }}"
          P_THR_TR: "${{ matrix.pthr_tr }}"
          TP_ATR: "${{ matrix.tp_atr }}"
          SL_ATR: "${{ github.event.inputs.SL_ATR }}"
          R_LO: "${{ matrix.r_lo }}"
          T_HI: "${{ matrix.t_hi }}"
          COOL: "${{ matrix.cooldown }}"
        run: |
          set -euo pipefail
          python - <<'PY'
import os, yaml, json
p='tmp/trade/conf/params.v2.yml'
with open(p,'r') as f: cfg=yaml.safe_load(f)
cfg.setdefault('orderflow',{})['ofi_thr']=float(os.environ['OFI_THR'])
cfg.setdefault('entry',{}).setdefault('p_thr',{})['trend']=float(os.environ['P_THR_TR'])
cfg.setdefault('exit',{})
cfg['exit']['tp_atr']=float(os.environ['TP_ATR']); cfg['exit']['sl_atr']=float(os.environ['SL_ATR'])
cfg.setdefault('regime',{})
cfg['regime']['range_lo_pctile']=float(os.environ['R_LO']); cfg['regime']['trend_hi_pctile']=float(os.environ['T_HI'])
cfg.setdefault('entry',{})['cooldown_bars']=int(float(os.environ['COOL']))
with open(p,'w') as f: yaml.safe_dump(cfg,f,sort_keys=False)
params_out = {'ofi_thr': float(os.environ['OFI_THR']),'ptr': float(os.environ['P_THR_TR']),'tp_atr': float(os.environ['TP_ATR']),'sl_atr': float(os.environ['SL_ATR']),'r_lo': float(os.environ['R_LO']),'t_hi': float(os.environ['T_HI']),'cooldown': int(float(os.environ['COOL']))}
os.makedirs('_out_4u/run', exist_ok=True)
open('_out_4u/run/params.json','w').write(json.dumps(params_out, indent=2))
PY
          echo '---- params.v2.yml ----'; cat tmp/trade/conf/params.v2.yml

      - name: Preflight strict
        env:
          CSV_GLOB: "${{ github.event.inputs.CSV_GLOB }}"
        run: |
          set -euo pipefail
          python tmp/trade/preflight_strict.py --data-root tmp/data --csv-glob "$CSV_GLOB" --outdir _out_4u/run

      - name: Detect entrypoint and run (V2.1)
        env:
          CSV_GLOB: "${{ github.event.inputs.CSV_GLOB }}"
        run: |
          set -euo pipefail
          ENTRY=""
          for c in "tmp/trade/run_4u.py" "tmp/trade/backtest/run_4u.py" "tmp/trade/backtest/runner.py"; do
            if [ -f "$c" ]; then ENTRY="$c"; break; fi
          done
          if [ -z "$ENTRY" ]; then echo "No entrypoint found"; exit 1; fi
          echo "ENTRY=$ENTRY"
          python "$ENTRY" --data-root tmp/data --csv-glob "$CSV_GLOB" --outdir _out_4u/run --params tmp/trade/conf/params.v2.yml

      - name: Grid metrics (write json)
        run: |
          set -euo pipefail
          python - <<'PY'
import json, os
s = json.load(open('_out_4u/run/summary.json')) if os.path.exists('_out_4u/run/summary.json') else {}
keys=['cum_pnl_close_based','avg_gatep','trend_frac','range_frac','entries','exits']
m = {k:s.get(k) for k in keys}
open('_out_4u/run/grid_metrics.json','w').write(json.dumps(m, indent=2))
PY

      - name: Upload tiny metrics artifact (per-matrix)
        uses: actions/upload-artifact@84480863f228bb9747b473957fcc9e309aa96097
        with:
          name: "grid-metrics-ofi=${{ matrix.ofi_thr }}-ptr=${{ matrix.pthr_tr }}-tp=${{ matrix.tp_atr }}-rlo=${{ matrix.r_lo }}-thi=${{ matrix.t_hi }}-cool=${{ matrix.cooldown }}"
          path: |
            _out_4u/run/grid_metrics.json
            _out_4u/run/summary.json
            _out_4u/run/params.json

  collect:
    needs: grid
    runs-on: ubuntu-latest
    steps:
      - name: Download all grid metrics (pinned SHA)
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0
        with:
          pattern: grid-metrics-*
          merge-multiple: false
          path: metrics

      - name: Aggregate & publish Top10
        run: |
          set -euo pipefail
          python - <<'PY'
import os, json, glob, pandas as pd
root = 'metrics'
recs = []
for d in glob.glob(os.path.join(root, '*')):
    gm = os.path.join(d, 'grid_metrics.json')
    pj = os.path.join(d, 'params.json')
    m = json.load(open(gm)) if os.path.exists(gm) else {}
    p = json.load(open(pj)) if os.path.exists(pj) else {}
    r={}; r.update(p); r.update(m); r['artifact']=os.path.basename(d); recs.append(r)
df = pd.DataFrame(recs)
if not df.empty:
    order = ['ofi_thr','ptr','tp_atr','sl_atr','r_lo','t_hi','cooldown','cum_pnl_close_based','avg_gatep','trend_frac','range_frac','entries','exits','artifact']
    cols = [c for c in order if c in df.columns] + [c for c in df.columns if c not in order]
    df = df[cols]
df.to_csv('grid_aggregate.csv', index=False)
top = df.sort_values(['cum_pnl_close_based','avg_gatep'], ascending=[False, False]).head(10)
top.to_csv('grid_top10.csv', index=False)
best = top.head(1).to_dict(orient='records')
json.dump(best, open('best_config.json','w'), indent=2)
# Summary table
def md_table(df):
    if df.empty: return "No results."
    cols=list(df.columns); L=[]
    L.append('|'+'|'.join(cols)+'|'); L.append('|'+'|'.join(['---']*len(cols))+'|')
    for _,row in df.iterrows():
        vals=[str(row.get(c,'')) for c in cols]; L.append('|'+'|'.join(vals)+'|')
    return '\n'.join(L)
open(os.environ.get('GITHUB_STEP_SUMMARY','SUMMARY.md'),'a').write('# Grid Top 10\n\n'+md_table(top))
PY

      - name: Upload consolidated tables
        uses: actions/upload-artifact@84480863f228bb9747b473957fcc9e309aa96097
        with:
          name: "grid-aggregate"
          path: |
            grid_aggregate.csv
            grid_top10.csv
            best_config.json
