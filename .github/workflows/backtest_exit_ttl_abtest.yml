name: Exit/TTL A-B (param v2)

on:
  workflow_dispatch:
    inputs:
      CODE_PACK:
        description: "Root code zip in repo (e.g., trade_v1.1.4.zip)"
        required: true
        default: "trade_v1.1.4.zip"
      DATA_ZIP:
        description: "Optional data zip to unzip into tmp/data (e.g., ETHUSDT_1min_2020_2025.zip)"
        required: false
        default: ""
      DATA_CSV:
        description: "Optional direct CSV path (repo-relative). If empty, CSV_GLOB is used."
        required: false
        default: ""
      CSV_GLOB:
        description: "Fallback glob for CSV search if DATA_CSV is empty."
        required: true
        default: "**/*ETHUSDT*1min*2020*2025*.csv"
      TTL_A:
        description: "TTL for run A"
        required: true
        default: "1"
      TTL_B:
        description: "TTL for run B"
        required: true
        default: "5000"

jobs:
  abtest:
    runs-on: ubuntu-latest
    steps:
      # ---- Pinned actions (replace with your org-approved SHAs if different) ----
      - name: Checkout (pinned SHA)
        uses: actions/checkout@11bd71901bbe5b1630b4b23b5b2ac60a8a6e3f2
      # --------------------------------------------------------------------------

      - name: Prepare workspace
        run: |
          set -Eeuo pipefail
          rm -rf _out_4u tmp || true
          mkdir -p _out_4u tmp/trade tmp/data

      - name: Bring code pack
        run: |
          set -Eeuo pipefail
          test -f "${{ github.event.inputs.CODE_PACK }}"
          unzip -oq "${{ github.event.inputs.CODE_PACK }}" -d tmp/trade
          echo "CODE_SHA256=$(sha256sum '${{ github.event.inputs.CODE_PACK }}' | awk '{print $1}')" >> $GITHUB_ENV

      - name: Bring dataset (zip / file / glob)
        env:
          DATA_ZIP: ${{ github.event.inputs.DATA_ZIP }}
          DATA_CSV: ${{ github.event.inputs.DATA_CSV }}
          CSV_GLOB: ${{ github.event.inputs.CSV_GLOB }}
        run: |
          set -Eeuo pipefail
          shopt -s nullglob globstar
          mkdir -p tmp/data
          if [ -n "${DATA_ZIP}" ] && [ -f "${DATA_ZIP}" ]; then
            unzip -oq "${DATA_ZIP}" -d tmp/data || true
          fi
          if [ -n "${DATA_CSV}" ] && [ -f "${DATA_CSV}" ]; then
            cp -f "${DATA_CSV}" tmp/data/
          fi
          # If still no CSV, try glob across repo
          if ! compgen -G "tmp/data/*.csv" > /dev/null; then
            for p in ${CSV_GLOB}; do
              if [ -f "${p}" ]; then
                cp -f "${p}" tmp/data/
                break
              fi
            done
          fi
          echo "CSV found under tmp/data:"
          ls -al tmp/data || true
          if ! compgen -G "tmp/data/*.csv" > /dev/null; then
            echo "::error title=NoCSV::No CSV found (tried DATA_ZIP, DATA_CSV, CSV_GLOB)."
            exit 1
          fi

      - name: Create run_engine.py (bridge & normalizer)
        run: |
          set -Eeuo pipefail
          cat > run_engine.py << 'PY'
          import os, sys, glob, json, shutil, subprocess, textwrap
          from pathlib import Path

          ROOT = Path.cwd()
          TRADE = ROOT / "tmp" / "trade"
          CONF = TRADE / "conf"
          OUT = ROOT / "_out_4u"
          DATA_DIRS = [ROOT/"tmp/data", ROOT/"data", TRADE/"data"]

          def select_csv()->Path:
            pats = []
            for d in DATA_DIRS:
              if d.exists():
                pats += list(d.glob("**/*.csv"))
            # filter out __MACOSX and dirs
            pats = [p for p in pats if p.is_file() and "__MACOSX" not in str(p)]
            if not pats:
              raise FileNotFoundError("No CSV found under tmp/data or data")
            # choose the first, preferring largest file
            pats.sort(key=lambda p: p.stat().st_size, reverse=True)
            return pats[0]

          def load_cfg()->dict:
            base = CONF/"config.yml"
            if base.exists():
              import yaml
              return yaml.safe_load(base.read_text()) or {}
            return {}

          def overlay_exit(cfg:dict, ttl:int)->Path:
            cfg = {**cfg}
            exit_cfg = cfg.get("exit", {})
            exit_cfg["ttl"] = int(ttl)
            # also mirror as hold_bars if engine expects that
            exit_cfg.setdefault("hold_bars", int(ttl))
            cfg["exit"] = exit_cfg
            CONF.mkdir(parents=True, exist_ok=True)
            eff = CONF/"config.effective.yml"
            try:
              import yaml
              eff.write_text(yaml.safe_dump(cfg, sort_keys=False, allow_unicode=True))
            except Exception:
              # plain JSON as fallback
              eff.write_text(json.dumps(cfg, ensure_ascii=False, indent=2))
            return eff

          def call_engine(data_path:Path, cfg_path:Path, out_dir:Path)->None:
            # prefer run_4u.py, then backtest/engine.py, then backtest/runner.py
            candidates = []
            p1 = TRADE/"run_4u.py"
            p2 = TRADE/"backtest"/"engine.py"
            p3 = TRADE/"backtest"/"runner.py"
            for p in [p1, p2, p3]:
              if p.exists():
                candidates.append(p)
            if not candidates:
              raise FileNotFoundError("No engine entry found (run_4u.py or backtest/engine.py/runner.py)")
            out_dir.mkdir(parents=True, exist_ok=True)
            for entry in candidates:
              cmd = ["python", "-u", str(entry),
                     "--data_path", str(data_path),
                     "--config", str(cfg_path),
                     "--out_dir", str(out_dir)]
              env = os.environ.copy()
              env["PYTHONPATH"] = f"{TRADE}:{TRADE/'backtest'}:{env.get('PYTHONPATH','')}"
              try:
                print(f"[run_engine] RUN -> {entry} args={cmd[4:]}")
                subprocess.run(cmd, check=True, env=env)
                return
              except subprocess.CalledProcessError as e:
                print(f"[run_engine] WARN: {entry} failed: {e} â€” trying next candidate")
                continue
            raise RuntimeError("All engine entry candidates failed.")

          def ensure_trades(out_dir:Path)->Path:
            # normalize possible locations/names into _out_4u/trades.csv
            candidates = []
            for pat in [
              out_dir/"trades.csv",
              out_dir/"trades_A.csv",
              out_dir/"trades_B.csv",
              TRADE/"_out_4u"/"trades.csv",
              ROOT/"trades.csv",
            ]:
              if pat.exists():
                candidates.append(pat)
            if not candidates:
              # best-effort scan
              for p in (ROOT, TRADE):
                for f in p.rglob("trades*.csv"):
                  candidates.append(f)
            if not candidates:
              raise FileNotFoundError("trades.csv not produced by engine")
            # choose latest modified
            candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)
            dst = ROOT/"_out_4u"/"trades.csv"
            dst.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(candidates[0], dst)
            return dst

          def main(ttl:int):
            data = select_csv()
            cfg = load_cfg()
            eff = overlay_exit(cfg, ttl)
            call_engine(data, eff, OUT)
            return ensure_trades(OUT)

          if __name__ == "__main__":
            ttl = int(os.environ.get("TTL", "0"))
            p = main(ttl)
            print(f"TRADES -> {p} ({p.stat().st_size} bytes)")
          PY

      - name: Run A (TTL=1)
        env:
          TTL: ${{ github.event.inputs.TTL_A }}
        run: |
          set -Eeuo pipefail
          python -u run_engine.py
          mv -f _out_4u/trades.csv _out_4u/trades_A.csv

      - name: Clean BETWEEN runs
        run: |
          set -Eeuo pipefail
          rm -f _out_4u/trades.csv || true

      - name: Run B (TTL=5000)
        env:
          TTL: ${{ github.event.inputs.TTL_B }}
        run: |
          set -Eeuo pipefail
          python -u run_engine.py
          mv -f _out_4u/trades.csv _out_4u/trades_B.csv

      - name: Assert A != B (TTL effect)
        run: |
          set -Eeuo pipefail
          shaA=$(sha256sum _out_4u/trades_A.csv | awk '{print $1}')
          shaB=$(sha256sum _out_4u/trades_B.csv | awk '{print $1}')
          echo "SHA_A ${shaA}"
          echo "SHA_B ${shaB}"
          if [ "${shaA}" = "${shaB}" ]; then
            echo "::error title=Exit/TTL not applied::A==B"
            exit 3
          fi

      - name: Upload artifacts (pinned SHA)
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: exit_ttl_abtest_outputs
          path: |
            _out_4u/trades_A.csv
            _out_4u/trades_B.csv
            tmp/trade/conf/config.effective.yml
          if-no-files-found: error
