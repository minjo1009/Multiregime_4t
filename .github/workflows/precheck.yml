name: Precheck CSV (strict)

on:
  workflow_dispatch:
    inputs:
      DATA_ZIP:
        description: Data zip at repo root
        required: true
        default: ETHUSDT_1min_2020_2025.zip
      CSV_GLOB:
        description: CSV glob inside data zip
        required: true
        default: "*ETHUSDT*1min*2020*2025*.csv"

permissions:
  contents: read

env:
  PY: "3.11"
  DATA_DIR: tmp/data
  OUT_DIR: _out_4u/run
  # --- pinned SHAs (strict: no tag fallback) ---
  CHECKOUT_SHA: "11bd71901b2cbc3cb3cbbf5b1b973078d1b96b7a"
  SETUP_PYTHON_SHA: "a26af69be951a213d495a4c3e4e4022e16d87065"
  UPLOAD_ARTIFACT_SHA: "ea165f8d65b6e0b1f71c5e3cd2a1f1e166d0ad2d"

jobs:
  preflight:
    runs-on: ubuntu-latest
    steps:
      - name: Validate pinned SHAs (ASCII/exists; strict, no fallback)
        shell: bash
        run: |
          set -euo pipefail
          hex40='^[0-9a-f]{40}$'
          check(){ n="$1"; s="$2"; u="https://api.github.com/repos/actions/${n}/tarball/${s}"; curl -fsIL "$u" >/dev/null; }
          die(){ echo "❌ PinnedSHA: $1" >&2; exit 86; }
          for kv in "checkout:${CHECKOUT_SHA}" "setup-python:${SETUP_PYTHON_SHA}" "upload-artifact:${UPLOAD_ARTIFACT_SHA}"; do
            name="${kv%%:*}"; sha="${kv##*:}"
            [[ "$sha" =~ $hex40 ]] || die "$name not 40-hex"
            check "$name" "$sha" || die "$name $sha not found (org requires pinned SHAs)"
          done
          echo "✅ pinned SHAs ok"

      - name: Checkout (pinned)
        uses: actions/checkout@11bd71901b2cbc3cb3cbbf5b1b973078d1b96b7a

      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ env.PY }}

      - name: Install deps (pandas/numpy/pyyaml; quiet)
        shell: bash
        run: |
          set -euo pipefail
          python3 -m pip -q install -U pip
          python3 -m pip -q install pandas numpy pyyaml

      - name: Prepare dirs & unzip data
        shell: bash
        run: |
          set -euo pipefail
          rm -rf "${DATA_DIR}" "${OUT_DIR}"
          mkdir -p "${DATA_DIR}" "${OUT_DIR}"
          unzip -oq "${{ github.event.inputs.DATA_ZIP }}" -d "${DATA_DIR}"
          echo "{}" > "${OUT_DIR}/gating_debug.json"

      - name: Detect CSV & export CSV_PATH
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p .ci
          cat > .ci/detect_csv.py <<'PY'
          import sys, os, glob
          base = os.environ["DATA_DIR"]
          pat  = os.environ.get("CSV_GLOB","").strip() or "*.csv"
          cand = glob.glob(os.path.join(base, pat), recursive=True)
          if not cand: cand = glob.glob(os.path.join(base, "**", "*.csv"), recursive=True)
          if not cand:
              print(f"ERROR: No CSV found under {base}", file=sys.stderr)
              sys.exit(2)
          print(os.path.abspath(cand[0]))
          PY
          CSV_PATH="$(python3 .ci/detect_csv.py)"
          echo "CSV_PATH=${CSV_PATH}" >> "$GITHUB_ENV"
          echo "Using CSV_PATH=${CSV_PATH}"

      - name: Preflight columns
        shell: bash
        run: |
          set -euo pipefail
          cat > .ci/preflight_cols.py <<'PY'
          import sys, os, pandas as pd
          p = os.environ.get("CSV_PATH") or (len(sys.argv)>1 and sys.argv[1])
          if not p or not os.path.exists(p):
              print("ERROR: CSV_PATH missing or not exists:", p); sys.exit(3)
          df = pd.read_csv(p, nrows=2)
          need = {'open_time','open','high','low','close','volume'}
          cols = {str(c).lower() for c in df.columns}
          miss = need - cols
          if miss:
              print("ERROR: Missing base columns:", sorted(miss)); sys.exit(4)
          print("OK: Columns present:", sorted(cols))
          PY
          python3 .ci/preflight_cols.py "$CSV_PATH"