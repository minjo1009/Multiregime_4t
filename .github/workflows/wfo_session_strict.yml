name: WFO_Session_Strict

on:
  workflow_dispatch:
    inputs:
      CODE_ZIP_URL:
        description: "URL to code zip"
        required: true
        type: string
      DATA_ZIP_URL:
        description: "URL to data zip"
        required: true
        type: string
      CSV_GLOB:
        description: "CSV glob pattern inside data zip"
        required: false
        default: "**/*ETHUSDT*1min*2020*2025*.csv"
        type: string
      FEES_BPS:
        description: "Trading fee in bps (e.g., 7.5)"
        required: false
        default: "7.5"
        type: string
      CHAMPION_CONFIG:
        description: "Champion config string"
        required: false
        default: "grid_p0.83_tp2.2_sl0.45_cd34_mh12_ofi0.42_thi0.74"
        type: string
      SPLITS:
        description: "Number of WFO splits"
        required: false
        default: "4"
        type: string
      TZ:
        description: "IANA timezone for session split"
        required: false
        default: "Asia/Seoul"
        type: string

jobs:
  validate_shas:
    runs-on: ubuntu-latest
    env:
      SETUP_PYTHON_SHA: "a26af69be951a213d495a4c3e4e4022e16d87065"
      UPLOAD_ARTIFACT_SHA: "ea165f8d65b6e0b1f71c5e3cd2a1f1e166d0ad2d"
    steps:
      - name: Validate pinned SHAs exist
        run: |
          set -euo pipefail
          echo "[PIN] validating SHAs..."
          git ls-remote https://github.com/actions/setup-python | grep -E "^${SETUP_PYTHON_SHA}" >/dev/null || { echo "::error::setup-python SHA not found"; exit 2; }
          git ls-remote https://github.com/actions/upload-artifact | grep -E "^${UPLOAD_ARTIFACT_SHA}" >/dev/null || { echo "::error::upload-artifact SHA not found"; exit 2; }
          echo "[PIN] ok"

  single_run:
    needs: validate_shas
    runs-on: ubuntu-latest
    env:
      SETUP_PYTHON_SHA: "a26af69be951a213d495a4c3e4e4022e16d87065"
      UPLOAD_ARTIFACT_SHA: "ea165f8d65b6e0b1f71c5e3cd2a1f1e166d0ad2d"
    steps:
      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: "3.11"
      - name: Install base deps
        run: |
          set -euo pipefail
          python -V
          pip install --upgrade pip
          pip install pandas numpy scikit-learn pyyaml
      - name: Prepare workspace and fetch zips
        run: |
          set -euo pipefail
          mkdir -p work/code work/data work/out/single _out_4u/run
          cd work
          echo "[DL] code zip"
          curl -fsSL "${{ inputs.CODE_ZIP_URL }}" -o code.zip
          echo "[DL] data zip"
          curl -fsSL "${{ inputs.DATA_ZIP_URL }}" -o data.zip
          unzip -q code.zip -d code
          unzip -q data.zip -d data
          cd ..
      - name: Write preflight_strict.py (safe echo)
        run: |
          set -euo pipefail
          mkdir -p scripts
          {
            echo 'import os,sys,glob,json'
            echo 'import pandas as pd'
            echo 'def find_csv(root,patt):'
            echo '  g=glob.glob(os.path.join(root,patt),recursive=True)'
            echo '  if not g: raise SystemExit("CSVDetect: no csv")'
            echo '  return g[0]'
            echo 'def read_df(path):'
            echo '  df=pd.read_csv(path)'
            echo '  cols={"open_time","open","high","low","close","volume"}'
            echo '  if not cols.issubset(df.columns):'
            echo '    raise SystemExit("Preflight: missing columns")'
            echo '  ot=df["open_time"]'
            echo '  try:'
            echo '    if pd.api.types.is_numeric_dtype(ot):'
            echo '      dt=pd.to_datetime(ot,unit="ms",utc=True)'
            echo '    else:'
            echo '      dt=pd.to_datetime(ot,utc=True)'
            echo '  except Exception:'
            echo '    dt=pd.to_datetime(ot,utc=True,errors="coerce")'
            echo '  df["dt_utc"]=dt'
            echo '  return df'
            echo 'def write_cfg(path,data_path,fee_bps,champion):'
            echo '  os.makedirs(os.path.dirname(path),exist_ok=True)'
            echo '  with open(path,"w") as f:'
            echo '    f.write("data_path: \"" + data_path + "\"\n")'
            echo '    f.write("fee_bps: " + str(fee_bps) + "\n")'
            echo '    f.write("champion_config: \"" + champion + "\"\n")'
            echo 'if __name__=="__main__":'
            echo '  mode=os.environ.get("MODE","single")'
            echo '  root_csv="work/data"'
            echo '  patt=os.environ.get("CSV_GLOB","**/*.csv")'
            echo '  fee=os.environ.get("FEES_BPS","7.5")'
            echo '  tz=os.environ.get("TZ","Asia/Seoul")'
            echo '  champion=os.environ.get("CHAMPION_CONFIG","")'
            echo '  out_csv="work/input.csv"'
            echo '  p=find_csv(root_csv,patt)'
            echo '  df=read_df(p)'
            echo '  if mode=="single":'
            echo '    df.to_csv(out_csv,index=False)'
            echo '  elif mode=="wfo":'
            echo '    k=int(os.environ.get("K","4"))'
            echo '    i=int(os.environ.get("I","0"))'
            echo '    dt=df["dt_utc"]'
            echo '    t0=dt.min(); t1=dt.max()'
            echo '    edges=pd.date_range(t0,t1,periods=k+1)'
            echo '    s=edges[i]; e=edges[i+1]'
            echo '    m=(dt>=s)&(dt<e)'
            echo '    df[m].to_csv(out_csv,index=False)'
            echo '  elif mode=="session":'
            echo '    sname=os.environ.get("SESSION","ASIA")'
            echo '    dfl=df.copy()'
            echo '    dfl["dt_loc"]=dfl["dt_utc"].dt.tz_convert(tz)'
            echo '    hr=dfl["dt_loc"].dt.hour'
            echo '    if sname=="ASIA":'
            echo '      m=(hr>=9)&(hr<17)'
            echo '    elif sname=="EU":'
            echo '      m=(hr>=17)|(hr<1)'
            echo '    else:'
            echo '      m=(hr>=1)&(hr<9)'
            echo '    dfl[m].drop(columns=["dt_loc"]).to_csv(out_csv,index=False)'
            echo '  else:'
            echo '    raise SystemExit("Runtime: unknown MODE")'
            echo '  write_cfg("conf/config.effective.yml",out_csv,fee,champion)'
          } > scripts/preflight_strict.py
      - name: Single run
        run: |
          set -euo pipefail
          export MODE=single
          export CSV_GLOB="${{ inputs.CSV_GLOB }}"
          export FEES_BPS="${{ inputs.FEES_BPS }}"
          export TZ="${{ inputs.TZ }}"
          export CHAMPION_CONFIG="${{ inputs.CHAMPION_CONFIG }}"
          python scripts/preflight_strict.py || { echo "::error::Preflight failed"; exit 3; }
          EP=""
          [ -f work/code/run_4u.py ] && EP="work/code/run_4u.py"
          [ -z "$EP" ] && [ -f work/code/backtest/run_4u.py ] && EP="work/code/backtest/run_4u.py"
          [ -z "$EP" ] && [ -f work/code/run.py ] && EP="work/code/run.py"
          [ -z "$EP" ] && [ -f work/code/backtest/runner.py ] && EP="work/code/backtest/runner.py"
          echo "[RUN] entrypoint=$EP"
          if [ -n "$EP" ]; then
            PYTHONPATH=work/code:work/code/src:work/code/src/trend4u python "$EP" || true
          else
            echo "::warning::No entrypoint found; skipping run"
          fi
          mkdir -p _out_4u/run work/out/single
          [ -f summary.json ] && cp summary.json work/out/single/ || echo "{}" > work/out/single/summary.json
          [ -f gating_debug.json ] && cp gating_debug.json work/out/single/ || echo "{}" > work/out/single/gating_debug.json
          [ -f preds_test.csv ] && cp preds_test.csv work/out/single/ || printf "" > work/out/single/preds_test.csv
          [ -f trades.csv ] && cp trades.csv work/out/single/ || printf "" > work/out/single/trades.csv
          [ -f summary_cost.json ] && cp summary_cost.json work/out/single/ || true
      - name: Zip single
        run: |
          set -euo pipefail
          cd work/out
          zip -qr ../single_results.zip single
      - name: Upload artifact (pinned)
        uses: actions/upload-artifact@ea165f8d65b6e0b1f71c5e3cd2a1f1e166d0ad2d
        with:
          name: single_results
          path: work/single_results.zip
          if-no-files-found: warn

  wfo:
    needs: validate_shas
    runs-on: ubuntu-latest
    env:
      SETUP_PYTHON_SHA: "a26af69be951a213d495a4c3e4e4022e16d87065"
      UPLOAD_ARTIFACT_SHA: "ea165f8d65b6e0b1f71c5e3cd2a1f1e166d0ad2d"
    steps:
      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: "3.11"
      - name: Install deps and unzip
        run: |
          set -euo pipefail
          pip install --upgrade pip
          pip install pandas numpy scikit-learn pyyaml
          mkdir -p work/code work/data work/out/wfo
          curl -fsSL "${{ inputs.CODE_ZIP_URL }}" -o work/code.zip
          curl -fsSL "${{ inputs.DATA_ZIP_URL }}" -o work/data.zip
          unzip -q work/code.zip -d work/code
          unzip -q work/data.zip -d work/data
      - name: Write preflight_strict.py (safe echo)
        run: |
          set -euo pipefail
          mkdir -p scripts
          {
            echo 'import os,sys,glob,json'
            echo 'import pandas as pd'
            echo 'def find_csv(root,patt):'
            echo '  g=glob.glob(os.path.join(root,patt),recursive=True)'
            echo '  if not g: raise SystemExit("CSVDetect: no csv")'
            echo '  return g[0]'
            echo 'def read_df(path):'
            echo '  df=pd.read_csv(path)'
            echo '  cols={"open_time","open","high","low","close","volume"}'
            echo '  if not cols.issubset(df.columns):'
            echo '    raise SystemExit("Preflight: missing columns")'
            echo '  ot=df["open_time"]'
            echo '  try:'
            echo '    if pd.api.types.is_numeric_dtype(ot):'
            echo '      dt=pd.to_datetime(ot,unit="ms",utc=True)'
            echo '    else:'
            echo '      dt=pd.to_datetime(ot,utc=True)'
            echo '  except Exception:'
            echo '    dt=pd.to_datetime(ot,utc=True,errors="coerce")'
            echo '  df["dt_utc"]=dt'
            echo '  return df'
            echo 'def write_cfg(path,data_path,fee_bps,champion):'
            echo '  os.makedirs(os.path.dirname(path),exist_ok=True)'
            echo '  with open(path,"w") as f:'
            echo '    f.write("data_path: \"" + data_path + "\"\n")'
            echo '    f.write("fee_bps: " + str(fee_bps) + "\n")'
            echo '    f.write("champion_config: \"" + champion + "\"\n")'
            echo 'if __name__=="__main__":'
            echo '  mode=os.environ.get("MODE","single")'
            echo '  root_csv="work/data"'
            echo '  patt=os.environ.get("CSV_GLOB","**/*.csv")'
            echo '  fee=os.environ.get("FEES_BPS","7.5")'
            echo '  tz=os.environ.get("TZ","Asia/Seoul")'
            echo '  champion=os.environ.get("CHAMPION_CONFIG","")'
            echo '  out_csv="work/input.csv"'
            echo '  p=find_csv(root_csv,patt)'
            echo '  df=read_df(p)'
            echo '  if mode=="single":'
            echo '    df.to_csv(out_csv,index=False)'
            echo '  elif mode=="wfo":'
            echo '    k=int(os.environ.get("K","4"))'
            echo '    i=int(os.environ.get("I","0"))'
            echo '    dt=df["dt_utc"]'
            echo '    t0=dt.min(); t1=dt.max()'
            echo '    edges=pd.date_range(t0,t1,periods=k+1)'
            echo '    s=edges[i]; e=edges[i+1]'
            echo '    m=(dt>=s)&(dt<e)'
            echo '    df[m].to_csv(out_csv,index=False)'
            echo '  elif mode=="session":'
            echo '    sname=os.environ.get("SESSION","ASIA")'
            echo '    dfl=df.copy()'
            echo '    dfl["dt_loc"]=dfl["dt_utc"].dt.tz_convert(tz)'
            echo '    hr=dfl["dt_loc"].dt.hour'
            echo '    if sname=="ASIA":'
            echo '      m=(hr>=9)&(hr<17)'
            echo '    elif sname=="EU":'
            echo '      m=(hr>=17)|(hr<1)'
            echo '    else:'
            echo '      m=(hr>=1)&(hr<9)'
            echo '    dfl[m].drop(columns=["dt_loc"]).to_csv(out_csv,index=False)'
            echo '  else:'
            echo '    raise SystemExit("Runtime: unknown MODE")'
            echo '  write_cfg("conf/config.effective.yml",out_csv,fee,champion)'
          } > scripts/preflight_strict.py
      - name: Run WFO splits
        run: |
          set -euo pipefail
          export CSV_GLOB="${{ inputs.CSV_GLOB }}"
          export FEES_BPS="${{ inputs.FEES_BPS }}"
          export TZ="${{ inputs.TZ }}"
          export CHAMPION_CONFIG="${{ inputs.CHAMPION_CONFIG }}"
          K="${{ inputs.SPLITS }}"
          EP=""
          [ -f work/code/run_4u.py ] && EP="work/code/run_4u.py"
          [ -z "$EP" ] && [ -f work/code/backtest/run_4u.py ] && EP="work/code/backtest/run_4u.py"
          [ -z "$EP" ] && [ -f work/code/run.py ] && EP="work/code/run.py"
          [ -z "$EP" ] && [ -f work/code/backtest/runner.py ] && EP="work/code/backtest/runner.py"
          echo "[RUN] entrypoint=$EP"
          for i in $(seq 0 $((K-1))); do
            echo "[WFO] split $i/$((K-1))"
            export MODE=wfo
            export K="$K"
            export I="$i"
            python scripts/preflight_strict.py || { echo "::error::Preflight failed"; exit 3; }
            if [ -n "$EP" ]; then
              PYTHONPATH=work/code:work/code/src:work/code/src/trend4u python "$EP" || true
            fi
            outdir="work/out/wfo/split_${i}"
            mkdir -p "$outdir"
            [ -f summary.json ] && mv -f summary.json "$outdir/" || echo "{}" > "$outdir/summary.json"
            [ -f gating_debug.json ] && mv -f gating_debug.json "$outdir/" || echo "{}" > "$outdir/gating_debug.json"
            [ -f preds_test.csv ] && mv -f preds_test.csv "$outdir/" || printf "" > "$outdir/preds_test.csv"
            [ -f trades.csv ] && mv -f trades.csv "$outdir/" || printf "" > "$outdir/trades.csv"
            [ -f summary_cost.json ] && mv -f summary_cost.json "$outdir/" || true
          done
      - name: Zip WFO
        run: |
          set -euo pipefail
          cd work/out
          zip -qr ../wfo_results.zip wfo
      - name: Upload artifact
        uses: actions/upload-artifact@ea165f8d65b6e0b1f71c5e3cd2a1f1e166d0ad2d
        with:
          name: wfo_results
          path: work/wfo_results.zip
          if-no-files-found: warn

  sessions:
    needs: validate_shas
    runs-on: ubuntu-latest
    env:
      SETUP_PYTHON_SHA: "a26af69be951a213d495a4c3e4e4022e16d87065"
      UPLOAD_ARTIFACT_SHA: "ea165f8d65b6e0b1f71c5e3cd2a1f1e166d0ad2d"
    steps:
      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: "3.11"
      - name: Install deps and unzip
        run: |
          set -euo pipefail
          pip install --upgrade pip
          pip install pandas numpy scikit-learn pyyaml pytz
          mkdir -p work/code work/data work/out/sessions
          curl -fsSL "${{ inputs.CODE_ZIP_URL }}" -o work/code.zip
          curl -fsSL "${{ inputs.DATA_ZIP_URL }}" -o work/data.zip
          unzip -q work/code.zip -d work/code
          unzip -q work/data.zip -d work/data
      - name: Write preflight_strict.py (safe echo)
        run: |
          set -euo pipefail
          mkdir -p scripts
          {
            echo 'import os,sys,glob,json'
            echo 'import pandas as pd'
            echo 'def find_csv(root,patt):'
            echo '  g=glob.glob(os.path.join(root,patt),recursive=True)'
            echo '  if not g: raise SystemExit("CSVDetect: no csv")'
            echo '  return g[0]'
            echo 'def read_df(path):'
            echo '  df=pd.read_csv(path)'
            echo '  cols={"open_time","open","high","low","close","volume"}'
            echo '  if not cols.issubset(df.columns):'
            echo '    raise SystemExit("Preflight: missing columns")'
            echo '  ot=df["open_time"]'
            echo '  try:'
            echo '    if pd.api.types.is_numeric_dtype(ot):'
            echo '      dt=pd.to_datetime(ot,unit="ms",utc=True)'
            echo '    else:'
            echo '      dt=pd.to_datetime(ot,utc=True)'
            echo '  except Exception:'
            echo '    dt=pd.to_datetime(ot,utc=True,errors="coerce")'
            echo '  df["dt_utc"]=dt'
            echo '  return df'
            echo 'def write_cfg(path,data_path,fee_bps,champion):'
            echo '  os.makedirs(os.path.dirname(path),exist_ok=True)'
            echo '  with open(path,"w") as f:'
            echo '    f.write("data_path: \"" + data_path + "\"\n")'
            echo '    f.write("fee_bps: " + str(fee_bps) + "\n")'
            echo '    f.write("champion_config: \"" + champion + "\"\n")'
            echo 'if __name__=="__main__":'
            echo '  mode=os.environ.get("MODE","single")'
            echo '  root_csv="work/data"'
            echo '  patt=os.environ.get("CSV_GLOB","**/*.csv")'
            echo '  fee=os.environ.get("FEES_BPS","7.5")'
            echo '  tz=os.environ.get("TZ","Asia/Seoul")'
            echo '  champion=os.environ.get("CHAMPION_CONFIG","")'
            echo '  out_csv="work/input.csv"'
            echo '  p=find_csv(root_csv,patt)'
            echo '  df=read_df(p)'
            echo '  if mode=="single":'
            echo '    df.to_csv(out_csv,index=False)'
            echo '  elif mode=="wfo":'
            echo '    k=int(os.environ.get("K","4"))'
            echo '    i=int(os.environ.get("I","0"))'
            echo '    dt=df["dt_utc"]'
            echo '    t0=dt.min(); t1=dt.max()'
            echo '    edges=pd.date_range(t0,t1,periods=k+1)'
            echo '    s=edges[i]; e=edges[i+1]'
            echo '    m=(dt>=s)&(dt<e)'
            echo '    df[m].to_csv(out_csv,index=False)'
            echo '  elif mode=="session":'
            echo '    sname=os.environ.get("SESSION","ASIA")'
            echo '    dfl=df.copy()'
            echo '    dfl["dt_loc"]=dfl["dt_utc"].dt.tz_convert(tz)'
            echo '    hr=dfl["dt_loc"].dt.hour'
            echo '    if sname=="ASIA":'
            echo '      m=(hr>=9)&(hr<17)'
            echo '    elif sname=="EU":'
            echo '      m=(hr>=17)|(hr<1)'
            echo '    else:'
            echo '      m=(hr>=1)&(hr<9)'
            echo '    dfl[m].drop(columns=["dt_loc"]).to_csv(out_csv,index=False)'
            echo '  else:'
            echo '    raise SystemExit("Runtime: unknown MODE")'
            echo '  write_cfg("conf/config.effective.yml",out_csv,fee,champion)'
          } > scripts/preflight_strict.py
      - name: Run sessions
        run: |
          set -euo pipefail
          export CSV_GLOB="${{ inputs.CSV_GLOB }}"
          export FEES_BPS="${{ inputs.FEES_BPS }}"
          export TZ="${{ inputs.TZ }}"
          export CHAMPION_CONFIG="${{ inputs.CHAMPION_CONFIG }}"
          EP=""
          [ -f work/code/run_4u.py ] && EP="work/code/run_4u.py"
          [ -z "$EP" ] && [ -f work/code/backtest/run_4u.py ] && EP="work/code/backtest/run_4u.py"
          [ -z "$EP" ] && [ -f work/code/run.py ] && EP="work/code/run.py"
          [ -z "$EP" ] && [ -f work/code/backtest/runner.py ] && EP="work/code/backtest/runner.py"
          for S in ASIA EU US; do
            echo "[SESSION] $S"
            export MODE=session
            export SESSION="$S"
            python scripts/preflight_strict.py || { echo "::error::Preflight failed"; exit 3; }
            if [ -n "$EP" ]; then
              PYTHONPATH=work/code:work/code/src:work/code/src/trend4u python "$EP" || true
            fi
            outdir="work/out/sessions/${S}"
            mkdir -p "$outdir"
            [ -f summary.json ] && mv -f summary.json "$outdir/" || echo "{}" > "$outdir/summary.json"
            [ -f gating_debug.json ] && mv -f gating_debug.json "$outdir/" || echo "{}" > "$outdir/gating_debug.json"
            [ -f preds_test.csv ] && mv -f preds_test.csv "$outdir/" || printf "" > "$outdir/preds_test.csv"
            [ -f trades.csv ] && mv -f trades.csv "$outdir/" || printf "" > "$outdir/trades.csv"
            [ -f summary_cost.json ] && mv -f summary_cost.json "$outdir/" || true
          done
      - name: Bundle all and upload
        run: |
          set -euo pipefail
          cd work
          zip -qr bundle_results.zip out
      - name: Upload artifact
        uses: actions/upload-artifact@ea165f8d65b6e0b1f71c5e3cd2a1f1e166d0ad2d
        with:
          name: bundle_results
          path: work/bundle_results.zip
          if-no-files-found: warn
