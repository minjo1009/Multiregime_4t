name: Backtest

on:
  workflow_dispatch:
    inputs:
      trade_zip:
        description: trade code zip (at repo root)
        required: true
        default: trade_v1.0.6_override.zip
      data_zip:
        description: market data zip (at repo root)
        required: true
        default: ETHUSDT_1min_2020_2025.zip
      csv_glob:
        description: CSV filename glob inside data zip
        required: true
        default: "*ETHUSDT*1min*2020*2025*.csv"
      out_dir:
        description: output directory
        required: true
        default: _out_4u/run
      python_version:
        description: Python version
        required: true
        default: "3.11"
      fail_on_fingerprint:
        description: fail if fingerprint missing (true/false)
        required: true
        default: "false"
  push:
    paths:
      - ".github/workflows/backtest.yml"

jobs:
  run-backtest:
    if: ${{ github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest

    env:
      RUN_DIR: tmp/trade
      DATA_DIR: tmp/data
      TRADE_ZIP: ${{ github.event.inputs.trade_zip }}
      DATA_ZIP:  ${{ github.event.inputs.data_zip }}
      CSV_GLOB:  ${{ github.event.inputs.csv_glob }}
      OUT_DIR:   ${{ github.event.inputs.out_dir }}
      PYVER:     ${{ github.event.inputs.python_version }}
      FAIL_FP:   ${{ github.event.inputs.fail_on_fingerprint }}

    steps:
      - name: Checkout (pinned)
        uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332  # v4.1.7

      - name: Prepare workspace & unzip
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${RUN_DIR}" "${DATA_DIR}" "${OUT_DIR}"
          test -f "${TRADE_ZIP}" || { echo "❌ missing ${TRADE_ZIP}"; exit 1; }
          test -f "${DATA_ZIP}"  || { echo "❌ missing ${DATA_ZIP}"; exit 1; }
          unzip -q "${TRADE_ZIP}" -d "${RUN_DIR}"
          unzip -q "${DATA_ZIP}"  -d "${DATA_DIR}"
          echo "== data sample =="; find "${DATA_DIR}" -type f -name "*.csv" | head -n 8 || true

      - name: Detect CSV (robust)
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob globstar
          FIRST=$(find "${DATA_DIR}" -type f -iname "${CSV_GLOB}" -print -quit || true)
          if [ -z "${FIRST:-}" ]; then
            FIRST=$(find "${DATA_DIR}" -type f -iname "*.csv" -print -quit || true)
          fi
          if [ -z "${FIRST:-}" ]; then
            echo "❌ No CSV found in ${DATA_DIR} (glob=${CSV_GLOB})"; exit 1
          fi
          CSV_PATH=$(readlink -f "$FIRST" || echo "$FIRST")
          echo "CSV_PATH=${CSV_PATH}" >> $GITHUB_ENV
          echo "Using CSV: ${CSV_PATH}"
          ls -al "$(dirname "$CSV_PATH")" || true

      - name: Setup Python (pinned; cache to tmp/trade)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065  # v5.6.0
        with:
          python-version: ${{ env.PYVER }}
          cache: pip
          cache-dependency-path: |
            ${{ env.RUN_DIR }}/requirements.txt
            ${{ env.RUN_DIR }}/pyproject.toml

      - name: Install requirements (+PyYAML)
        shell: bash
        working-directory: ${{ env.RUN_DIR }}
        run: |
          set -euo pipefail
          python -V
          python -m pip install -U pip
          if [ -f requirements.txt ]; then
            python -m pip install -r requirements.txt
          else
            python -m pip install numpy pandas scikit-learn scipy matplotlib
          fi
          # engine.py uses `import yaml`
          python -c "import yaml" 2>/dev/null || python -m pip install pyyaml

      # np.를 쓰는 파일에 import numpy as np 주입 (전역 가드)
      - name: Guard numpy import (auto-inject if missing)
        shell: bash
        working-directory: ${{ env.RUN_DIR }}
        run: |
          set -euo pipefail
          mapfile -t FILES < <(grep -RIl --include="*.py" "np\." . || true)
          for f in "${FILES[@]}"; do
            grep -qE '(^|\s)import\s+numpy\s+as\s+np' "$f" || sed -i '1i import numpy as np' "$f"
          done

      # calibration.predict() 함수 안에도 import numpy as np 삽입
      - name: Patch calibration np import (function-level)
        shell: bash
        working-directory: ${{ env.RUN_DIR }}
        run: |
          set -euo pipefail
          F="trend4p/calibration.py"
          if [ -f "$F" ]; then
            grep -qE '(^|\s)import\s+numpy\s+as\s+np' "$F" || sed -i '1i import numpy as np' "$F"
            sed -i '/^[[:space:]]*def[[:space:]]\+predict[[:space:]]*(/a\        import numpy as np' "$F" || true
            echo "[patched] $F"
          else
            echo "WARN: $F not found (skip)"
          fi

      - name: Fingerprint check (warn-only)
        shell: bash
        working-directory: ${{ env.RUN_DIR }}
        run: |
          set -euo pipefail
          F="backtest/runner.py"
          miss=0
          grep -q "Coverage-aligned gating" "$F" || { echo "WARN: missing Coverage-aligned gating"; miss=$((miss+1)); }
          grep -q "S1 probability floor cutoff" "$F" || { echo "WARN: missing S1 probability floor cutoff"; miss=$((miss+1)); }
          if [ "$FAIL_FP" = "true" ] && [ $miss -gt 0 ]; then
            echo "fingerprint mismatch & fail_on_fingerprint=true"; exit 1
          fi
          echo "fingerprint warnings: $miss"

      - name: Sanity check CSV path (2nd pass)
        shell: bash
        run: |
          set -euo pipefail
          if [ ! -f "${CSV_PATH}" ]; then
            echo "⚠️ CSV_PATH missing → re-detecting..."
            shopt -s nullglob globstar
            NEW=$(find "${DATA_DIR}" -type f -iname "${CSV_GLOB}" -print -quit || true)
            [ -n "${NEW:-}" ] || NEW=$(find "${DATA_DIR}" -type f -iname "*.csv" -print -quit || true)
            [ -n "${NEW:-}" ] || { echo "❌ CSV not found after re-detect"; exit 1; }
            CSV_PATH=$(readlink -f "$NEW" || echo "$NEW")
            echo "CSV_PATH=${CSV_PATH}" >> $GITHUB_ENV
            echo "Re-detected CSV: ${CSV_PATH}"
          fi
          echo "Final CSV_PATH=${CSV_PATH}"

            # ✅ OF shift 브로드캐스팅 핫픽스: of_shift를 (N,) 시계열로 강제 (줄 전체 치환)
      - name: Patch engine OF shift (timewise mean)
        shell: bash
        working-directory: ${{ env.RUN_DIR }}
        run: |
          set -euo pipefail
          F="backtest/engine.py"
          [ -f "$F" ] || { echo "❌ not found: $F"; exit 1; }

          # 1) compute_of_shift(df)가 없으면 삽입 (idempotent)
          grep -q "def compute_of_shift(df):" "$F" || awk '
            {print $0}
            END{
              print ""
              print "def compute_of_shift(df):"
              print "    import numpy as np, pandas as pd"
              print "    def z(a):"
              print "        a=np.asarray(a,dtype=float)"
              print "        m=np.nanmedian(a); sd=np.nanstd(a)"
              print "        sd = 1e-12 if (sd==0 or not np.isfinite(sd)) else sd"
              print "        return (a-m)/sd"
              print "    v=z(df.get(\"VPIN\", 0)).ravel()"
              print "    a=z(df.get(\"ATS\", 0)).ravel()"
              print "    l=z(df.get(\"lambda_kyle\", 0)).ravel()"
              print "    zstack=np.vstack([v,a,l])      # (3, N)"
              print "    s=np.nanmean(zstack, axis=0)   # ✅ (N,), time-wise mean"
              print "    return pd.Series(s, index=df.index).fillna(0.0)"
            }' "$F" > "$F.tmp" && mv "$F.tmp" "$F"

          # 2) of_shift 할당 줄을 '전체 줄 교체' (첫 1회만) — 잔여 토큰 제거
          awk 'BEGIN{done=0}
               {
                 if(!done && $0 ~ /^[[:space:]]*of_shift[[:space:]]*=/){
                   print "        of_shift = compute_of_shift(df)"; done=1
                 } else print $0
               }' "$F" > "$F.tmp" && mv "$F.tmp" "$F"

          # 3) 그래도 없으면 logit_core 바로 위에 삽입
          if ! grep -q "of_shift = compute_of_shift(df)" "$F"; then
            LN=$(grep -n "logit_core" "$F" | head -n1 | cut -d: -f1 || true)
            if [ -n "${LN:-}" ]; then
              sed -i "${LN}i \        of_shift = compute_of_shift(df)" "$F"
            else
              echo "        of_shift = compute_of_shift(df)" >> "$F"
            fi
          fi

          grep -n "compute_of_shift" "$F" | head -n 2 || true
          grep -n "of_shift = compute_of_shift(df)" "$F" | head -n 1 || true

      - name: Run backtest
        shell: bash
        working-directory: ${{ env.RUN_DIR }}
        env:
          OUT_DIR: ${{ env.OUT_DIR }}
        run: |
          set -euo pipefail
          mkdir -p "${OUT_DIR}"
          echo "Running with CSV_PATH=${CSV_PATH}"
          test -f "${CSV_PATH}" || { echo "❌ CSV missing: ${CSV_PATH}"; exit 1; }
          python run_4u.py --data_path "${CSV_PATH}" --config "conf/config.yml" --out_dir "${OUT_DIR}"
          echo "---- outputs ----"; ls -al "${OUT_DIR}" || true
          echo "---- summary ----"; head -n 60 "${OUT_DIR}/summary.json" 2>/dev/null || true
          echo "---- gating ----";  head -n 60 "${OUT_DIR}/gating_debug.json" 2>/dev/null || true

      - name: Upload artifacts (pinned)
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4.6.2
        with:
          name: backtest-output
          path: |
            ${{ env.OUT_DIR }}/summary.json
            ${{ env.OUT_DIR }}/gating_debug.json
            ${{ env.OUT_DIR }}/trades.csv
            ${{ env.OUT_DIR }}/preds_test.csv
          if-no-files-found: error
          retention-days: 30
          compression-level: 6
