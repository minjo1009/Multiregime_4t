name: Backtest

on:
  workflow_dispatch:
    inputs:
      trade_zip:
        description: Trade code zip (in repo root)
        required: true
        default: "trade_v1.0.7_full.zip"
      data_zip:
        description: Data zip (in repo root)
        required: true
        default: "ETHUSDT_1min_2020_2025.zip"
      csv_glob:
        description: CSV glob inside data zip
        required: true
        default: "*ETHUSDT*1min*2020*2025*.csv"
      out_dir:
        description: Output directory
        required: true
        default: "_out_4u/run"

jobs:
  run-backtest:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    env:
      REPO_DIR: repo
      RUN_DIR: tmp/trade
      DATA_DIR: tmp/data
      OUT_DIR: ${{ inputs.out_dir }}
      TRADE_ZIP: ${{ inputs.trade_zip }}
      DATA_ZIP: ${{ inputs.data_zip }}
      CSV_GLOB: ${{ inputs.csv_glob }}

    steps:
      # --- Manual checkout (policy-safe; no actions/checkout) ---
      - name: Manual checkout (policy-safe)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$REPO_DIR"
          git -C "$REPO_DIR" init
          git -C "$REPO_DIR" remote add origin "https://x-access-token:${{ github.token }}@github.com/${{ github.repository }}.git"
          git -C "$REPO_DIR" fetch --depth 1 origin "${GITHUB_SHA:-${GITHUB_REF##*/}}"
          git -C "$REPO_DIR" checkout -q FETCH_HEAD
          echo "Checked out:" && git -C "$REPO_DIR" rev-parse --short HEAD
          ls -al "$REPO_DIR"

      # --- Unzip code & data; verify required files exist ---
      - name: Unpack zips and verify structure
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$RUN_DIR" "$DATA_DIR" "$OUT_DIR"
          cp "$REPO_DIR/${TRADE_ZIP}" . || { echo "❌ trade zip not found: ${TRADE_ZIP}"; exit 1; }
          cp "$REPO_DIR/${DATA_ZIP}"  . || { echo "❌ data zip not found: ${DATA_ZIP}"; exit 1; }
          unzip -q "$TRADE_ZIP" -d "$RUN_DIR"
          unzip -q "$DATA_ZIP"  -d "$DATA_DIR"
          echo "== trade tree =="; ls -al "$RUN_DIR"
          echo "== data tree =="; ls -al "$DATA_DIR"
          # required files
          test -f "$RUN_DIR/requirements.txt" || { echo "❌ requirements.txt missing in ${RUN_DIR}"; exit 1; }
          test -f "$RUN_DIR/run_4u.py"        || { echo "❌ run_4u.py missing in ${RUN_DIR}"; exit 1; }
          test -f "$RUN_DIR/backtest/engine.py" || { echo "❌ backtest/engine.py missing"; exit 1; }
          test -f "$RUN_DIR/conf/config.yml"     || { echo "❌ conf/config.yml missing"; exit 1; }

      # --- Setup Python AFTER unzip; pin commit; cache points to real path ---
      - name: Setup Python (pinned; cache on real path)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: tmp/trade/requirements.txt
          check-latest: false
          allow-prereleases: false
          update-environment: true

      # --- Install deps ---
      - name: Install requirements
        shell: bash
        working-directory: ${{ env.RUN_DIR }}
        run: |
          set -euo pipefail
          python -V
          python -m pip install -U pip
          python -m pip install -r requirements.txt
          python - <<'PY'
          import yaml, json, numpy, pandas, sklearn, sys
          print("deps OK:", "yaml", getattr(yaml,'__version__','?'),
                "| numpy", numpy.__version__,
                "| pandas", pandas.__version__,
                "| sklearn", sklearn.__version__,
                "| py", sys.version.split()[0])
          PY

      # --- sklearn 1.4/1.5 family smoke (estimator vs base_estimator) ---
      - name: sklearn smoke (1.4/1.5 호환)
        shell: bash
        working-directory: ${{ env.RUN_DIR }}
        run: |
          set -euo pipefail
          python - <<'PY'
          import inspect
          from sklearn.calibration import CalibratedClassifierCV as C
          from sklearn.linear_model import LogisticRegression as L
          params = set(getattr(inspect.signature(C), 'parameters', {}).keys())
          print("sklearn", __import__('sklearn').__version__, "| C param:", "estimator" if 'estimator' in params else "base_estimator")
          PY

      # --- CSV preflight (path + base columns) ---
      - name: Preflight CSV
        shell: bash
        run: |
          set -euo pipefail
          CSV_PATH="$(ls ${DATA_DIR}/${CSV_GLOB} 2>/dev/null | head -n1 || true)"
          [ -n "$CSV_PATH" ] || CSV_PATH="$(ls ${DATA_DIR}/*.csv 2>/dev/null | head -n1 || true)"
          [ -n "$CSV_PATH" ] || { echo "❌ No CSV found in ${DATA_DIR}"; exit 1; }
          echo "Using CSV_PATH=${CSV_PATH}"
          python - <<'PY'
          import pandas as pd, os, sys
          p=os.environ['CSV_PATH']
          df=pd.read_csv(p, nrows=2)
          need={'open_time','open','high','low','close','volume'}
          miss=need-set(df.columns)
          if miss:
              print("❌ Missing base columns:", miss); sys.exit(1)
          print("✅ Columns OK:", sorted(df.columns))
          PY
          echo "CSV_PATH=${CSV_PATH}" >> $GITHUB_ENV

      # --- Run backtest ---
      - name: Run backtest
        shell: bash
        working-directory: ${{ env.RUN_DIR }}
        run: |
          set -euo pipefail
          python run_4u.py --data_path "${CSV_PATH}" --config "conf/config.yml" --out_dir "${OUT_DIR}"
          echo "---- gating debug (head) ----"
          [ -f "${OUT_DIR}/gating_debug.json" ] || echo "{}" > "${OUT_DIR}/gating_debug.json"
          head -n 60 "${OUT_DIR}/gating_debug.json" || true
          ls -al "${OUT_DIR}"

      # --- Upload artifacts (pinned SHA) ---
      - name: Upload artifacts (pinned)
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: backtest-output
          path: |
            ${{ env.OUT_DIR }}/summary.json
            ${{ env.OUT_DIR }}/gating_debug.json
            ${{ env.OUT_DIR }}/preds_test.csv
            ${{ env.OUT_DIR }}/trades.csv
            ${{ env.OUT_DIR }}/charts/
          if-no-files-found: warn
          retention-days: 30