name: backtest

on:
  workflow_dispatch:
    inputs:
      CODE_ZIP:
        description: "Code pack zip (path in repo or https URL)"
        required: true
        type: string
      DATA_ZIP:
        description: "Data pack zip (path in repo or https URL)"
        required: true
        type: string
      CSV_GLOB:
        description: "CSV glob (e.g., **/*ETHUSDT*1min*2020*2025*.csv)"
        required: true
        type: string
      PY:
        description: "Python version"
        required: false
        default: "3.11"
        type: string
      COVERAGE_GUARD:
        description: "Fail when coverage==0"
        required: false
        default: "true"
        type: choice
        options:
        - "true"
        - "false"

jobs:
  backtest:
    runs-on: ubuntu-latest
    env:
      CHECKOUT_SHA: "11bd71901b2cbc3cb3cbbf5b1b973078d1b96b7a"
      SETUP_PYTHON_SHA: "a26af69be951a213d495a4c3e4e4022e16d87065"
      UPLOAD_ARTIFACT_SHA: "ea165f8d65b6e0b1f71c5e3cd2a1f1e166d0ad2d"
    steps:
      - name: Validate pinned SHAs
        run: |
          set -Eeuo pipefail
          sha_re='^[0-9a-f]{40}$'
          check() {
            name="$1"; sha="$2"
            if ! [[ "$sha" =~ $sha_re ]]; then
              echo "::error::$name not full 40-hex SHA"; exit 2; fi
            code=$(curl -s -o /dev/null -w "%{http_code}" "https://api.github.com/repos/actions/${name}/tarball/${sha}")
            if [ "$code" != "200" ]; then
              echo "::error::Tarball HEAD failed for actions/${name}@${sha} (HTTP ${code})"; exit 2; fi
          }
          check checkout "$CHECKOUT_SHA"
          check setup-python "$SETUP_PYTHON_SHA"
          check upload-artifact "$UPLOAD_ARTIFACT_SHA"
          echo "Pinned SHAs look good."

      - name: Checkout
        uses: actions/checkout@11bd71901b2cbc3cb3cbbf5b1b973078d1b96b7a
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ github.event.inputs.PY }}

      - name: System deps
        run: |
          sudo apt-get update -y
          sudo apt-get install -y unzip tzdata

      - name: Init workspace
        run: |
          set -Eeuo pipefail
          mkdir -p tmp/trade tmp/data _out_4u/run scripts

      - name: Fetch code.zip
        run: |
          set -Eeuo pipefail
          SRC="${{ github.event.inputs.CODE_ZIP }}"
          if [[ "$SRC" =~ ^https?:// ]]; then
            curl -L "$SRC" -o code.zip
          else
            if [ -f "$SRC" ]; then cp "$SRC" code.zip; else echo "::error::CODE_ZIP not found"; exit 1; fi
          fi
          unzip -q -o code.zip -d tmp/trade_raw
          ROOTS=$(find tmp/trade_raw -mindepth 1 -maxdepth 1 -type d | wc -l)
          if [ "$ROOTS" = "1" ]; then
            mv tmp/trade_raw/*/* tmp/trade/ 2>/dev/null || true
          else
            mv tmp/trade_raw/* tmp/trade/ 2>/dev/null || true
          fi

      - name: Fetch data.zip
        run: |
          set -Eeuo pipefail
          SRC="${{ github.event.inputs.DATA_ZIP }}"
          if [[ "$SRC" =~ ^https?:// ]]; then
            curl -L "$SRC" -o data.zip
          else
            if [ -f "$SRC" ]; then cp "$SRC" data.zip; else echo "::error::DATA_ZIP not found"; exit 1; fi
          fi
          unzip -q -o data.zip -d tmp/data

      - name: Python deps
        run: |
          set -Eeuo pipefail
          python -m pip install --upgrade pip
          if [ -f tmp/trade/requirements.txt ]; then
            pip install -r tmp/trade/requirements.txt
          else
            pip install numpy pandas scikit-learn pyyaml
          fi

      - name: Ensure helper scripts (fallbacks)
        run: |
          set -Eeuo pipefail
          # canon_csv.py fallback (no heredoc)
          mkdir -p scripts
          printf '%s
'             'import sys,glob,json,os'             'pat = sys.argv[1] if len(sys.argv)>1 else "**/*.csv"'             'paths = sorted(glob.glob(pat, recursive=True))'             'paths = [p for p in paths if os.path.isfile(p)]'             'print(paths[0] if paths else "")'             > scripts/canon_csv.py
          # preflight_csv.py fallback (no heredoc)
          printf '%s
'             'import sys, os, json, pandas as pd'             'p = sys.argv[1] if len(sys.argv)>1 else ""'             'out = {"path": p, "exists": os.path.isfile(p)}'             'if out["exists"]:'             '    try:'             '        df = pd.read_csv(p, nrows=1000)'             '        out["columns"] = list(df.columns)'             '        out["rows_previewed"] = len(df)'             '    except Exception as e:'             '        out["read_error"] = str(e)'             'print(json.dumps(out, ensure_ascii=False))'             > scripts/preflight_csv.py

      - name: Write CSV path (preflight)
        run: |
          set -Eeuo pipefail
          cd tmp/data
          PAT="${{ github.event.inputs.CSV_GLOB }}"
          echo "CSV_GLOB=$PAT"
          PYFILE="../trade/scripts/canon_csv.py"
          if [ ! -f "$PYFILE" ]; then PYFILE="../../scripts/canon_csv.py"; fi
          SEL=$(python -u "$PYFILE" "${PAT}")
          cd - >/dev/null
          if [ -z "${SEL:-}" ] || [ ! -f "$SEL" ]; then
            echo "::error::No CSV found with glob '${PAT}' under tmp/data"
            echo "" > scripts/CSV_PATH.txt
            exit 1
          fi
          echo "$SEL" > scripts/CSV_PATH.txt
          echo "CSV_PATH=$SEL" >> "$GITHUB_ENV"
          # preflight JSON
          PREF="tmp/trade/scripts/preflight_csv.py"
          if [ ! -f "$PREF" ]; then PREF="scripts/preflight_csv.py"; fi
          python -u "$PREF" "$SEL" | tee preflight.json || true
          echo "Selected CSV:"; cat scripts/CSV_PATH.txt
          ls -l "$SEL"

      - name: Verify skeleton and import
        continue-on-error: true
        run: |
          set -Eeuo pipefail
          export PYTHONPATH="tmp/trade:tmp/trade/backtest:${PYTHONPATH:-}"
          printf '%s
'             'import os, importlib, json, sys, pathlib'             'p = os.environ.get("CSV_PATH") or (pathlib.Path("scripts/CSV_PATH.txt").read_text().strip() if pathlib.Path("scripts/CSV_PATH.txt").exists() else "")'             'out={"csv_path":p, "csv_exists": os.path.isfile(p)}'             'for mod in ["backtest.runner","trend4p.calibration"]:'             '    try:'             '        m=importlib.import_module(mod); out[mod]=getattr(m,"__file__",None)'             '    except Exception as e:'             '        out[mod]=f"IMPORT_ERROR: {e}"'             'print(json.dumps(out, ensure_ascii=False))'             'import sys as _s; _s.exit(0 if out["csv_exists"] else 3)'             > verify_import.py
          python -u verify_import.py

      - name: Engine compile triage
        continue-on-error: true
        run: |
          set -Eeuo pipefail
          printf '%s
'             'import sys, os, py_compile, pathlib, json'             'roots=["tmp/trade","tmp/trade/backtest","tmp/trade/trend4p"]'             'files=[]'             'for r in roots:'             '    if os.path.isdir(r):'             '        for p in pathlib.Path(r).rglob("*.py"):'             '            files.append(str(p))'             'fails=[]'             'for f in files:'             '    try:'             '        py_compile.compile(f, doraise=True)'             '    except Exception as e:'             '        fails.append((f,str(e)))'             'print(json.dumps({"compiled": len(files)-len(fails), "failed": fails[:10]}, ensure_ascii=False))'             > triage.py
          python -u triage.py

      - name: Run backtest (entrypoint sweep)
        run: |
          set -Eeuo pipefail
          export PYTHONPATH="tmp/trade:tmp/trade/backtest:${PYTHONPATH:-}"
          tryrun() { echo "[try] $*"; python -u "$@" && return 0 || return 1; }
          if [ -f tmp/trade/scripts/entrypoint_run.sh ]; then
            bash tmp/trade/scripts/entrypoint_run.sh || true
          else
            if [ -f tmp/trade/run_4u.py ]; then tryrun tmp/trade/run_4u.py || true; fi
            if [ -f tmp/trade/backtest/runner.py ]; then tryrun tmp/trade/backtest/runner.py || true; fi
          fi
          mkdir -p _out_4u/run
          python - "$@" <<'PYCODE' >/dev/null 2>&1 || true
PYCODE
          python - <<'PYCODE' >/dev/null 2>&1 || true
PYCODE
          # ensure minimal artifacts exist
          python - "$@" <<'PY'
import json, os, pathlib
root=pathlib.Path("_out_4u"); root.mkdir(exist_ok=True, parents=True)
run=(root/"run"); run.mkdir(exist_ok=True, parents=True)
def ensure(fp, default):
    if not fp.exists():
        if isinstance(default, dict):
            fp.write_text(json.dumps(default))
        else:
            fp.write_text(default)
ensure(root/"summary.json", {"status":"empty"})
ensure(root/"gating_debug.json", {})
ensure(run/"gating_debug.json", {})
ensure(root/"preds_test.csv", "")
ensure(root/"trades.csv", "")
PY

      - name: Post analyze gating (if available)
        if: ${{ always() }}
        run: |
          set -Eeuo pipefail
          if [ -f tmp/trade/scripts/post_analyze.py ]; then
            python -u tmp/trade/scripts/post_analyze.py || true
          fi

      - name: Sync gating_debug root
        if: ${{ always() }}
        run: |
          cp -f _out_4u/run/gating_debug.json _out_4u/gating_debug.json || true

      - name: Upload results
        if: ${{ always() }}
        uses: actions/upload-artifact@ea165f8d65b6e0b1f71c5e3cd2a1f1e166d0ad2d
        with:
          name: backtest_outputs
          path: |
            _out_4u/**
            preflight.json
