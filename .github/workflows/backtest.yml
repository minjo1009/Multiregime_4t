name: Backtest v1.0.9 (Checklist2.3a+gatefix)

on:
  workflow_dispatch:
    inputs:
      CODE_ZIP:
        description: Code ZIP path (repo-relative or URL)
        required: true
        default: trade_v1.0.9.zip
      DATA_ZIP:
        description: Data ZIP path (repo-relative or URL)
        required: true
        default: ETHUSDT_1min_2020_2025.zip
      CSV_GLOB:
        description: Glob for CSV inside data zip
        required: true
        default: "**/*ETHUSDT*1min*2020*2025*.csv"
      ALLOW_DEDUP:
        description: "Deduplicate code.zip automatically if duplicate paths found"
        required: false
        default: "true"  # 2.3a 업데이트: 기본 자동 디듀프 허용
      COVERAGE_GUARD:
        description: "Fail run when inferred coverage == 0"
        required: false
        default: "true"

jobs:
  backtest:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    env:
      PYTHONUNBUFFERED: "1"
      PYTHONDONTWRITEBYTECODE: "1"

    steps:
      - name: Validate pinned SHAs (Checklist2.3a)
        run: |
          set -euo pipefail
          verify() {
            repo="$1"; sha="$2"
            [[ "$sha" =~ ^[0-9a-f]{40}$ ]] || { echo "::error title=PinFormat::${repo}@${sha} not 40-hex"; exit 1; }
            url="https://codeload.github.com/${repo}/legacy.tar.gz/${sha}"
            code=$(curl -s -o /dev/null -w "%{http_code}" -I "$url" || true)
            [ "$code" = "200" ] || { echo "::error title=PinUnavailable::${repo}@${sha} codeload=$code"; exit 1; }
          }
          verify actions/checkout 11bd71901bbe5b1630ceea73d27597364c9af683   # v4.2.2
          verify actions/setup-python a26af69be951a213d495a4c3e4e4022e16d87065 # v5.6.0
          verify actions/upload-artifact ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2

      - name: Checkout
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: Setup Python 3.11
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: '3.11'

      - name: Prepare OS deps
        env:
          DEBIAN_FRONTEND: noninteractive
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -yq --no-install-recommends unzip tzdata rsync
          sudo ln -fs /usr/share/zoneinfo/Asia/Seoul /etc/localtime
          sudo dpkg-reconfigure -f noninteractive tzdata

      - name: Reset workspace folders (clean + precreate logs)
        run: |
          set -euo pipefail
          rm -rf tmp/trade tmp/data tmp/trade_raw _out_4u scripts
          mkdir -p tmp/trade tmp/data tmp/trade_raw _out_4u/run _out_4u/logs scripts
          : > _out_4u/logs/stdout.log

      - name: Bring zips
        run: |
          set -euo pipefail
          CODE_ZIP="${{ github.event.inputs.CODE_ZIP }}"
          DATA_ZIP="${{ github.event.inputs.DATA_ZIP }}"
          fetch() { src="$1"; dst="$2"; [[ "$src" =~ ^https?:// ]] && curl -L "$src" -o "$dst" || cp -f "$src" "$dst"; }
          fetch "$CODE_ZIP" tmp/code.zip
          fetch "$DATA_ZIP" tmp/data.zip
          ls -l tmp/*.zip

      - name: Show code.zip sha256 & list
        run: |
          set -euo pipefail
          if command -v sha256sum >/dev/null; then sha256sum tmp/code.zip; else shasum -a 256 tmp/code.zip; fi
          unzip -Z1 tmp/code.zip | head -n 50 || true

      - name: Inspect code.zip for duplicates (fail-fast or auto-dedupe)
        run: |
          set -euo pipefail
          dups=$(unzip -Z1 tmp/code.zip | sort | uniq -d || true)
          if [ -n "$dups" ]; then
            echo "$dups" | tee _out_4u/logs/zip_duplicates.txt
            echo "Duplicate paths detected in code.zip:"; printf '%s\n' "$dups"
            if [ "${{ github.event.inputs.ALLOW_DEDUP }}" = "true" ]; then
              echo "::warning::Auto-dedup enabled. Repacking code.zip…"
              rm -rf tmp/code_src
              mkdir -p tmp/code_src
              unzip -oq tmp/code.zip -d tmp/code_src
              (cd tmp && zip -qr -X code.dedup.zip code_src)
              mv -f tmp/code.dedup.zip tmp/code.zip
              echo "::notice::Dedup complete; proceeding with cleaned archive."
            else
              echo "::error title=ZipDuplicate::Please rebuild code.zip without duplicates (or rerun with ALLOW_DEDUP=true)"
              exit 1
            fi
          fi

      - name: Unzip packs (flatten) + sample csv list
        run: |
          set -euo pipefail
          unzip -oq tmp/code.zip -d tmp/trade_raw
          shopt -s nullglob dotglob
          if [ "$(find tmp/trade_raw -mindepth 1 -maxdepth 1 -type d | wc -l)" -eq 1 ] && \
             [ "$(find tmp/trade_raw -mindepth 1 -maxdepth 1 -type f | wc -l)" -eq 0 ]; then
            mv tmp/trade_raw/*/* tmp/trade/ 2>/dev/null || mv tmp/trade_raw/* tmp/trade/
          else
            mv tmp/trade_raw/* tmp/trade/ 2>/dev/null || true
          fi
          unzip -oq tmp/data.zip -d tmp/data
          echo "Code tree:"; find tmp/trade -maxdepth 2 -type d -print
          echo "CSV sample (max 10):"; find tmp/data -type f -name "*.csv" | head -n 10 || true

      - name: Sanitize stdlib shadows (importlib/typing/enum/dataclasses)
        run: |
          set -euo pipefail
          cd tmp/trade
          for f in importlib.py typing.py enum.py dataclasses.py; do
            if [ -f "$f" ]; then
              mv "$f" "${f}.shadowed"
              echo "::warning::Shadowed stdlib detected and renamed: $f -> ${f}.shadowed"
            fi
          done

      - name: Python deps (with fallback)
        working-directory: tmp/trade
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install --no-cache-dir -r requirements.txt || true; fi
          pip install --no-cache-dir numpy pandas pyyaml scikit-learn jsonschema || true

      # ---------- Writers (scripts) ----------
      - name: Write preflight_csv.py (ABS path writer)
        run: |
          set -euo pipefail
          cat <<'PY_A' > scripts/preflight_csv.py
          #!/usr/bin/env python3
          import sys, json, os, glob, pandas as pd, pathlib
          root = sys.argv[1] if len(sys.argv)>1 else "tmp/data"
          csv_glob = os.environ.get("CSV_GLOB","**/*.csv")
          matches = sorted(glob.glob(os.path.join(root, csv_glob), recursive=True))
          if not matches:
              matches = sorted(glob.glob(os.path.join(root, "**/*.csv"), recursive=True))
          out = {"glob": csv_glob, "found": matches[:10]}
          if not matches:
              print(json.dumps(out, ensure_ascii=True)); sys.exit(0)
          path = pathlib.Path(matches[0]).resolve().as_posix()
          try:
              pd.read_csv(path, nrows=2)
              out["sample_path"]=path
          except Exception as e:
              out["error"]=str(e); out["sample_path"]=path
          print(json.dumps(out, ensure_ascii=True))
          with open("CSV_PATH.txt","w", encoding="utf-8") as f: f.write(path)
          PY_A
          chmod +x scripts/preflight_csv.py

      - name: Write canon_csv.py (robust ABS + fallback search)
        run: |
          set -euo pipefail
          cat <<'PY' > scripts/canon_csv.py
          #!/usr/bin/env python3
          import os, sys, glob
          ws = os.environ.get("GITHUB_WORKSPACE", os.getcwd())
          def abs1(p): return os.path.abspath(p) if p else ""
          cand = (sys.argv[1] if len(sys.argv)>1 else "").strip()
          p = abs1(cand if os.path.isabs(cand) else os.path.join(ws, cand))
          if p and os.path.isfile(p):
              print(p); sys.exit(0)
          for f in glob.glob(os.path.join(ws, "tmp", "data", "**", "*.csv"), recursive=True):
              print(os.path.abspath(f)); sys.exit(0)
          print(""); sys.exit(0)
          PY
          chmod +x scripts/canon_csv.py

      - name: Write make_empty_artifacts.py (dual gating_debug + logs)
        run: |
          set -euo pipefail
          cat <<'PY_B' > scripts/make_empty_artifacts.py
          #!/usr/bin/env python3
          import pathlib
          base = pathlib.Path("_out_4u/run"); base.mkdir(parents=True, exist_ok=True)
          (base/"gating_debug.json").write_text("{}", encoding="utf-8")
          root = pathlib.Path("_out_4u"); root.mkdir(parents=True, exist_ok=True)
          (root/"gating_debug.json").write_text("{}", encoding="utf-8")
          (root/"summary.json").write_text("{}", encoding="utf-8")
          (root/"preds_test.csv").write_text("", encoding="utf-8")
          (root/"trades.csv").write_text("", encoding="utf-8")
          (root/"logs").mkdir(parents=True, exist_ok=True)
          (root/"logs/stdout.log").write_text("", encoding="utf-8")
          print("Empty artifacts created")
          PY_B
          chmod +x scripts/make_empty_artifacts.py

      - name: Write entrypoint_run.sh (--data_path first, full logs)
        run: |
          set -euo pipefail
          cat <<'SH_A' > scripts/entrypoint_run.sh
          #!/usr/bin/env bash
          set -Eeuo pipefail
          ROOT="$GITHUB_WORKSPACE/tmp/trade"
          LOG="$GITHUB_WORKSPACE/_out_4u/logs/stdout.log"
          cd "$GITHUB_WORKSPACE"
          trap 'echo "::group::tail stdout.log"; tail -n 200 "$LOG" 2>/dev/null || true; echo "::endgroup::"' EXIT

          RAW="$(cat scripts/CSV_PATH.txt 2>/dev/null || true)"
          CAND="$(python -c 'import sys; print(sys.stdin.read().strip())' <<<"$RAW")"
          CSV_PATH="$(GITHUB_WORKSPACE="$GITHUB_WORKSPACE" python -u scripts/canon_csv.py "$CAND")"
          if [ -z "${CSV_PATH:-}" ] || [ ! -f "$CSV_PATH" ]; then
            echo "::error::No CSV found under tmp/data (got: '${CAND:-<empty>}')" | tee -a "$LOG"
            python -u "$GITHUB_WORKSPACE/scripts/make_empty_artifacts.py" | tee -a "$LOG"
            exit 0
          fi
          echo "Using CSV: $CSV_PATH (exists=yes)" | tee -a "$LOG"

          export PYTHONPATH="${ROOT}:${ROOT}/backtest:${PYTHONPATH:-}"
          mkdir -p "_out_4u/run" "_out_4u/logs"
          cd "$ROOT"
          CFG="conf/config.yml"

          py() { python -X faulthandler -u "$@"; }
          try() { echo "+ $*" | tee -a "$LOG"; ( "$@" ) >>"$LOG" 2>&1; return ${PIPESTATUS[0]}; }

          try py run_4u.py --data_path "$CSV_PATH" --config "$CFG" && exit 0
          try py run_4u.py --data "$CSV_PATH" --config "$CFG" && exit 0
          try py run_4u.py "$CSV_PATH" && exit 0
          if [ -f "backtest/run_4u.py" ]; then
            try py backtest/run_4u.py --data_path "$CSV_PATH" --config "$CFG" && exit 0
            try py backtest/run_4u.py --data "$CSV_PATH" --config "$CFG" && exit 0
          fi
          try py -m backtest.runner --data "$CSV_PATH" --config "$CFG" && exit 0 || true

          echo "::warning::Entrypoint attempts failed; writing empty artifacts" | tee -a "$LOG"
          py "$GITHUB_WORKSPACE/scripts/make_empty_artifacts.py" | tee -a "$LOG"
          exit 0
          SH_A
          chmod +x scripts/entrypoint_run.sh

      - name: Write shim source (standalone)
        run: |
          set -euo pipefail
          cat <<'PY_SHIM' > scripts/run_4u_shim.py
          import os, sys
          def main():
              csv = os.environ.get("CSV_PATH") or (sys.argv[1] if len(sys.argv)>1 else None)
              cfg = "conf/config.yml"
              if not csv:
                  print("[shim] CSV_PATH not provided"); return 3
              try:
                  from backtest.runner import run_backtest
              except Exception as e:
                  print(f"[shim] runner import failed: {e}"); return 2
              try:
                  _ = run_backtest(data_path=csv, config_path=cfg)
              except TypeError:
                  try:
                      _ = run_backtest(csv, cfg)
                  except Exception as e:
                      print(f"[shim] run_backtest failed: {e}"); return 4
              return 0
          if __name__ == "__main__":
              sys.exit(main())
          PY_SHIM
          chmod +x scripts/run_4u_shim.py

      - name: Write calibration shim injector (predict/predict_proba 포함)
        run: |
          set -euo pipefail
          cat <<'PY_CAL' > scripts/ensure_calibrator.py
          import sys, re, pathlib
          root = pathlib.Path("tmp/trade/trend4p")
          f = root / "calibration.py"
          if not f.exists():
              sys.exit(0)
          code = f.read_text(encoding="utf-8")
          if re.search(r'\bclass\s+Calibrator\b', code) and ("predict(" in code) and ("predict_proba(" in code):
              print("Calibrator already provides predict/predict_proba"); sys.exit(0)
          append = r'''
          # --- Injected Calibrator shim (Checklist2.3a+gatefix) ---
          try:
              import numpy as _np
              from sklearn.isotonic import IsotonicRegression as _Iso
          except Exception:
              import numpy as _np
              class _Iso:
                  def __init__(self,*a,**k): pass
                  def fit(self,*a,**k): return self
                  def transform(self, x): return _np.asarray(x,float).ravel()
          class Calibrator:
              def __init__(self, method="isotonic", by_session=False, **kwargs):
                  self.method = (method or "off").lower(); self.by_session=bool(by_session); self._m=None
              def _prep(self, y, p):
                  y=_np.asarray(y,float).ravel(); p=_np.asarray(p,float).ravel()
                  m=_np.isfinite(y)&_np.isfinite(p); return y[m],p[m]
              def fit(self, y=None, p=None, **kw):
                  if y is None and p is None:
                      p = kw.get("proba") or kw.get("p"); y = kw.get("target") or kw.get("y")
                  if p is None or y is None:
                      self._m=None; return self
                  y,p=self._prep(y,p)
                  if y.size<3:
                      self._m=None; return self
                  self._m = _Iso(out_of_bounds="clip").fit(p,y) if self.method in ("isotonic","iso") else None
                  return self
              def transform(self, p):
                  p=_np.asarray(p,float).ravel()
                  try: out=self._m.transform(p) if self._m is not None else p
                  except Exception: out=p
                  return _np.clip(_np.asarray(out,float).ravel(),1e-6,1-1e-6)
              def predict(self, p): return self.transform(p)
              def predict_proba(self, p): return self.transform(p)
              def __call__(self, p): return self.transform(p)
              def fit_transform(self, y, p, **kw): return self.fit(y=y,p=p,**kw).transform(p)
          # --- End shim ---
          '''
          f.write_text(code + "\n" + append, encoding="utf-8")
          print("Injected Calibrator shim with predict/predict_proba")
          PY_CAL
          chmod +x scripts/ensure_calibrator.py

      - name: Write gating post-analyze & self-check (gatefix)
        run: |
          set -euo pipefail
          cat <<'PY_POST' > scripts/post_analyze.py
          #!/usr/bin/env python3
          import os, json, pandas as pd
          from pathlib import Path
          OUT = Path("_out_4u"); RUN = OUT/"run"; RUN.mkdir(parents=True, exist_ok=True)
          diag = {}
          preds_p = OUT/"preds_test.csv"; trades_p = OUT/"trades.csv"
          def safe_read(p):
              try: return pd.read_csv(p)
              except Exception: return None
          preds = safe_read(preds_p); trades = safe_read(trades_p)
          diag["exists"]={"preds": preds is not None, "trades": trades is not None}
          diag["sizes"]={"preds_rows": 0 if preds is None else int(len(preds)),
                         "trades_rows": 0 if trades is not None else int(len(trades))}
          cov=0.0
          if trades is not None and len(trades)>0:
              cov = float(len(trades))/max(1, diag["sizes"]["preds_rows"])
          elif preds is not None and "gate" in preds.columns:
              cov = float((preds["gate"].astype(float)>0.5).mean())
          if preds is not None and "gate" in preds.columns:
              g=preds["gate"].astype(float)
              qs=[0.0,0.01,0.5,0.9,0.95,0.99,1.0]
              diag["gate_percentiles"]={str(q): float(g.quantile(q)) for q in qs}
              diag["gate_mean"]=float(g.mean())
          diag["coverage_overall_inferred"]=cov
          (RUN/"gating_debug.json").write_text(json.dumps(diag, indent=2, ensure_ascii=False), encoding="utf-8")
          print("[post_analyze] coverage≈", cov)
          if os.environ.get("COVERAGE_GUARD","false").lower()=="true" and cov<=0.0:
              import sys; print("::error::coverage==0"); sys.exit(3)
          PY_POST
          chmod +x scripts/post_analyze.py

          cat <<'PY_SC' > scripts/self_check_gate.py
          #!/usr/bin/env python3
          import json
          from pathlib import Path
          p = Path("_out_4u/run/gating_debug.json")
          assert p.exists() and p.stat().st_size>2, "gating_debug.json missing or empty"
          obj = json.loads(p.read_text(encoding="utf-8"))
          assert "coverage_overall_inferred" in obj, "missing coverage"
          print("[self_check_gate] OK; coverage≈", obj.get("coverage_overall_inferred"))
          PY_SC
          chmod +x scripts/self_check_gate.py

      - name: Patch calibration if needed
        run: |
          set -euo pipefail
          python -u scripts/ensure_calibrator.py

      - name: Install shim if missing (non-destructive)
        run: |
          set -euo pipefail
          if [ ! -f tmp/trade/run_4u.py ]; then
            mkdir -p tmp/trade
            cp -f scripts/run_4u_shim.py tmp/trade/run_4u.py
            chmod +x tmp/trade/run_4u.py
            echo "Shim installed: tmp/trade/run_4u.py"
          else
            echo "Original run_4u.py present; shim not installed."
          fi

      - name: Verify project skeleton (config/runner)
        run: |
          set -euo pipefail
          python - <<'PY'
          import os, sys, json, pathlib, yaml
          root = pathlib.Path("tmp/trade")
          must_exist = ["conf/config.yml"]
          candidates = ["run_4u.py", "backtest/run_4u.py", "backtest/runner.py"]
          miss = [p for p in must_exist if not (root/p).exists()]
          found = [p for p in candidates if (root/p).exists()]
          out = {"missing": miss, "runner_candidates": found}
          cfgp = root/"conf/config.yml"
          if cfgp.exists():
              try:
                  data = yaml.safe_load(cfgp.read_text(encoding="utf-8")) or {}
                  out["config_keys"] = list(data)[:15]
                  out["config_size"] = cfgp.stat().st_size
              except Exception as e:
                  out["config_error"] = str(e)
          print(json.dumps(out, ensure_ascii=False))
          if miss: sys.exit(2)
          PY

      - name: Preflight data (warn-only)
        env:
          CSV_GLOB: ${{ github.event.inputs.CSV_GLOB }}
        run: |
          set -euo pipefail
          python -u scripts/preflight_csv.py tmp/data | tee preflight.json || true
          [ -f CSV_PATH.txt ] && mv CSV_PATH.txt scripts/CSV_PATH.txt || true
          echo "Preflight path:"; cat scripts/CSV_PATH.txt || true
          echo "Exists?"; [ -f "$(cat scripts/CSV_PATH.txt 2>/dev/null)" ] && echo yes || echo no

      - name: Verify runner & calibrator before run (import test)
        run: |
          set -euo pipefail
          export PYTHONPATH="tmp/trade:tmp/trade/backtest:${PYTHONPATH:-}"
          python - <<'PY'
          import sys, os, importlib, json
          p = open("scripts/CSV_PATH.txt").read().strip() if os.path.exists("scripts/CSV_PATH.txt") else ""
          out={"csv_path":p, "csv_exists": os.path.isfile(p)}
          for mod in ["backtest.runner","trend4p.calibration"]:
              try:
                  m=importlib.import_module(mod); out[mod]=getattr(m,"__file__",None)
              except Exception as e:
                  out[mod]=f"IMPORT_ERROR: {e}"
          print(json.dumps(out, ensure_ascii=False))
          if not out["csv_exists"]: sys.exit(3)
          PY

      - name: Smoke test Calibrator API
        run: |
          set -euo pipefail
          export PYTHONPATH="tmp/trade:tmp/trade/backtest:${PYTHONPATH:-}"
          python - <<'PY'
          import numpy as np
          from trend4p.calibration import Calibrator
          c = Calibrator(method="isotonic").fit([0,1,1,0],[0.1,0.8,0.9,0.2])
          x = [0.2,0.5,0.8]
          for fn in ("transform","predict","predict_proba"):
              y = getattr(c, fn)(x)
              arr = np.asarray(y, float)
              assert arr.shape[0]==3 and np.isfinite(arr).all() and (arr>=0).all() and (arr<=1).all(), fn
          print("Calibrator API OK")
          PY

      - name: Run backtest
        run: |
          set -euo pipefail
          python -u scripts/make_empty_artifacts.py
          bash scripts/entrypoint_run.sh
          [ -f _out_4u/run/gating_debug.json ] && cp -f _out_4u/run/gating_debug.json _out_4u/gating_debug.json || true
          echo "Artifacts directory:"; ls -al _out_4u || true; ls -al _out_4u/run || true

      - name: Sweep for outputs (if code saved elsewhere)
        run: |
          set -euo pipefail
          for name in summary.json preds_test.csv trades.csv gating_debug.json metrics.json; do
            f=$(find tmp/trade -maxdepth 6 -type f -name "$name" | head -n1 || true)
            if [ -n "$f" ]; then
              cp -f "$f" "_out_4u/$name" || true
              echo "collected $name from $f"
            fi
          done

      - name: Post analyze gating (fill run/gating_debug.json)
        env:
          COVERAGE_GUARD: ${{ github.event.inputs.COVERAGE_GUARD }}
        run: |
          set -euo pipefail
          python -u scripts/post_analyze.py

      - name: Self-check gating
        run: |
          set -euo pipefail
          python -u scripts/self_check_gate.py

      - name: Post-run sanity (warn if empty)
        run: |
          set -euo pipefail
          python - <<'PY'
          import os
          paths = [
              "_out_4u/summary.json",
              "_out_4u/preds_test.csv",
              "_out_4u/trades.csv",
              "_out_4u/gating_debug.json",
              "_out_4u/run/gating_debug.json",
              "_out_4u/logs/stdout.log",
          ]
          for p in paths:
              if not os.path.exists(p):
                  print(f"::warning::missing {p}")
                  continue
              sz = os.path.getsize(p)
              if sz <= 2 and not p.endswith(".log"):
                  print(f"::warning::empty artifact: {p} ({sz} bytes)")
          PY

      - name: Enforce non-empty outputs (debug gate; non-blocking)
        continue-on-error: true
        if: always()
        run: |
          set -euo pipefail
          bad=0
          for f in _out_4u/summary.json _out_4u/preds_test.csv _out_4u/trades.csv; do
            if [ ! -s "$f" ]; then echo "::error::$f is empty or missing"; bad=$((bad+1)); fi
          done
          if [ $bad -ge 3 ]; then exit 1; fi

      - name: Upload artifacts (entire folder)
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: backtest_v1.0.9_outputs
          path: _out_4u/**
          if-no-files-found: warn