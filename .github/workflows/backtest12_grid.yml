name: backtest12-grid

on:
  workflow_dispatch:
    inputs:
      CODE_ZIP:
        description: Repo path to code zip (at repo root)
        required: true
        default: trade_v1.1.9.zip
      DATA_ZIP:
        description: Repo path to data zip (at repo root)
        required: true
        default: ETHUSDT_1min_2020_2025.zip
      CSV_FILE:
        description: CSV filename after unzip
        required: true
        default: ETHUSDT_1min_2020_2025.csv

jobs:
  grid:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 6
      matrix:
        include:
          # === Percent 모드(고정 TP/SL) ===
          - {MODE: pct, THR_US: 4.0, THR_EU: 3.8, THR_ASIA: 3.5, HOLD: 6, BE: 3, TP: 0.0035, SL: 0.0018, FILTER: ema}
          - {MODE: pct, THR_US: 4.0, THR_EU: 3.8, THR_ASIA: 3.5, HOLD: 8, BE: 5, TP: 0.0035, SL: 0.0018, FILTER: none}
          - {MODE: pct, THR_US: 4.2, THR_EU: 3.9, THR_ASIA: 3.6, HOLD: 6, BE: 5, TP: 0.0042, SL: 0.0020, FILTER: ema}
          - {MODE: pct, THR_US: 4.2, THR_EU: 3.9, THR_ASIA: 3.6, HOLD: 8, BE: 3, TP: 0.0042, SL: 0.0020, FILTER: none}
          # === ATR 모드(ATR 비율*계수 → 퍼센트 환산) ===
          - {MODE: atr, K1: 1.2, K2: 0.7, THR_US: 4.0, THR_EU: 3.8, THR_ASIA: 3.5, HOLD: 6, BE: 3, FILTER: ema}
          - {MODE: atr, K1: 1.6, K2: 0.9, THR_US: 4.0, THR_EU: 3.8, THR_ASIA: 3.5, HOLD: 8, BE: 5, FILTER: none}
          - {MODE: atr, K1: 1.2, K2: 0.7, THR_US: 4.2, THR_EU: 3.9, THR_ASIA: 3.6, HOLD: 6, BE: 5, FILTER: ema}
          - {MODE: atr, K1: 1.6, K2: 0.9, THR_US: 4.2, THR_EU: 3.9, THR_ASIA: 3.6, HOLD: 8, BE: 3, FILTER: none}

    env:
      RUN_DIR: tmp/trade
      DATA_DIR: tmp/data
      OUT_DIR: _out_4u/run
      PYVER: '3.11'

    steps:
      # ✅ pinned (checkout v5.0.0)
      - name: Checkout
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8
        with:
          fetch-depth: 0

      # ✅ pinned (setup-python v5.6.0)
      - name: Setup Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ env.PYVER }}

      - name: Resolve ZIPs
        shell: bash
        run: |
          set -euo pipefail
          res() { local in="$1" out="$2" path=""; local base="$(basename "$in")"; if [[ -f "$in" ]]; then path="${GITHUB_WORKSPACE}/$in"; else path="$(find "${GITHUB_WORKSPACE}" -maxdepth 2 -type f -name "$base" -print -quit || true)"; fi; [[ -n "$path" && -f "$path" ]] || { echo "::error::ZIP not found: $in"; exit 66; }; echo "${out}=${path}" >> "$GITHUB_ENV"; echo "[resolved] $in -> $path"; }
          res "${{ github.event.inputs.CODE_ZIP }}" CODE_ZIP_ABS
          res "${{ github.event.inputs.DATA_ZIP }}" DATA_ZIP_ABS

      - name: Unpack code and data
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$RUN_DIR" "$DATA_DIR" "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"
          unzip -q "$CODE_ZIP_ABS" -d "$RUN_DIR"
          unzip -q "$DATA_ZIP_ABS" -d "$DATA_DIR"
          if [ ! -f "$RUN_DIR/run_4u.py" ]; then CAND="$(find "$RUN_DIR" -maxdepth 2 -type f -name 'run_4u.py' -print -quit || true)"; [ -n "$CAND" ] || { echo "::error::run_4u.py not found in code zip"; exit 67; }; echo "RUN_DIR=$(dirname "$CAND")" >> "$GITHUB_ENV"; echo "[debug] RUN_DIR -> $(dirname "$CAND")"; fi
          echo "[debug] CSV files:"; find "$DATA_DIR" -maxdepth 2 -type f -name '*.csv' -print || true

      - name: Install deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install -U pip >/dev/null
          if [ -f "$RUN_DIR/requirements.txt" ]; then pip install -r "$RUN_DIR/requirements.txt"; else pip install pandas numpy pyyaml >/dev/null; fi

      - name: Detect CSV (ABS)
        shell: bash
        run: |
          set -euo pipefail
          CSV="${GITHUB_WORKSPACE}/${{ env.DATA_DIR }}/${{ github.event.inputs.CSV_FILE }}"
          if [ ! -f "$CSV" ]; then F="$(find "${{ env.DATA_DIR }}" -type f -name "${{ github.event.inputs.CSV_FILE }}" -print -quit || true)"; [ -n "$F" ] || { echo "::error::CSV not found: ${{ github.event.inputs.CSV_FILE }}"; exit 64; }; CSV="${GITHUB_WORKSPACE}/${F}"; fi
          echo "CSV_PATH=$CSV" >> "$GITHUB_ENV"
          echo "[csv] $CSV"

      - name: Preflight (schema + ATR ratio)
        shell: bash
        run: |
          set -euo pipefail
          python -c "import os,json,pandas as pd,numpy as np; csv=os.environ['CSV_PATH']; cols=['open_time','open','high','low','close','volume']; df=pd.read_csv(csv,usecols=cols,nrows=400000); need=['open_time','open','high','low','close','volume']; miss=[c for c in need if c not in df.columns]; pc=df['close'].shift(1); tr=(df['high']-df['low']).abs(); import numpy as _np; tr=_np.maximum(tr,(df['high']-pc).abs()); tr=_np.maximum(tr,(df['low']-pc).abs()); atr=pd.Series(tr).rolling(14,min_periods=14).mean(); ratio=float(_np.nanmedian((atr/df['close']).values)); hint='ms' if pd.to_numeric(df['open_time'],errors='coerce').max()>1e12 else 's'; print(json.dumps({'path':csv,'rows_scanned':int(len(df)),'columns':list(df.columns),'missing':miss,'open_time_hint':hint,'atr_ratio_median':ratio}))" | tee "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}/preflight.json"
          ATR="$(jq -r '.atr_ratio_median' "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}/preflight.json")"
          echo "ATR_RATIO=$ATR" >> "$GITHUB_ENV"

      - name: Set params from matrix
        shell: bash
        run: |
          set -euo pipefail
          echo "MODE=${{ matrix.MODE }}" >> "$GITHUB_ENV"
          echo "THR_US=${{ matrix.THR_US }}" >> "$GITHUB_ENV"
          echo "THR_EU=${{ matrix.THR_EU }}" >> "$GITHUB_ENV"
          echo "THR_ASIA=${{ matrix.THR_ASIA }}" >> "$GITHUB_ENV"
          echo "HOLD=${{ matrix.HOLD }}" >> "$GITHUB_ENV"
          echo "BE=${{ matrix.BE }}" >> "$GITHUB_ENV"
          echo "FILTER=${{ matrix.FILTER }}" >> "$GITHUB_ENV"
          : "${ATR_RATIO:=0}"
          if [ "${{ matrix.MODE }}" = "atr" ]; then
            TP_EFF=$(awk "BEGIN { print ${ATR_RATIO} * ${{ matrix.K1 }} }")
            SL_EFF=$(awk "BEGIN { print ${ATR_RATIO} * ${{ matrix.K2 }} }")
          else
            TP_EFF="${{ matrix.TP }}"
            SL_EFF="${{ matrix.SL }}"
          fi
          echo "TP_EFF=$TP_EFF" >> "$GITHUB_ENV"
          echo "SL_EFF=$SL_EFF" >> "$GITHUB_ENV"
          echo "[params] MODE=${{ matrix.MODE }} THR_US=${{ matrix.THR_US }} THR_EU=${{ matrix.THR_EU }} THR_ASIA=${{ matrix.THR_ASIA }} HOLD=${{ matrix.HOLD }} BE=${{ matrix.BE }} FILTER=${{ matrix.FILTER }} TP_EFF=$TP_EFF SL_EFF=$SL_EFF"

      - name: Override config (polyfill) + snapshot
        shell: bash
        run: |
          set -euo pipefail
          python -c "import os,pathlib,yaml,hashlib,json; run_dir=os.environ['RUN_DIR']; mode=os.environ.get('MODE','pct'); thr_us=float(os.environ['THR_US']); thr_eu=float(os.environ['THR_EU']); thr_asia=float(os.environ['THR_ASIA']); hold=int(os.environ['HOLD']); tp=float(os.environ['TP_EFF']); sl=float(os.environ['SL_EFF']); flt=os.environ['FILTER']; be=int(os.environ['BE']); conf=pathlib.Path(run_dir)/'conf'; conf.mkdir(parents=True, exist_ok=True); eff=conf/'config.effective.yml'; base=conf/'config.yml'; cfg={'thr_by_session':{'US':thr_us,'EU':thr_eu,'ASIA':thr_asia},'thr':thr_us,'threshold':thr_us,'tp_pct':tp,'tp':tp,'take_profit':tp,'sl_pct':sl,'sl':sl,'stop_loss':sl,'hold_bars':hold,'hold':hold,'holding_period':hold,'allow_long':True,'allow_short':True,'fees_bps_per_leg':3.0,'taker_bps':3.0,'slippage_bps':0.0,'calibration':'isotonic','beta':1.6,'temp':6.0,'__debug_tag__':'mode{}_thrUS{}_EU{}_AS{}_h{}_tp{}_sl{}_f{}_be{}'.format(mode,thr_us,thr_eu,thr_asia,hold,tp,sl,flt,be)}; text=yaml.safe_dump(cfg, sort_keys=False).encode(); open(eff,'wb').write(text); open(base,'wb').write(text); print(json.dumps({'wrote':[str(eff),str(base)],'sha256':hashlib.sha256(text).hexdigest()}))"
          SNAP="${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"
          cp -f "$RUN_DIR/conf/config.effective.yml" "$SNAP/_cfg_snapshot.yml"
          sha256sum "$RUN_DIR/conf/config.effective.yml" | awk '{print $1}' > "$SNAP/_cfg_snapshot.sha256"

      - name: Run backtest
        shell: bash
        run: |
          set -euo pipefail
          export PYTHONPATH="$RUN_DIR"
          python "$RUN_DIR/run_4u.py" --data_path "$CSV_PATH" --out_dir "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"

      # ✅ here-doc로 변경 — 다줄 파이썬 안전 주입
      - name: Enrich summary (compute PF/Win/N from trades.csv)
        shell: bash
        run: |
          set -euo pipefail
          OUT="${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"
          python - "$OUT" <<'PY'
import json, pandas as pd, numpy as np, pathlib, sys
out = pathlib.Path(sys.argv[1])
sjp = out / "summary.json"
tsp = out / "trades.csv"
# load summary
try:
    sj = json.loads(sjp.read_text(encoding="utf-8"))
except Exception:
    sj = {}
pf = hit = nt = None
if tsp.exists():
    df = pd.read_csv(tsp)
    for cand in ["pnl","ret","pnl_pct","PnL","pl","profit","strategy_return"]:
        if cand in df.columns:
            v = pd.to_numeric(df[cand], errors="coerce").dropna()
            n = len(v)
            if n > 0:
                nt  = int(n)
                hit = float((v > 0).mean())
                pos = float(v[v>0].sum())
                neg = float((-v[v<0]).sum())
                pf  = (pos/neg) if neg > 0 else (1e9 if pos > 0 else 0.0)
            break
if hit is not None: sj.setdefault("hit_rate", hit)
if pf  is not None: sj.setdefault("profit_factor", pf)
if nt  is not None: sj.setdefault("n_trades", nt)
sj.setdefault("metrics_schema_version", 1)
sjp.write_text(json.dumps(sj, ensure_ascii=False, indent=2), encoding="utf-8")
print("[enrich]", {"hit_rate": hit, "profit_factor": pf, "n_trades": nt})
PY

      - name: Inject APPLIED_CONFIG to outputs
        shell: bash
        run: |
          set -euo pipefail
          python -c "import os,json,hashlib,yaml,pathlib; run_dir=pathlib.Path(os.environ['RUN_DIR']); out_dir=pathlib.Path(os.environ['GITHUB_WORKSPACE'])/os.environ['OUT_DIR']; conf=run_dir/'conf'/'config.effective.yml'; cfg=yaml.safe_load(conf.read_text()) if conf.exists() else {}; h=hashlib.sha256((yaml.safe_dump(cfg, sort_keys=False)).encode()).hexdigest(); print('APPLIED_CONFIG:', json.dumps({'sha256':h, **cfg}, ensure_ascii=False)); import json as _j; load=lambda p: (_j.loads(p.read_text()) if p.exists() else {}); dump=lambda p,o: p.write_text(_j.dumps(o, ensure_ascii=False, indent=2)); summary=out_dir/'summary.json'; gating=out_dir/'gating_debug.json'; sj=load(summary); gj=load(gating); thr=(cfg.get('thr_by_session') or {}); (isinstance(thr,dict) and gj.setdefault('thr_by_session',thr)); [gj.setdefault(k,cfg[k]) for k in ('beta','temp') if k in cfg and k not in gj]; [sj.setdefault(dst,cfg[src]) for src,dst in [('tp_pct','tp_pct'),('tp','tp_pct'),('take_profit','tp_pct'),('sl_pct','sl_pct'),('sl','sl_pct'),('stop_loss','sl_pct'),('hold_bars','hold_bars'),('holding_period','hold_bars'),('hold','hold_bars')] if src in cfg and dst not in sj]; sj.setdefault('__config_sha256__',h); gj.setdefault('__config_sha256__',h); dump(summary,sj); dump(gating,gj)"

      - name: Verify hashes & keys
        shell: bash
        run: |
          set -euo pipefail
          OUT="${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"
          PRE_HASH="$(cat "$OUT/_cfg_snapshot.sha256")"
          POST_HASH="$(sha256sum "$RUN_DIR/conf/config.effective.yml" | awk '{print $1}')"
          echo "[hash] PRE=$PRE_HASH POST=$POST_HASH"
          [ "$PRE_HASH" = "$POST_HASH" ] || { echo "::error::override overwritten during run"; exit 71; }
          echo "[summary]"; jq -r '.tp_pct, .sl_pct, .hold_bars, .hit_rate, .profit_factor, .n_trades, .__config_sha256__' "$OUT/summary.json" || true
          echo "[gating ]"; jq -r '.thr_by_session, .beta, .temp, .__config_sha256__' "$OUT/gating_debug.json" || true

      # ✅ pinned (upload-artifact v4.6.2)
      - name: Upload artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: out_mode${{ matrix.MODE }}_thrUS${{ matrix.THR_US }}_EU${{ matrix.THR_EU }}_AS${{ matrix.THR_ASIA }}_h${{ matrix.HOLD }}_be${{ matrix.BE }}_filter${{ matrix.FILTER }}
          path: |
            ${{ env.OUT_DIR }}/summary.json
            ${{ env.OUT_DIR }}/gating_debug.json
            ${{ env.OUT_DIR }}/trades.csv
            ${{ env.OUT_DIR }}/preds_test.csv
            ${{ env.OUT_DIR }}/preflight.json
            ${{ env.OUT_DIR }}/_cfg_snapshot.yml
            ${{ env.OUT_DIR }}/_cfg_snapshot.sha256

  aggregate:
    needs: [grid]
    runs-on: ubuntu-latest
    steps:
      # ✅ pinned (download-artifact v5.0.0)
      - name: Download all artifacts
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0
        with:
          path: all_runs

      - name: Ensure jq
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y
            sudo apt-get install -y jq
          fi

      # ✅ 예상 런 수 가드
      - name: Guard: expected run count
        shell: bash
        run: |
          set -euo pipefail
          EXPECT=8
          FOUND=$(find all_runs -type f -name summary.json | wc -l | tr -d ' ')
          echo "[guard] expected=$EXPECT found=$FOUND"
          [ "$FOUND" -eq "$EXPECT" ] || { echo "::error::per-run artifacts missing"; exit 74; }

      - name: Leaderboard (PF/Win/MCC) — robust (jq + awk fallback)
        shell: bash
        run: |
          set -euo pipefail
          echo "artifact,thr_US,thr_EU,thr_ASIA,tp_pct,sl_pct,hold_bars,hit_rate,profit_factor,mcc,n_trades" > leaderboard.tmp.csv
          while IFS= read -r -d '' s; do
            dir="$(dirname "$s")"
            tag="$(basename "$dir")"
            if [[ -f "$dir/gating_debug.json" ]]; then
              thr_US="$(jq -r '.thr_by_session.US // empty' "$dir/gating_debug.json")"
              thr_EU="$(jq -r '.thr_by_session.EU // empty' "$dir/gating_debug.json")"
              thr_AS="$(jq -r '.thr_by_session.ASIA // empty' "$dir/gating_debug.json")"
            else
              thr_US=""; thr_EU=""; thr_AS=""
            fi
            tp="$(jq -r '.tp_pct // .tp // empty' "$s")"
            sl="$(jq -r '.sl_pct // .sl // empty' "$s")"
            hold="$(jq -r '.hold_bars // .holding_period // .hold // empty' "$s")"
            hit="$(jq -r '.hit_rate // .win_rate // .winrate // empty' "$s")"
            pf="$(jq -r '.profit_factor // .pf // empty' "$s")"
            mcc="$(jq -r '.mcc // .MCC // empty' "$s")"
            nt="$(jq -r '.n_trades // .trades // .trades_count // empty' "$s")"

            if [[ -z "$hit" || -z "$pf" || -z "$nt" ]]; then
              if [[ -f "$dir/trades.csv" ]]; then
                FALLBACK="$(awk -F, '
                  NR==1{
                    col=0;
                    for(i=1;i<=NF;i++){
                      h=$i; gsub(/"/,"",h);
                      if(h=="pnl" || h=="ret" || h=="pnl_pct" || h=="PnL"){ col=i }
                    }
                    next
                  }
                  col>0{
                    v=$col;
                    if(v!=""){
                      x=v+0;
                      n++;
                      if(x>0){ win++; pos+=x } else if(x<0){ neg+=-x }
                    }
                  }
                  END{
                    if(n>0){
                      if(neg>0){ pf=pos/neg } else { pf=(pos>0? 1000000000 : 0) }
                      printf("{\"hit\":%.8f,\"pf\":%.8f,\"nt\":%d}", (win/n), pf, n)
                    } else {
                      printf("{\"hit\":null,\"pf\":null,\"nt\":null}")
                    }
                  }' "$dir/trades.csv")"
                f_hit="$(echo "$FALLBACK" | jq -r '.hit // empty')"
                f_pf="$(echo "$FALLBACK" | jq -r '.pf // empty')"
                f_nt="$(echo "$FALLBACK" | jq -r '.nt // empty')"
                [[ -z "$hit" && -n "$f_hit" ]] && hit="$f_hit"
                [[ -z "$pf"  && -n "$f_pf"  ]] && pf="$f_pf"
                [[ -z "$nt"  && -n "$f_nt"  ]] && nt="$f_nt"
              fi
            fi

            echo "$tag,$thr_US,$thr_EU,$thr_AS,$tp,$sl,$hold,$hit,$pf,$mcc,$nt" >> leaderboard.tmp.csv
          done < <(find all_runs -type f -name summary.json -print0)

          { head -n 1 leaderboard.tmp.csv; tail -n +2 leaderboard.tmp.csv | sort -t, -k9,9nr -k8,8nr -k10,10nr; } > leaderboard.csv
          echo "[TOP 12]"; head -n 12 leaderboard.csv

      # ✅ pinned (upload-artifact v4.6.2)
      - name: Upload leaderboard
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: backtest12_grid_results
          path: |
            leaderboard.csv