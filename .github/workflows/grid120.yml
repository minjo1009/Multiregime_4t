name: backtest12-grid-v120

on:
  workflow_dispatch:
    inputs:
      CODE_ZIP:
        description: Repo path to code zip (at repo root)
        required: true
        default: trade_v1.2.0.zip
      DATA_ZIP:
        description: Repo path to data zip (at repo root)
        required: true
        default: ETHUSDT_1min_2020_2025.zip
      CSV_FILE:
        description: CSV filename after unzip
        required: true
        default: ETHUSDT_1min_2020_2025.csv

jobs:
  grid:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 6
    env:
      RUN_DIR: tmp/trade
      DATA_DIR: tmp/data
      OUT_BASE: _out_4u
      PYVER: '3.11'
    steps:
      # ✅ pinned (checkout v5.0.0)
      - name: "Checkout"
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8
        with:
          fetch-depth: 0

      # ✅ pinned (setup-python v5.6.0)
      - name: "Setup Python"
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ env.PYVER }}

      - name: "Resolve ZIPs"
        shell: bash
        run: |
          set -euo pipefail
          res() {
            local in="$1" out="$2" path=""
            local base="$(basename "$in")"
            if [[ -f "$in" ]]; then path="${GITHUB_WORKSPACE}/$in"
            else path="$(find "${GITHUB_WORKSPACE}" -maxdepth 2 -type f -name "$base" -print -quit || true)"; fi
            [[ -n "$path" && -f "$path" ]] || { echo "::error::ZIP not found: $in"; exit 66; }
            echo "${out}=${path}" >> "$GITHUB_ENV"; echo "[resolved] $in -> $path"
          }
          res "${{ github.event.inputs.CODE_ZIP }}" CODE_ZIP_ABS
          res "${{ github.event.inputs.DATA_ZIP }}" DATA_ZIP_ABS

      - name: "Unpack code and data"
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$RUN_DIR" "$DATA_DIR" "${GITHUB_WORKSPACE}/${{ env.OUT_BASE }}"
          unzip -q "$CODE_ZIP_ABS" -d "$RUN_DIR"
          unzip -q "$DATA_ZIP_ABS" -d "$DATA_DIR"
          if [[ ! -f "$RUN_DIR/run_4u.py" ]]; then
            CAND="$(find "$RUN_DIR" -maxdepth 3 -type f -name 'run_4u.py' -print -quit || true)"
            [[ -n "$CAND" ]] || { echo "::error::run_4u.py not found in code zip"; exit 67; }
            echo "RUN_DIR=$(dirname "$CAND")" >> "$GITHUB_ENV"
            echo "[debug] RUN_DIR -> $(dirname "$CAND")"
          fi
          echo "[debug] CSV files:"; find "$DATA_DIR" -maxdepth 2 -type f -name '*.csv' -print || true

      - name: "Install deps"
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install -U pip >/dev/null
          pip install pandas numpy pyyaml >/dev/null

      - name: "Detect CSV (ABS) + Preflight"
        shell: bash
        run: |
          set -euo pipefail
          CSV="${GITHUB_WORKSPACE}/${{ env.DATA_DIR }}/${{ github.event.inputs.CSV_FILE }}"
          if [[ ! -f "$CSV" ]]; then
            F="$(find "${{ env.DATA_DIR }}" -type f -name "${{ github.event.inputs.CSV_FILE }}" -print -quit || true)"
            [[ -n "$F" ]] || { echo "::error::CSV not found: ${{ github.event.inputs.CSV_FILE }}"; exit 64; }
            CSV="${GITHUB_WORKSPACE}/${F}"
          fi
          echo "CSV_PATH=$CSV" >> "$GITHUB_ENV"; echo "[csv] $CSV"

          cat > preflight.py <<'PY'
import os, json, pandas as pd, numpy as np
csv = os.environ['CSV_PATH']
need = ['open_time','open','high','low','close','volume']
df = pd.read_csv(csv, nrows=200000)
missing = [c for c in need if c not in df.columns]
max_ot = pd.to_numeric(df.get('open_time', pd.Series(dtype='float64')), errors='coerce').max()
hint = 'ms' if (pd.notna(max_ot) and max_ot > 1e12) else 's'
print(json.dumps({"path": csv,
                  "rows_scanned": int(len(df)),
                  "columns": list(df.columns),
                  "missing": missing,
                  "open_time_hint": hint}))
PY
          python preflight.py > "${GITHUB_WORKSPACE}/${{ env.OUT_BASE }}/preflight.json"
          cat "${GITHUB_WORKSPACE}/${{ env.OUT_BASE }}/preflight.json"
          miss=$(jq -r '.missing|length' "${GITHUB_WORKSPACE}/${{ env.OUT_BASE }}/preflight.json")
          [[ "$miss" == "0" ]] || { echo "::error::Required columns missing"; exit 65; }

      - name: "Set params & OUT_DIR (export matrix)"
        shell: bash
        run: |
          set -euo pipefail
          # matrix는 이동: strategy.include 는 아래 aggregate에서 필요 없어서 grid만 고정
          echo "MODE=pct" >> "$GITHUB_ENV"  # v120 엔진은 단순; ATR외부계산 비활성. 필요시 확장.
          # 조합 파라미터는 런 단일값으로 시작(원하면 strategy.matrix 추가)
          echo "THR_US=4.0"   >> "$GITHUB_ENV"
          echo "THR_EU=3.8"   >> "$GITHUB_ENV"
          echo "THR_ASIA=3.5" >> "$GITHUB_ENV"
          echo "HOLD=6"       >> "$GITHUB_ENV"
          echo "BE=3"         >> "$GITHUB_ENV"
          echo "FILTER=ema"   >> "$GITHUB_ENV"
          echo "TP_EFF=0.0035" >> "$GITHUB_ENV"
          echo "SL_EFF=0.0018" >> "$GITHUB_ENV"
          TAG="mode${MODE}_us${THR_US}_eu${THR_EU}_as${THR_ASIA}_h${HOLD}_be${BE}_f${FILTER}"
          echo "RUN_TAG=$TAG" >> "$GITHUB_ENV"
          echo "OUT_DIR=${{ env.OUT_BASE }}/$TAG" >> "$GITHUB_ENV"
          mkdir -p "${GITHUB_WORKSPACE}/${OUT_DIR}"
          echo "[tag] $TAG"

      - name: "Write conf/config.effective.yml (python; no heredoc)"
        shell: bash
        run: |
          set -euo pipefail
          cat > write_conf.py <<'PY'
import os, json, pathlib, yaml, hashlib
run_dir = os.environ['RUN_DIR']
cfg = {
  "thr_by_session": {
    "US": float(os.environ["THR_US"]),
    "EU": float(os.environ["THR_EU"]),
    "ASIA": float(os.environ["THR_ASIA"]),
  },
  "tp_pct": float(os.environ["TP_EFF"]),
  "sl_pct": float(os.environ["SL_EFF"]),
  "hold_bars": int(os.environ["HOLD"]),
  "allow_long": True,
  "allow_short": True,
}
p = pathlib.Path(run_dir)/"conf"/"config.effective.yml"
p.parent.mkdir(parents=True, exist_ok=True)
text = yaml.safe_dump(cfg, sort_keys=False)
p.write_text(text, encoding="utf-8")
sha = hashlib.sha256(text.encode()).hexdigest()
print(json.dumps({"wrote": str(p), "sha256": sha}))
PY
          python write_conf.py | tee _conf_write_log.json
          jq -r '.sha256' _conf_write_log.json | awk '{print "[conf] sha256="$1}'

      - name: "Run backtest (v1.2.0)"
        shell: bash
        run: |
          set -euo pipefail
          export PYTHONPATH="$RUN_DIR"
          python "$RUN_DIR/run_4u.py" --data_path "$CSV_PATH" --out_dir "${GITHUB_WORKSPACE}/${OUT_DIR}"

      - name: "Validate summary/trades (no placeholders, metrics present)"
        shell: bash
        run: |
          set -euo pipefail
          S="${GITHUB_WORKSPACE}/${OUT_DIR}/summary.json"
          T="${GITHUB_WORKSPACE}/${OUT_DIR}/trades.csv"
          test -s "$S" && test -s "$T" || { echo "::error::missing outputs"; exit 77; }
          jq -e '(.placeholders|not) and (.hit_rate!=null) and (.profit_factor!=null) and (.n_trades!=null)' "$S" >/dev/null \
            || { echo "::error::invalid summary"; cat "$S"; exit 79; }
          echo "[ok] metrics: hit_rate=$(jq -r .hit_rate "$S") pf=$(jq -r .profit_factor "$S") n=$(jq -r .n_trades "$S")"

      - name: "Upload artifacts (per-run)"
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: out_${{ env.RUN_TAG }}
          path: |
            ${{ env.OUT_DIR }}/summary.json
            ${{ env.OUT_DIR }}/trades.csv
            ${{ env.OUT_DIR }}/gating_debug.json
            ${{ env.OUT_DIR }}/_*.json
            ${{ env.OUT_DIR }}/*.log
          if-no-files-found: ignore

  aggregate:
    needs: [grid]
    runs-on: ubuntu-latest
    steps:
      - name: "Download all artifacts"
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0
        with:
          path: all_runs

      - name: "Ensure jq"
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y && sudo apt-get install -y jq
          fi

      - name: "Build leaderboard.csv"
        shell: bash
        run: |
          set -euo pipefail
          echo "artifact,thr_US,thr_EU,thr_ASIA,tp_pct,sl_pct,hold_bars,hit_rate,profit_factor,mcc,n_trades" > leaderboard.csv
          while IFS= read -r -d '' s; do
            dir="$(dirname "$s")"; tag="$(basename "$dir")"
            gj="$dir/gating_debug.json"
            if [[ -f "$gj" ]]; then
              thr_US="$(jq -r '.thr_by_session.US // empty' "$gj")"
              thr_EU="$(jq -r '.thr_by_session.EU // empty' "$gj")"
              thr_AS="$(jq -r '.thr_by_session.ASIA // empty' "$gj")"
            else
              thr_US=""; thr_EU=""; thr_AS=""
            fi
            tp="$(jq -r '.tp_pct // empty' "$s")"
            sl="$(jq -r '.sl_pct // empty' "$s")"
            hold="$(jq -r '.hold_bars // empty' "$s")"
            hit="$(jq -r '.hit_rate // empty' "$s")"
            pf="$(jq -r '.profit_factor // empty' "$s")"
            mcc="$(jq -r '.mcc // empty' "$s")"
            nt="$(jq -r '.n_trades // empty' "$s")"
            echo "$tag,$thr_US,$thr_EU,$thr_AS,$tp,$sl,$hold,$hit,$pf,$mcc,$nt" >> leaderboard.csv
          done < <(find all_runs -type f -name summary.json -print0)

          { head -n 1 leaderboard.csv; tail -n +2 leaderboard.csv | sort -t, -k9,9nr -k8,8nr -k10,10nr; } > leaderboard.sorted.csv
          echo "== Top 10 =="
          ( head -n 1 leaderboard.sorted.csv && tail -n +2 leaderboard.sorted.csv | head -n 10 ) | column -s, -t | sed 's/^/  /'

      - name: "Upload leaderboard"
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: backtest12_grid_v120_results
          path: |
            leaderboard.csv
            leaderboard.sorted.csv