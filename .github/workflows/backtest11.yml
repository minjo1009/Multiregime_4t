name: multigrid-v1.1.10

on:
  workflow_dispatch:
    inputs:
      CODE_ZIP:
        description: Repo path to code zip
        required: true
        default: trade_v1.1.9.zip
      DATA_ZIP:
        description: Repo path to data zip
        required: true
        default: ETHUSDT_1min_2020_2025.zip
      CSV_FILE:
        description: CSV filename after unzip
        required: true
        default: ETHUSDT_1min_2020_2025.csv

jobs:
  grid:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 6
      matrix:
        include:
          # === Percent 모드(고정 TP/SL) ===
          - {MODE: pct, THR_US: 4.0, THR_EU: 3.8, THR_ASIA: 3.5, HOLD: 6, BE: 3, TP: 0.0035, SL: 0.0018, FILTER: ema}
          - {MODE: pct, THR_US: 4.0, THR_EU: 3.8, THR_ASIA: 3.5, HOLD: 8, BE: 5, TP: 0.0035, SL: 0.0018, FILTER: none}
          - {MODE: pct, THR_US: 4.2, THR_EU: 3.9, THR_ASIA: 3.6, HOLD: 6, BE: 5, TP: 0.0042, SL: 0.0020, FILTER: ema}
          - {MODE: pct, THR_US: 4.2, THR_EU: 3.9, THR_ASIA: 3.6, HOLD: 8, BE: 3, TP: 0.0042, SL: 0.0020, FILTER: none}
          # === ATR 모드(ATR비율 * k1/k2 → 퍼센트로 환산) ===
          - {MODE: atr, K1: 1.2, K2: 0.7, THR_US: 4.0, THR_EU: 3.8, THR_ASIA: 3.5, HOLD: 6, BE: 3, FILTER: ema}
          - {MODE: atr, K1: 1.6, K2: 0.9, THR_US: 4.0, THR_EU: 3.8, THR_ASIA: 3.5, HOLD: 8, BE: 5, FILTER: none}
          - {MODE: atr, K1: 1.2, K2: 0.7, THR_US: 4.2, THR_EU: 3.9, THR_ASIA: 3.6, HOLD: 6, BE: 5, FILTER: ema}
          - {MODE: atr, K1: 1.6, K2: 0.9, THR_US: 4.2, THR_EU: 3.9, THR_ASIA: 3.6, HOLD: 8, BE: 3, FILTER: none}

    env:
      RUN_DIR: tmp/trade
      DATA_DIR: tmp/data
      OUT_DIR: _out_4u/run
      PYVER: '3.11'

    steps:
      - name: Checkout (pinned)
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8

      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ env.PYVER }}

      - name: Resolve ZIPs
        shell: bash
        run: |
          set -euo pipefail
          res() {
            local in="$1" out="$2" path=""
            local base="$(basename "$in")"
            if [[ -f "$in" ]]; then path="${GITHUB_WORKSPACE}/$in"
            else path="$(find "${GITHUB_WORKSPACE}" -maxdepth 2 -type f -name "$base" -print -quit || true)"
            fi
            [[ -n "$path" && -f "$path" ]] || { echo "::error::ZIP not found: $in"; exit 66; }
            echo "${out}=${path}" >> "$GITHUB_ENV"
            echo "[resolved] $in -> $path"
          }
          res "${{ github.event.inputs.CODE_ZIP }}" CODE_ZIP_ABS
          res "${{ github.event.inputs.DATA_ZIP }}" DATA_ZIP_ABS

      - name: Unpack code and data
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$RUN_DIR" "$DATA_DIR" "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"
          unzip -q "$CODE_ZIP_ABS" -d "$RUN_DIR"
          unzip -q "$DATA_ZIP_ABS" -d "$DATA_DIR"
          if [ ! -f "$RUN_DIR/run_4u.py" ]; then
            CAND="$(find "$RUN_DIR" -maxdepth 2 -type f -name 'run_4u.py' -print -quit || true)"
            [ -n "$CAND" ] || { echo "::error::run_4u.py not found in code zip"; exit 67; }
            echo "RUN_DIR=$(dirname "$CAND")" >> "$GITHUB_ENV"
            echo "[debug] RUN_DIR -> $(dirname "$CAND")"
          fi
          echo "[debug] CSV files:"; find "$DATA_DIR" -maxdepth 2 -type f -name '*.csv' -print || true

      - name: Install deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install -U pip >/dev/null
          if [ -f "$RUN_DIR/requirements.txt" ]; then
            pip install -r "$RUN_DIR/requirements.txt"
          else
            pip install pandas numpy pyyaml >/dev/null
          fi

      - name: Detect CSV (ABS)
        shell: bash
        run: |
          set -euo pipefail
          CSV="${GITHUB_WORKSPACE}/${{ env.DATA_DIR }}/${{ github.event.inputs.CSV_FILE }}"
          if [ ! -f "$CSV" ]; then
            F="$(find "${{ env.DATA_DIR }}" -type f -name "${{ github.event.inputs.CSV_FILE }}" -print -quit || true)"
            [ -n "$F" ] || { echo "::error::CSV not found: ${{ github.event.inputs.CSV_FILE }}"; exit 64; }
            CSV="${GITHUB_WORKSPACE}/${F}"
          fi
          echo "CSV_PATH=$CSV" >> "$GITHUB_ENV"
          echo "[csv] $CSV"

      - name: Preflight (schema + ATR ratio)
        shell: bash
        run: |
          set -euo pipefail
          python -c "import os,json,pandas as pd,numpy as np; csv=os.environ['CSV_PATH']; df=pd.read_csv(csv,usecols=['open_time','high','low','close'],nrows=500000); need=['open_time','open','high','low','close','volume']; miss=[c for c in need if c not in df.columns]; pc=df['close'].shift(1); import numpy as np; tr=(df['high']-df['low']).abs(); tr=np.maximum(tr, (df['high']-pc).abs()); tr=np.maximum(tr, (df['low']-pc).abs()); atr=pd.Series(tr).rolling(14,min_periods=14).mean(); ratio=float(np.nanmedian((atr/df['close']).values)); print(json.dumps({'path':csv,'rows_scanned':int(len(df)),'columns':list(df.columns),'missing':miss,'open_time_hint':'ms' if pd.to_numeric(df['open_time'],errors='coerce').max()>1e12 else 's','atr_ratio_median':ratio}))" | tee "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}/preflight.json"
          echo "ATR_RATIO=$(jq -r '.atr_ratio_median' ${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}/preflight.json)" >> "$GITHUB_ENV"

      - name: Set params from matrix (and compute ATR tp/sl if needed)
        shell: bash
        run: |
          set -euo pipefail
          echo "MODE=${{ matrix.MODE }}" >> "$GITHUB_ENV"
          echo "THR_US=${{ matrix.THR_US }}" >> "$GITHUB_ENV"
          echo "THR_EU=${{ matrix.THR_EU }}" >> "$GITHUB_ENV"
          echo "THR_ASIA=${{ matrix.THR_ASIA }}" >> "$GITHUB_ENV"
          echo "HOLD=${{ matrix.HOLD }}" >> "$GITHUB_ENV"
          echo "BE=${{ matrix.BE }}" >> "$GITHUB_ENV"
          echo "FILTER=${{ matrix.FILTER }}" >> "$GITHUB_ENV"
          if [ "${{ matrix.MODE }}" = "atr" ]; then
            ATR="${ATR_RATIO:-0.0}"
            TP_EFF=$(awk "BEGIN { print ${ATR} * ${{ matrix.K1 }} }")
            SL_EFF=$(awk "BEGIN { print ${ATR} * ${{ matrix.K2 }} }")
          else
            TP_EFF="${{ matrix.TP }}"
            SL_EFF="${{ matrix.SL }}"
          fi
          echo "TP_EFF=$TP_EFF" >> "$GITHUB_ENV"
          echo "SL_EFF=$SL_EFF" >> "$GITHUB_ENV"
          echo "[params] MODE=${{ matrix.MODE }} THR_US=${{ matrix.THR_US }} THR_EU=${{ matrix.THR_EU }} THR_ASIA=${{ matrix.THR_ASIA }} HOLD=${{ matrix.HOLD }} BE=${{ matrix.BE }} FILTER=${{ matrix.FILTER }} TP_EFF=$TP_EFF SL_EFF=$SL_EFF"

      - name: Override config (polyfill) + snapshot
        shell: bash
        run: |
          set -euo pipefail
          python -c "import os,pathlib,yaml,hashlib,json; run_dir=os.environ['RUN_DIR']; thr_us=float(os.environ['THR_US']); thr_eu=float(os.environ['THR_EU']); thr_asia=float(os.environ['THR_ASIA']); hold=int(os.environ['HOLD']); tp=float(os.environ['TP_EFF']); sl=float(os.environ['SL_EFF']); flt=os.environ['FILTER']; be=int(os.environ['BE']); conf=pathlib.Path(run_dir)/'conf'; conf.mkdir(parents=True, exist_ok=True); eff=conf/'config.effective.yml'; base=conf/'config.yml'; cfg={'thr_by_session':{'US':thr_us,'EU':thr_eu,'ASIA':thr_asia},'thr':thr_us,'threshold':thr_us,'tp_pct':tp,'tp':tp,'take_profit':tp,'sl_pct':sl,'sl':sl,'stop_loss':sl,'hold_bars':hold,'hold':hold,'holding_period':hold,'allow_long':True,'allow_short':True,'fees_bps_per_leg':3.0,'taker_bps':3.0,'slippage_bps':0.0,'calibration':'isotonic','beta':1.6,'temp':6.0,'__debug_tag__':f'mode{os.environ.get('MODE','pct')}_thrUS{thr_us}_EU{thr_eu}_AS{thr_asia}_h{hold}_tp{tp}_sl{sl}_f{flt}_be{be}'}; text=yaml.safe_dump(cfg, sort_keys=False).encode(); open(eff,'wb').write(text); open(base,'wb').write(text); print(json.dumps({'wrote':[str(eff),str(base)],'sha256':hashlib.sha256(text).hexdigest()}))"
          SNAP="${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"
          cp -f "$RUN_DIR/conf/config.effective.yml" "$SNAP/_cfg_snapshot.yml"
          sha256sum "$RUN_DIR/conf/config.effective.yml" | awk '{print $1}' > "$SNAP/_cfg_snapshot.sha256"

      - name: Run backtest
        shell: bash
        run: |
          set -euo pipefail
          export PYTHONPATH="$RUN_DIR"
          python "$RUN_DIR/run_4u.py" --data_path "$CSV_PATH" --out_dir "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"

      - name: Inject APPLIED_CONFIG to outputs
        shell: bash
        run: |
          set -euo pipefail
          python -c "import os,json,hashlib,yaml,pathlib; run_dir=pathlib.Path(os.environ['RUN_DIR']); out_dir=pathlib.Path(os.environ['GITHUB_WORKSPACE'])/os.environ['OUT_DIR']; conf=run_dir/'conf'/'config.effective.yml'; cfg=yaml.safe_load(conf.read_text()) if conf.exists() else {}; h=hashlib.sha256((yaml.safe_dump(cfg, sort_keys=False)).encode()).hexdigest(); print('APPLIED_CONFIG:', json.dumps({'sha256':h, **cfg}, ensure_ascii=False)); import json as _j; load=lambda p: (_j.loads(p.read_text()) if p.exists() else {}); dump=lambda p,o: p.write_text(_j.dumps(o, ensure_ascii=False, indent=2)); summary=out_dir/'summary.json'; gating=out_dir/'gating_debug.json'; sj=load(summary); gj=load(gating); thr=(cfg.get('thr_by_session') or {}); (isinstance(thr,dict) and gj.setdefault('thr_by_session',thr)); [gj.setdefault(k,cfg[k]) for k in ('beta','temp') if k in cfg and k not in gj]; [sj.setdefault(dst,cfg[src]) for src,dst in [('tp_pct','tp_pct'),('tp','tp_pct'),('take_profit','tp_pct'),('sl_pct','sl_pct'),('sl','sl_pct'),('stop_loss','sl_pct'),('hold_bars','hold_bars'),('holding_period','hold_bars'),('hold','hold_bars')] if src in cfg and dst not in sj]; sj.setdefault('__config_sha256__',h); gj.setdefault('__config_sha256__',h); dump(summary,sj); dump(gating,gj)"

      - name: Verify hashes & keys
        shell: bash
        run: |
          set -euo pipefail
          OUT="${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"
          PRE_HASH="$(cat "$OUT/_cfg_snapshot.sha256")"
          POST_HASH="$(sha256sum "$RUN_DIR/conf/config.effective.yml" | awk '{print $1}')"
          echo "[hash] PRE=$PRE_HASH POST=$POST_HASH"
          [ "$PRE_HASH" = "$POST_HASH" ] || { echo "::error::override overwritten during run"; exit 71; }
          echo "[summary]"; jq -r '.tp_pct, .sl_pct, .hold_bars, .__config_sha256__' "$OUT/summary.json" || true
          echo "[gating ]"; jq -r '.thr_by_session, .beta, .temp, .__config_sha256__' "$OUT/gating_debug.json" || true

      - name: Upload artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: out_mode${{ matrix.MODE }}_thrUS${{ matrix.THR_US }}_EU${{ matrix.THR_EU }}_AS${{ matrix.THR_ASIA }}_h${{ matrix.HOLD }}_be${{ matrix.BE }}_filter${{ matrix.FILTER }}
          path: |
            ${{ env.OUT_DIR }}/summary.json
            ${{ env.OUT_DIR }}/gating_debug.json
            ${{ env.OUT_DIR }}/trades.csv
            ${{ env.OUT_DIR }}/preds_test.csv
            ${{ env.OUT_DIR }}/preflight.json
            ${{ env.OUT_DIR }}/_cfg_snapshot.yml
            ${{ env.OUT_DIR }}/_cfg_snapshot.sha256

  aggregate:
    needs: [grid]
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          path: all_runs

      - name: Leaderboard (PF/Win/Params) — python -c one-liner
        shell: bash
        run: |
          set -euo pipefail
          python -c "import json,glob,pathlib,pandas as pd; rows=[]; 
from pathlib import Path
for s in glob.glob('all_runs/**/summary.json', recursive=True):
    p=Path(s); g=p.parent/'gating_debug.json'; sj=json.loads(open(s).read()); gj=json.loads(open(g).read()) if g.exists() else {}; tag=p.parent.parts[1] if len(p.parent.parts)>1 else p.parent.name; thr=(gj.get('thr_by_session') or {}); rows.append({'artifact':tag,'thr_US':thr.get('US'),'thr_EU':thr.get('EU'),'thr_ASIA':thr.get('ASIA'),'tp_pct':sj.get('tp_pct'),'sl_pct':sj.get('sl_pct'),'hold_bars':sj.get('hold_bars'),'hit_rate':sj.get('hit_rate'),'profit_factor':sj.get('profit_factor'),'mcc':sj.get('mcc'),'n_trades':sj.get('n_trades')}); 
df=pd.DataFrame(rows); 
df.sort_values(by=[c for c in ['profit_factor','hit_rate','mcc'] if c in df.columns], ascending=False, inplace=True); 
df.to_csv('leaderboard.csv', index=False); 
print(df[['artifact','profit_factor','hit_rate','mcc','n_trades']].head(12).to_string(index=False))"
          ls -l

      - name: Upload leaderboard
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: multigrid_v1.1.10_results
          path: |
            leaderboard.csv