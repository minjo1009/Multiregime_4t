name: 4t-backtest

on:
  workflow_dispatch:
    inputs:
      code_zip:
        description: 'Code pack ZIP at repo root'
        required: true
        default: 'trend4t_hotfix_pack_u3.zip'
      data_zip:
        description: 'Data ZIP at repo root (optional if CSV exists)'
        required: false
        default: 'ETHUSDT_1min_2020_2025.zip'
      data_csv:
        description: 'Data CSV name (after unzip, under data/). Leave empty to auto-detect.'
        required: false
        default: ''
      train_start:
        required: true
        default: '2025-01-01'
      train_end:
        required: true
        default: '2025-04-30'
      test_start:
        required: true
        default: '2025-05-01'
      test_end:
        required: true
        default: '2025-06-30'
      H:
        required: true
        default: '5'

permissions:
  contents: read

jobs:
  backtest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (pinned)
        uses: actions/checkout@08eba0b27e820071cde6df949e0beb9ba4906955

      - name: Setup Python 3.11 (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Show repo tree
        run: |
          set -euxo pipefail
          pwd
          ls -al

      - name: Unzip code pack
        run: |
          set -euo pipefail
          CODE_ZIP="${{ github.event.inputs.code_zip }}"
          if [ ! -f "$CODE_ZIP" ]; then
            echo "❌ Code pack [$CODE_ZIP] not found at repo root."; exit 2
          fi
          unzip -o "$CODE_ZIP" -d .
          echo "After code unzip:"
          ls -al
          # Quick import-spec check
          python - <<'PY'
          import importlib.util, sys
          for m in ("run_4t","trend4p.data_utils","trend4p.execution_4t","trend4p.labeling","trend4p.model_4t"):
              print(m, "OK" if importlib.util.find_spec(m) else "MISSING")
          PY

      - name: Install Python deps
        run: |
          set -euxo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            # Pins chosen to be compatible with scikit-learn >=1.4 (CalibratedClassifierCV(estimator=...))
            pip install "numpy>=1.25,<2.0" "pandas>=2.0,<3.0" "scikit-learn>=1.4,<1.6" "pyarrow" "tabulate"
          fi
          python -c "import sys, numpy, pandas, sklearn; print(sys.version); print('numpy', numpy.__version__); print('pandas', pandas.__version__); print('sklearn', sklearn.__version__)"

      - name: Prepare data
        run: |
          set -euxo pipefail
          mkdir -p data
          DATA_ZIP="${{ github.event.inputs.data_zip }}"
          DATA_CSV_INPUT="${{ github.event.inputs.data_csv }}"

          # If a data ZIP exists at repo root, unzip to data/
          if [ -n "$DATA_CSV_INPUT" ]; then
            echo "CSV override requested: $DATA_CSV_INPUT"
          fi

          if [ -n "$DATA_ZIP" ] && [ -f "$DATA_ZIP" ]; then
            echo "Unzipping data ZIP: $DATA_ZIP -> data/"
            unzip -o "$DATA_ZIP" -d data
          else
            echo "No data ZIP found (this is OK if CSV already present)."
          fi

          # If CSV is at repo root, move to data/
          if [ -n "$DATA_CSV_INPUT" ] && [ -f "$DATA_CSV_INPUT" ] && [ ! -f "data/$DATA_CSV_INPUT" ]; then
            mv "$DATA_CSV_INPUT" "data/$DATA_CSV_INPUT"
          fi

          echo "data/ listing:"
          ls -al data || true

          # Resolve CSV path (override > pattern > single CSV)
          python - <<'PY'
          import os, glob, sys, json
          data_dir = "data"
          os.makedirs(data_dir, exist_ok=True)
          csv_input = os.environ.get("DATA_CSV_INPUT","").strip()
          resolved = None

          if csv_input:
            cand = os.path.join(data_dir, csv_input)
            if os.path.exists(cand):
              resolved = cand
            else:
              # try to find by basename anywhere under data/
              matches = glob.glob(os.path.join(data_dir, "**", os.path.basename(csv_input)), recursive=True)
              if matches:
                resolved = matches[0]
          if not resolved:
            # try common ETH 1min patterns
            pats = [
              os.path.join(data_dir, "*ETH*1min*.csv"),
              os.path.join(data_dir, "*ETHUSDT*1min*.csv"),
              os.path.join(data_dir, "*.csv"),
            ]
            for p in pats:
              m = glob.glob(p)
              if m:
                resolved = m[0]; break

          if not resolved or not os.path.exists(resolved):
            print("❌ Could not resolve CSV under data/."); sys.exit(3)

          # Emit path for next steps
          print("RESOLVED_CSV:", resolved)
          open("_resolved_csv.txt","w").write(resolved)
          PY
        env:
          DATA_CSV_INPUT: ${{ github.event.inputs.data_csv }}

      - name: Quick CSV sanity check
        run: |
          set -euxo pipefail
          CSV_PATH="$(cat _resolved_csv.txt)"
          python - <<'PY'
          import os, pandas as pd
          csv_path = open("_resolved_csv.txt").read().strip()
          print("CSV_PATH:", csv_path, "exists:", os.path.exists(csv_path))
          df = pd.read_csv(csv_path, nrows=10)
          print("HEADERS:", list(df.columns))
          print(df.head(3).to_string(index=False))
          PY

      - name: Run backtest (never hard-fail; write fallback summary on error)
        shell: bash
        run: |
          set +e
          OUT_DIR="_out_4t/github"
          mkdir -p "$OUT_DIR"
          CSV_PATH="$(cat _resolved_csv.txt)"

          python run_4t.py \
            --data "$CSV_PATH" \
            --train_start "${{ github.event.inputs.train_start }}" \
            --train_end   "${{ github.event.inputs.train_end }}" \
            --test_start  "${{ github.event.inputs.test_start }}" \
            --test_end    "${{ github.event.inputs.test_end }}" \
            --H ${{ github.event.inputs.H }} \
            --out_dir "$OUT_DIR" | tee "$OUT_DIR/run.log"
          rc=$?
          echo "python exit code: $rc"

          if [ $rc -ne 0 ]; then
            echo "Backtest non-zero exit. Writing fallback summary JSON to keep artifacts."
            python - <<'PY'
            import json, os, time, pathlib
            out = pathlib.Path("_out_4t/github/train_test_summary_fallback.json")
            out.parent.mkdir(parents=True, exist_ok=True)
            json.dump({"status":"failed","msg":"exception in run_4t.py","ts":time.time()}, open(out,"w"))
            print("Wrote", out)
            PY
          fi

          # Always exit 0 so the artifact step runs
          exit 0

      - name: Upload artifacts (always)
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: backtest_outputs
          path: |
            _out_4t/github/**
            **/train_test_summary*.json
            **/logs/**
          if-no-files-found: warn
