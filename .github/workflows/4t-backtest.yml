name: 4t-backtest

on:
  workflow_dispatch:
    inputs:
      train_start: { description: "YYYY-MM-DD", default: "2025-01-01", required: true }
      train_end:   { description: "YYYY-MM-DD", default: "2025-04-30", required: true }
      test_start:  { description: "YYYY-MM-DD", default: "2025-05-01", required: true }
      test_end:    { description: "YYYY-MM-DD", default: "2025-06-30", required: true }
      horizon:     { description: "Forecast horizon H", default: "5", required: true }
      out_dir:     { description: "Output dir", default: "_out_4t/github", required: true }

jobs:
  backtest:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: read

    steps:
      # 0) 필수 액션들 — 반드시 풀 SHA로 핀 고정해야 통과됨.
      - name: Checkout
        # actions/checkout@v4 풀 SHA로 교체
        uses: actions/checkout@REPLACE_WITH_CHECKOUT_SHA

      # (선택) 캐시 — 풀 SHA 정책이면 이것도 SHA 필요. 미사용으로 두면 됨.
      # - name: Setup cache (optional)
      #   uses: actions/cache@REPLACE_WITH_CACHE_SHA
      #   with:
      #     path: ~/.cache/pip
      #     key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
      #     restore-keys: |
      #       ${{ runner.os }}-pip-

      # 1) 시스템 파이썬 사용(액션 없이). venv 구성
      - name: Show Python
        run: |
          python3 -V
          which python3
      - name: Create venv
        run: |
          python3 -m venv .venv
          source .venv/bin/activate
          python -V
          pip -V

      # 2) 루트의 두 개 zip 찾기 (코드팩/데이터)
      - name: Locate zips
        id: findzips
        shell: bash
        run: |
          set -euo pipefail
          echo "Repo root listing:"
          ls -alh

          # 코드팩: trend4t_hotfix_pack_u3.zip (정확 파일명)
          CODE_ZIP="trend4t_hotfix_pack_u3.zip"
          if [[ ! -f "$CODE_ZIP" ]]; then
            echo "❌ Code pack zip not found: $CODE_ZIP"
            exit 2
          fi
          echo "code_zip=$CODE_ZIP" >> $GITHUB_OUTPUT

          # 데이터 ZIP: 루트에 있는 *ETH*1min* 혹은 ETHUSDT_1min_2020_2025.zip 등 탐색
          DATA_ZIP="$(ls -1 *.zip | grep -iE '(eth|usdt).*1min' | head -n1 || true)"
          if [[ -z "${DATA_ZIP:-}" ]]; then
            echo "❌ Data zip not found (expect something like ETHUSDT_1min_2020_2025.zip)"
            exit 3
          fi
          echo "data_zip=$DATA_ZIP" >> $GITHUB_OUTPUT
          echo "Found data zip: $DATA_ZIP"

      # 3) 코드팩 해제
      - name: Unzip code pack
        run: |
          set -euo pipefail
          unzip -o "${{ steps.findzips.outputs.code_zip }}" -d .
          echo "Top-level after unzip:"
          ls -alh
          echo "Tree (first 2 levels):"
          find . -maxdepth 2 -type d -print

      # 4) 데이터 해제 → data/ 로 정리
      - name: Prepare data
        run: |
          set -euo pipefail
          mkdir -p data
          unzip -o "${{ steps.findzips.outputs.data_zip }}" -d data || true
          # ZIP 내부에 CSV가 바로 있지 않고 폴더가 있을 수 있으므로 가장 큰 1분 CSV 찾기
          CSV_PATH="$(find data -maxdepth 3 -type f -iname '*1min*.csv' -o -iname '*1_min*.csv' | head -n1 || true)"
          if [[ -z "${CSV_PATH:-}" ]]; then
            # 혹시 루트에 CSV가 들어있었다면 그걸 data로 이동
            CSV_PATH="$(ls -1 *.csv 2>/dev/null | head -n1 || true)"
            if [[ -n "${CSV_PATH:-}" ]]; then
              mv "$CSV_PATH" "data/"
              CSV_PATH="data/$(basename "$CSV_PATH")"
            fi
          fi
          if [[ -z "${CSV_PATH:-}" ]]; then
            echo "❌ Could not find 1min CSV after unzip."
            echo "data/ listing:"
            ls -alh data || true
            exit 4
          fi

          # 실행 스크립트들이 기대하는 이름으로 통일
          TARGET="data/ETHUSDT_1min_2020_2025.csv"
          mv -f "$CSV_PATH" "$TARGET"
          echo "csv_path=$TARGET" >> $GITHUB_OUTPUT
          echo "✅ CSV ready at $TARGET"

      # 5) requirements 설치 (zip에 동봉되어 있으면 우선 사용, 없으면 안전 기본셋 생성)
      - name: Install deps
        run: |
          set -euo pipefail
          source .venv/bin/activate
          REQS=""
          # 코드팩 최상단 or trend4p/ 하위 탐색
          if [[ -f "requirements.txt" ]]; then
            REQS="requirements.txt"
          elif [[ -f "trend4p/requirements.txt" ]]; then
            REQS="trend4p/requirements.txt"
          else
            cat > requirements.txt <<'TXT'
          numpy
          pandas
          scikit-learn==1.5.1
          scipy
          pyarrow
          matplotlib
          TXT
            REQS="requirements.txt"
          fi
          echo "Using requirements: $REQS"
          pip install --upgrade pip
          pip install -r "$REQS"

      # 6) 핫픽스(오류 재현 방지): 열 이름/NaN 라벨/ts 파싱/CalibratedClassifier 파라미터 등 자동 패치
      - name: Apply hotfixes
        shell: bash
        run: |
          set -euo pipefail

          # 6-1) data_utils.py: 시간컬럼 open_time → ts, pandas 경고 옵션 정리
          if [[ -f trend4p/data_utils.py ]]; then
            python - <<'PY'
import io,sys,re,os,json,pathlib
p=pathlib.Path("trend4p/data_utils.py")
s=p.read_text(encoding="utf-8")
# open_time 을 ts로 매핑
s=re.sub(r'pd\.to_datetime\([^)]*\)', "pd.to_datetime(df['open_time'], utc=True, errors='coerce')", s) if 'open_time' in s else s
# 혹시 ts 컬럼 만드는 부분이 없다면 주입
if "df['ts']" not in s:
    s = "import pandas as pd\n" + s
p.write_text(s, encoding="utf-8")
print("patched:", p)
PY
          fi

          # 6-2) labeling.py: NaN → 0 후 int 캐스팅 (IntCastingNaNError 방지)
          if [[ -f trend4p/labeling.py ]]; then
            python - <<'PY'
import pathlib,re
p=pathlib.Path("trend4p/labeling.py")
s=p.read_text(encoding="utf-8")
s=re.sub(r"return\s+y\.astype\(int\)",
         "y=y.fillna(0)\n    return y.astype(int)", s)
p.write_text(s, encoding="utf-8")
print("patched:", p)
PY
          fi

          # 6-3) model_4t.py: CalibratedClassifierCV(base_estimator=...) → estimator=... (sklearn>=1.4)
          if [[ -f trend4p/model_4t.py ]]; then
            python - <<'PY'
import pathlib,re
p=pathlib.Path("trend4p/model_4t.py")
s=p.read_text(encoding="utf-8")
s=s.replace("CalibratedClassifierCV(base_estimator=",
            "CalibratedClassifierCV(estimator=")
p.write_text(s, encoding="utf-8")
print("patched:", p)
PY
          fi

      # 7) 사전 점검(헤더/타임스팬/NaN 비율)
      - name: Preflight check
        run: |
          set -euo pipefail
          source .venv/bin/activate
          python - <<'PY'
import pandas as pd, json, sys
csv="data/ETHUSDT_1min_2020_2025.csv"
df=pd.read_csv(csv, nrows=1000)
cols=list(df.columns)
need={'open_time','open','high','low','close'}
missing=sorted(list(need-set(c.lower() for c in cols)))
print(json.dumps({
  "head_cols": cols[:10],
  "need_missing": missing
}, ensure_ascii=False, indent=2))
PY

      # 8) 백테스트 실행
      - name: Run backtest
        env:
          OUT_DIR: ${{ inputs.out_dir }}
        run: |
          set -euxo pipefail
          source .venv/bin/activate
          mkdir -p "$OUT_DIR"
          # PYTHONPATH에 현재 리포 추가
          export PYTHONPATH=$PWD:$PYTHONPATH

          # run_4t.py 존재 위치에 맞춰 실행 (루트 배치 가정)
          python run_4t.py \
            --data data/ETHUSDT_1min_2020_2025.csv \
            --train_start "${{ inputs.train_start }}" \
            --train_end   "${{ inputs.train_end }}" \
            --test_start  "${{ inputs.test_start }}" \
            --test_end    "${{ inputs.test_end }}" \
            --H "${{ inputs.horizon }}" \
            --out_dir "${{ inputs.out_dir }}" | tee "${{ inputs.out_dir }}/stdout.jsonl"

      # 9) 산출물 없더라도 로그는 올리기
      - name: Upload results
        if: always()
        # actions/upload-artifact@v4 풀 SHA로 교체
        uses: actions/upload-artifact@REPLACE_WITH_UPLOAD_ARTIFACT_SHA
        with:
          name: bt_${{ github.run_id }}
          path: |
            _out_4t/github/**
            **/train_test_summary*.json
            **/logs/**
            **/*.log
          if-no-files-found: warn
