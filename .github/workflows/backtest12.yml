name: backtest12

on:
  workflow_dispatch:
    inputs:
      CODE_ZIP:
        description: Repo path to code zip
        required: true
        default: trade_v1.1.9.zip
      DATA_ZIP:
        description: Repo path to data zip
        required: true
        default: ETHUSDT_1min_2020_2025.zip
      CSV_FILE:
        description: CSV filename after unzip
        required: true
        default: ETHUSDT_1min_2020_2025.csv

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      RUN_DIR: tmp/trade
      DATA_DIR: tmp/data
      OUT_DIR: _out_4u/run
      PYVER: '3.11'
      # ==== 전략 V1 기본 파라미터(필요 시 수정) ====
      THR_US: '4.1'
      THR_EU: '3.9'
      THR_ASIA: '3.6'
      HOLD: '6'
      TP: '0.0038'
      SL: '0.0020'
      FILTER: 'ema'
      BE: '5'

    steps:
      - name: Checkout (pinned)
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8

      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ env.PYVER }}

      - name: Resolve ZIPs
        shell: bash
        run: |
          set -euo pipefail
          res() { local in="$1" out="$2" path=""; local base="$(basename "$in")"; if [[ -f "$in" ]]; then path="${GITHUB_WORKSPACE}/$in"; else path="$(find "${GITHUB_WORKSPACE}" -maxdepth 2 -type f -name "$base" -print -quit || true)"; fi; [[ -n "$path" && -f "$path" ]] || { echo "::error::ZIP not found: $in"; exit 66; }; echo "${out}=${path}" >> "$GITHUB_ENV"; echo "[resolved] $in -> $path"; }
          res "${{ github.event.inputs.CODE_ZIP }}" CODE_ZIP_ABS
          res "${{ github.event.inputs.DATA_ZIP }}" DATA_ZIP_ABS

      - name: Unpack code and data
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$RUN_DIR" "$DATA_DIR" "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"
          unzip -q "$CODE_ZIP_ABS" -d "$RUN_DIR"
          unzip -q "$DATA_ZIP_ABS" -d "$DATA_DIR"
          if [ ! -f "$RUN_DIR/run_4u.py" ]; then CAND="$(find "$RUN_DIR" -maxdepth 2 -type f -name 'run_4u.py' -print -quit || true)"; [ -n "$CAND" ] || { echo "::error::run_4u.py not found in code zip"; exit 67; }; echo "RUN_DIR=$(dirname "$CAND")" >> "$GITHUB_ENV"; echo "[debug] RUN_DIR -> $(dirname "$CAND")"; fi
          echo "[debug] CSV files:"; find "$DATA_DIR" -maxdepth 2 -type f -name '*.csv' -print || true

      - name: Install deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install -U pip >/dev/null
          if [ -f "$RUN_DIR/requirements.txt" ]; then pip install -r "$RUN_DIR/requirements.txt"; else pip install pandas numpy pyyaml >/dev/null; fi

      - name: Detect CSV (ABS)
        shell: bash
        run: |
          set -euo pipefail
          CSV="${GITHUB_WORKSPACE}/${{ env.DATA_DIR }}/${{ github.event.inputs.CSV_FILE }}"
          if [ ! -f "$CSV" ]; then F="$(find "${{ env.DATA_DIR }}" -type f -name "${{ github.event.inputs.CSV_FILE }}" -print -quit || true)"; [ -n "$F" ] || { echo "::error::CSV not found: ${{ github.event.inputs.CSV_FILE }}"; exit 64; }; CSV="${GITHUB_WORKSPACE}/${F}"; fi
          echo "CSV_PATH=$CSV" >> "$GITHUB_ENV"
          echo "[csv] $CSV"

      - name: Preflight (schema/tz/missing)
        shell: bash
        run: |
          set -euo pipefail
          python -c "import os,json,pandas as pd; csv=os.environ['CSV_PATH']; df=pd.read_csv(csv, nrows=10000); need=['open_time','open','high','low','close','volume']; miss=[c for c in need if c not in df.columns]; m=pd.to_numeric(df['open_time'], errors='coerce').max() if 'open_time' in df.columns else -1; hint='ms' if (m is not None and m>1e12) else 's'; print(json.dumps({'path':csv,'rows_scanned':int(len(df)),'columns':list(df.columns),'missing':miss,'open_time_hint':hint}))" | tee "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}/preflight.json"

      - name: Override config (polyfill) + snapshot
        shell: bash
        run: |
          set -euo pipefail
          python -c "import os,pathlib,yaml,hashlib,json; run_dir=os.environ['RUN_DIR']; thr_us=float(os.environ['THR_US']); thr_eu=float(os.environ['THR_EU']); thr_asia=float(os.environ['THR_ASIA']); hold=int(os.environ['HOLD']); tp=float(os.environ['TP']); sl=float(os.environ['SL']); flt=os.environ['FILTER']; be=int(os.environ['BE']); conf=pathlib.Path(run_dir)/'conf'; conf.mkdir(parents=True, exist_ok=True); eff=conf/'config.effective.yml'; base=conf/'config.yml'; cfg={'thr_by_session':{'US':thr_us,'EU':thr_eu,'ASIA':thr_asia},'thr':thr_us,'threshold':thr_us,'tp_pct':tp,'tp':tp,'take_profit':tp,'sl_pct':sl,'sl':sl,'stop_loss':sl,'hold_bars':hold,'hold':hold,'holding_period':hold,'allow_long':True,'allow_short':True,'fees_bps_per_leg':3.0,'taker_bps':3.0,'slippage_bps':0.0,'calibration':'isotonic','beta':1.6,'temp':6.0,'__debug_tag__':'thrUS{}_EU{}_AS{}_h{}_tp{}_sl{}_f{}_be{}'.format(thr_us,thr_eu,thr_asia,hold,tp,sl,flt,be)}; text=yaml.safe_dump(cfg, sort_keys=False).encode(); open(eff,'wb').write(text); open(base,'wb').write(text); print(json.dumps({'wrote':[str(eff),str(base)],'sha256':hashlib.sha256(text).hexdigest()}))"
          SNAP="${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"
          cp -f "$RUN_DIR/conf/config.effective.yml" "$SNAP/_cfg_snapshot.yml"
          sha256sum "$RUN_DIR/conf/config.effective.yml" | awk '{print $1}' > "$SNAP/_cfg_snapshot.sha256"

      - name: Run backtest
        shell: bash
        run: |
          set -euo pipefail
          export PYTHONPATH="$RUN_DIR"
          python "$RUN_DIR/run_4u.py" --data_path "$CSV_PATH" --out_dir "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"

      - name: Inject APPLIED_CONFIG to outputs
        shell: bash
        run: |
          set -euo pipefail
          python -c "import os,json,hashlib,yaml,pathlib; run_dir=pathlib.Path(os.environ['RUN_DIR']); out_dir=pathlib.Path(os.environ['GITHUB_WORKSPACE'])/os.environ['OUT_DIR']; conf=run_dir/'conf'/'config.effective.yml'; cfg=yaml.safe_load(conf.read_text()) if conf.exists() else {}; h=hashlib.sha256((yaml.safe_dump(cfg, sort_keys=False)).encode()).hexdigest(); print('APPLIED_CONFIG:', json.dumps({'sha256':h, **cfg}, ensure_ascii=False)); import json as _j; load=lambda p: (_j.loads(p.read_text()) if p.exists() else {}); dump=lambda p,o: p.write_text(_j.dumps(o, ensure_ascii=False, indent=2)); summary=out_dir/'summary.json'; gating=out_dir/'gating_debug.json'; sj=load(summary); gj=load(gating); thr=(cfg.get('thr_by_session') or {}); (isinstance(thr,dict) and gj.setdefault('thr_by_session',thr)); [gj.setdefault(k,cfg[k]) for k in ('beta','temp') if k in cfg and k not in gj]; [sj.setdefault(dst,cfg[src]) for src,dst in [('tp_pct','tp_pct'),('tp','tp_pct'),('take_profit','tp_pct'),('sl_pct','sl_pct'),('sl','sl_pct'),('stop_loss','sl_pct'),('hold_bars','hold_bars'),('holding_period','hold_bars'),('hold','hold_bars')] if src in cfg and dst not in sj]; sj.setdefault('__config_sha256__',h); gj.setdefault('__config_sha256__',h); dump(summary,sj); dump(gating,gj)"
          ls -l "${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"

      - name: Verify hashes & keys
        shell: bash
        run: |
          set -euo pipefail
          OUT="${GITHUB_WORKSPACE}/${{ env.OUT_DIR }}"
          PRE_HASH="$(cat "$OUT/_cfg_snapshot.sha256")"
          POST_HASH="$(sha256sum "$RUN_DIR/conf/config.effective.yml" | awk '{print $1}')"
          echo "[hash] PRE=$PRE_HASH POST=$POST_HASH"
          [ "$PRE_HASH" = "$POST_HASH" ] || { echo "::error::override overwritten during run"; exit 71; }
          echo "[summary]"; jq -r '.tp_pct, .sl_pct, .hold_bars, .__config_sha256__' "$OUT/summary.json" || true
          echo "[gating ]"; jq -r '.thr_by_session, .beta, .temp, .__config_sha256__' "$OUT/gating_debug.json" || true

      - name: Upload artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: out_single_run
          path: |
            ${{ env.OUT_DIR }}/summary.json
            ${{ env.OUT_DIR }}/gating_debug.json
            ${{ env.OUT_DIR }}/trades.csv
            ${{ env.OUT_DIR }}/preds_test.csv
            ${{ env.OUT_DIR }}/preflight.json
            ${{ env.OUT_DIR }}/_cfg_snapshot.yml
            ${{ env.OUT_DIR }}/_cfg_snapshot.sha256

  aggregate:
    needs: [run]
    runs-on: ubuntu-latest
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          path: all_runs

      - name: Leaderboard (PF/Win/MCC) — single line
        shell: bash
        run: |
          set -euo pipefail
          python -c "import json,glob; from pathlib import Path; import pandas as pd; rows=[]; import os; files=glob.glob('all_runs/**/summary.json', recursive=True); 
[rows.append((lambda p,sj,gj,tag: {'artifact':tag,'thr_US':(gj.get('thr_by_session') or {}).get('US'),'thr_EU':(gj.get('thr_by_session') or {}).get('EU'),'thr_ASIA':(gj.get('thr_by_session') or {}).get('ASIA'),'tp_pct':sj.get('tp_pct'),'sl_pct':sj.get('sl_pct'),'hold_bars':sj.get('hold_bars'),'hit_rate':sj.get('hit_rate'),'profit_factor':sj.get('profit_factor'),'mcc':sj.get('mcc'),'n_trades':sj.get('n_trades')})(Path(s).parent, json.loads(open(s,'r').read()), (json.loads(open((Path(s).parent/'gating_debug.json'),'r').read()) if (Path(s).parent/'gating_debug.json').exists() else {}), (Path(s).parent.parts[1] if len(Path(s).parent.parts)>1 else Path(s).parent.name))) for s in files]; df=pd.DataFrame(rows); 
df.sort_values(by=[c for c in ['profit_factor','hit_rate','mcc'] if c in df.columns], ascending=False, inplace=True); df.to_csv('leaderboard.csv', index=False); print(df[['artifact','profit_factor','hit_rate','mcc','n_trades']].head(12).to_string(index=False))"
          ls -l

      - name: Upload leaderboard
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: backtest12_results
          path: |
            leaderboard.csv