name: WFO_Session_Local

on:
  workflow_dispatch:
    inputs:
      CODE_ZIP_PATH:
        description: "Path to code zip in repo"
        required: false
        default: "strategy_v2_codepack_v2.1.3.zip"
        type: string
      DATA_ZIP_PATH:
        description: "Path to data zip in repo"
        required: false
        default: "ETHUSDT_1min_2020_2025.zip"
        type: string
      CSV_GLOB:
        description: "CSV glob pattern inside data zip"
        required: false
        default: "**/*ETHUSDT*1min*2020*2025*.csv"
        type: string
      FEES_BPS:
        description: "Trading fee in bps (e.g., 7.5)"
        required: false
        default: "7.5"
        type: string
      CHAMPION_CONFIG:
        description: "Champion config string"
        required: false
        default: "grid_p0.83_tp2.2_sl0.45_cd34_mh12_ofi0.42_thi0.74"
        type: string
      SPLITS:
        description: "Number of WFO splits"
        required: false
        default: "4"
        type: string
      TZ:
        description: "IANA timezone for session split"
        required: false
        default: "Asia/Seoul"
        type: string
      ENTRYPOINT:
        description: "Python path to run (e.g., work/code/run.py). Leave 'auto' to autodetect."
        required: false
        default: "auto"
        type: string

jobs:
  validate_shas:
    runs-on: ubuntu-latest
    env:
      CHECKOUT_SHA: "08c6903cd8c0fde910a37f88322edcfb5dd907a8"
      SETUP_PYTHON_SHA: "a26af69be951a213d495a4c3e4e4022e16d87065"
      UPLOAD_ARTIFACT_SHA: "ea165f8d65b6e75b540449e92b4886f43607fa02"
    steps:
      - name: Validate pinned SHAs exist
        run: |
          set -euo pipefail
          echo "[PIN] validating SHAs by fetching commits..."
          mkdir -p _pincheck && cd _pincheck
          git -c init.defaultBranch=main init checkout && cd checkout
          git fetch --depth 1 https://github.com/actions/checkout "${CHECKOUT_SHA}"
          [ "$(git cat-file -t "${CHECKOUT_SHA}")" = "commit" ] || { echo "::error::checkout SHA not a commit"; exit 2; }
          cd ..
          git -c init.defaultBranch=main init setup_python && cd setup_python
          git fetch --depth 1 https://github.com/actions/setup-python "${SETUP_PYTHON_SHA}"
          [ "$(git cat-file -t "${SETUP_PYTHON_SHA}")" = "commit" ] || { echo "::error::setup-python SHA not a commit"; exit 2; }
          cd ..
          git -c init.defaultBranch=main init upload_artifact && cd upload_artifact
          git fetch --depth 1 https://github.com/actions/upload-artifact "${UPLOAD_ARTIFACT_SHA}"
          [ "$(git cat-file -t "${UPLOAD_ARTIFACT_SHA}")" = "commit" ] || { echo "::error::upload-artifact SHA not a commit"; exit 2; }
          cd ..
          echo "[PIN] ok"

  single_run:
    needs: validate_shas
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (pinned)
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8
      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: "3.11"
      - name: Install base deps
        run: |
          set -euo pipefail
          python -V
          pip install --upgrade pip
          pip install pandas numpy scikit-learn pyyaml pytz
      - name: Prepare workspace from repo files
        run: |
          set -euo pipefail
          WORK=work
          mkdir -p "${WORK}/code" "${WORK}/data" "${WORK}/out/single" "_out_4u/run" "_out_4u/logs"
          cp -f "${{ inputs.CODE_ZIP_PATH }}" "${WORK}/code.zip"
          cp -f "${{ inputs.DATA_ZIP_PATH }}" "${WORK}/data.zip"
          unzip -q "${WORK}/code.zip" -d "${WORK}/code"
          unzip -q "${WORK}/data.zip" -d "${WORK}/data"
          echo "[TREE] work/code:"
          find work/code -maxdepth 3 -type f | sort | sed 's/^/  /'
      - name: Write preflight to work/
        run: |
          set -euo pipefail
          mkdir -p work
          {
            echo 'import os,sys,glob,json'
            echo 'import pandas as pd'
            echo 'def find_csv(root,patt):'
            echo '  g=glob.glob(os.path.join(root,patt),recursive=True)'
            echo '  if not g: raise SystemExit("CSVDetect: no csv")'
            echo '  return g[0]'
            echo 'def read_df(path):'
            echo '  df=pd.read_csv(path)'
            echo '  cols={"open_time","open","high","low","close","volume"}'
            echo '  if not cols.issubset(df.columns):'
            echo '    raise SystemExit("Preflight: missing columns")'
            echo '  ot=df["open_time"]'
            echo '  try:'
            echo '    if pd.api.types.is_numeric_dtype(ot):'
            echo '      dt=pd.to_datetime(ot,unit="ms",utc=True)'
            echo '    else:'
            echo '      dt=pd.to_datetime(ot,utc=True)'
            echo '  except Exception:'
            echo '    dt=pd.to_datetime(ot,utc=True,errors="coerce")'
            echo '  df["dt_utc"]=dt'
            echo '  return df'
            echo 'def write_cfg(path,data_path,fee_bps,champion):'
            echo '  os.makedirs(os.path.dirname(path),exist_ok=True)'
            echo '  with open(path,"w") as f:'
            echo '    f.write("data_path: \"" + data_path + "\"\n")'
            echo '    f.write("fee_bps: " + str(fee_bps) + "\n")'
            echo '    f.write("champion_config: \"" + champion + "\"\n")'
            echo 'if __name__=="__main__":'
            echo '  root_csv="work/data"'
            echo '  patt=os.environ.get("CSV_GLOB","**/*.csv")'
            echo '  fee=os.environ.get("FEES_BPS","7.5")'
            echo '  tz=os.environ.get("TZ","Asia/Seoul")'
            echo '  champion=os.environ.get("CHAMPION_CONFIG","")'
            echo '  out_csv="work/input.csv"'
            echo '  p=find_csv(root_csv,patt)'
            echo '  df=read_df(p)'
            echo '  df.to_csv(out_csv,index=False)'
            echo '  write_cfg("conf/config.effective.yml",out_csv,fee,champion)'
          } > work/preflight_strict.py
      - name: Single run
        run: |
          set -euo pipefail
          export CSV_GLOB="${{ inputs.CSV_GLOB }}"
          export FEES_BPS="${{ inputs.FEES_BPS }}"
          export TZ="${{ inputs.TZ }}"
          export CHAMPION_CONFIG="${{ inputs.CHAMPION_CONFIG }}"
          python work/preflight_strict.py || { echo "::error::Preflight failed"; exit 3; }
          EP_INPUT="${{ inputs.ENTRYPOINT }}"
          if [ "$EP_INPUT" != "auto" ]; then
            EP="$EP_INPUT"
          else
            EP=""
            [ -f work/code/run_4u.py ] && EP="work/code/run_4u.py"
            [ -z "$EP" ] && [ -f work/code/backtest/run_4u.py ] && EP="work/code/backtest/run_4u.py"
            [ -z "$EP" ] && [ -f work/code/run.py ] && EP="work/code/run.py"
            [ -z "$EP" ] && [ -f work/code/backtest/runner.py ] && EP="work/code/backtest/runner.py"
          fi
          echo "[RUN] entrypoint=$EP"
          if [ -n "$EP" ]; then
            set +e
            PYTHONPATH=work/code:work/code/src:work/code/src/trend4u python "$EP" > _out_4u/logs/single_stdout.txt 2> _out_4u/logs/single_stderr.txt
            RC=$?
            set -e
            echo "[RUN] rc=$RC"
          else
            echo "::warning::No entrypoint found; skipping run"
          fi
          mkdir -p _out_4u/run work/out/single
          [ -f summary.json ] && cp summary.json work/out/single/ || echo "{}" > work/out/single/summary.json
          [ -f gating_debug.json ] && cp gating_debug.json work/out/single/ || echo "{}" > work/out/single/gating_debug.json
          [ -f preds_test.csv ] && cp preds_test.csv work/out/single/ || printf "" > work/out/single/preds_test.csv
          [ -f trades.csv ] && cp trades.csv work/out/single/ || printf "" > work/out/single/trades.csv
          [ -f summary_cost.json ] && cp summary_cost.json work/out/single/ || true
      - name: Zip single & logs
        run: |
          set -euo pipefail
          cd work/out
          zip -qr ../single_results.zip single
          cd ../..
          zip -qr work/logs_single.zip _out_4u/logs
      - name: Upload artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: single_results
          path: |
            work/single_results.zip
            work/logs_single.zip
          if-no-files-found: warn

  # wfo & sessions jobs remain as before (auto-detect entrypoint only, or allow overriding similarly as above)
