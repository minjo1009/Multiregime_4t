name: WFO_Session_Local

on:
  workflow_dispatch:
    inputs:
      CODE_ZIP_PATH:
        description: "Path to code zip in repo"
        required: false
        default: "strategy_v2_codepack_v2.1.3.zip"
        type: string
      DATA_ZIP_PATH:
        description: "Path to data zip in repo"
        required: false
        default: "ETHUSDT_1min_2020_2025.zip"
        type: string
      CSV_GLOB:
        description: "CSV glob pattern inside data zip"
        required: false
        default: "**/*ETHUSDT*1min*2020*2025*.csv"
        type: string
      FEES_BPS:
        description: "Trading fee in bps (e.g., 7.5)"
        required: false
        default: "7.5"
        type: string
      CHAMPION_CONFIG:
        description: "Champion config string"
        required: false
        default: "grid_p0.83_tp2.2_sl0.45_cd34_mh12_ofi0.42_thi0.74"
        type: string
      SPLITS:
        description: "Number of WFO splits"
        required: false
        default: "4"
        type: string
      TZ:
        description: "IANA timezone for session split"
        required: false
        default: "Asia/Seoul"
        type: string
      ENTRYPOINT:
        description: "Python path to run (e.g., work/code/run.py). Leave 'auto' to autodetect."
        required: false
        default: "auto"
        type: string
      ENTRY_ARGS:
        description: "Extra CLI args for ENTRYPOINT (e.g., --config conf/config.effective.yml)"
        required: false
        default: ""
        type: string

jobs:
  validate_shas:
    runs-on: ubuntu-latest
    env:
      CHECKOUT_SHA: "08c6903cd8c0fde910a37f88322edcfb5dd907a8"
      SETUP_PYTHON_SHA: "a26af69be951a213d495a4c3e4e4022e16d87065"
      UPLOAD_ARTIFACT_SHA: "ea165f8d65b6e75b540449e92b4886f43607fa02"
    steps:
      - name: Validate pinned SHAs exist
        run: |
          set -euo pipefail
          echo "[PIN] validating SHAs by fetching commits..."
          mkdir -p _pincheck && cd _pincheck
          git -c init.defaultBranch=main init checkout && cd checkout
          git fetch --depth 1 https://github.com/actions/checkout "${ env.CHECKOUT_SHA }"
          [ "$(git cat-file -t "${ env.CHECKOUT_SHA }")" = "commit" ] || { echo "::error::checkout SHA not a commit"; exit 2; }
          cd ..
          git -c init.defaultBranch=main init setup_python && cd setup_python
          git fetch --depth 1 https://github.com/actions/setup-python "${ env.SETUP_PYTHON_SHA }"
          [ "$(git cat-file -t "${ env.SETUP_PYTHON_SHA }")" = "commit" ] || { echo "::error::setup-python SHA not a commit"; exit 2; }
          cd ..
          git -c init.defaultBranch=main init upload_artifact && cd upload_artifact
          git fetch --depth 1 https://github.com/actions/upload-artifact "${ env.UPLOAD_ARTIFACT_SHA }"
          [ "$(git cat-file -t "${ env.UPLOAD_ARTIFACT_SHA }")" = "commit" ] || { echo "::error::upload-artifact SHA not a commit"; exit 2; }
          cd ..
          echo "[PIN] ok"

  single_run:
    needs: validate_shas
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (pinned)
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8
      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: "3.11"
      - name: Install base deps
        run: |
          set -euo pipefail
          python -V
          pip install --upgrade pip
          pip install pandas numpy scikit-learn pyyaml pytz
      - name: Prepare workspace
        run: |
          set -euo pipefail
          WORK=work
          mkdir -p "${ env.WORK }/code" "${ env.WORK }/data" "${ env.WORK }/out/single" "_out_4u/run" "_out_4u/logs"
          cp -f "${ inputs.CODE_ZIP_PATH }" "${ env.WORK }/code.zip"
          cp -f "${ inputs.DATA_ZIP_PATH }" "${ env.WORK }/data.zip"
          unzip -q "${ env.WORK }/code.zip" -d "${ env.WORK }/code"
          unzip -q "${ env.WORK }/data.zip" -d "${ env.WORK }/data"
          echo "[TREE] work/code:"
          find work/code -maxdepth 3 -type f | sort | sed 's/^/  /'
      - name: Write preflight (safe echo)
        run: |
          set -euo pipefail
          mkdir -p work conf
          {
            echo 'import os,sys,glob,json'
            echo 'import pandas as pd'
            echo 'import pathlib'
            echo 'def find_csv(root,patt):'
            echo '  g=glob.glob(os.path.join(root,patt),recursive=True)'
            echo '  if not g: raise SystemExit("CSVDetect: no csv")'
            echo '  return g[0]'
            echo 'def read_df(path):'
            echo '  df=pd.read_csv(path)'
            echo '  req={"open_time","open","high","low","close","volume"}'
            echo '  if not req.issubset(df.columns): raise SystemExit("Preflight: missing columns")'
            echo '  ot=df["open_time"]'
            echo '  try:'
            echo '    dt=pd.to_datetime(ot,unit="ms",utc=True) if pd.api.types.is_numeric_dtype(ot) else pd.to_datetime(ot,utc=True)'
            echo '  except Exception:'
            echo '    dt=pd.to_datetime(ot,utc=True,errors="coerce")'
            echo '  df["dt_utc"]=dt'
            echo '  return df'
            echo 'def write_cfg(path,data_path,fee_bps,champion):'
            echo '  os.makedirs(os.path.dirname(path),exist_ok=True)'
            echo '  with open(path,"w") as f:'
            echo '    f.write("data_path: \"" + data_path + "\"\n")'
            echo '    f.write("fee_bps: " + str(fee_bps) + "\n")'
            echo '    f.write("champion_config: \"" + champion + "\"\n")'
            echo 'if __name__=="__main__":'
            echo '  root="work/data"'
            echo '  patt=os.environ.get("CSV_GLOB","**/*.csv")'
            echo '  fee=os.environ.get("FEES_BPS","7.5")'
            echo '  champ=os.environ.get("CHAMPION_CONFIG","")'
            echo '  csv=find_csv(root,patt)'
            echo '  df=read_df(csv)'
            echo '  out_csv="work/input.csv"'
            echo '  df.to_csv(out_csv,index=False)'
            echo '  pathlib.Path("conf").mkdir(parents=True,exist_ok=True)'
            echo '  with open("conf/config.effective.yml","w") as f:'
            echo '    f.write(f"data_path: '{out_csv}\\n")'
            echo '    f.write(f"fee_bps: {fee}\\n")'
            echo '    f.write(f"champion_config: '{champ}'\\n")'
            echo '  print("[PREFLIGHT] csv:", csv, "rows:", len(df))'
          } > work/preflight_strict.py
      - name: Run (with ENTRYPOINT/ARGS)
        run: |
          set -euo pipefail
          EP_INPUT="${ inputs.ENTRYPOINT }"
          ARGS="${ inputs.ENTRY_ARGS }"
          if [ "$EP_INPUT" = "auto" ]; then
            EP=""
            [ -f work/code/run_4u.py ] && EP="work/code/run_4u.py"
            [ -z "$EP" ] && [ -f work/code/backtest/run_4u.py ] && EP="work/code/backtest/run_4u.py"
            [ -z "$EP" ] && [ -f work/code/run.py ] && EP="work/code/run.py"
            [ -z "$EP" ] && [ -f work/code/backtest/runner.py ] && EP="work/code/backtest/runner.py"
          else
            EP="$EP_INPUT"
          fi
          echo "[RUN] entrypoint=$EP args=$ARGS"
          if [ -n "$EP" ]; then
            set +e
            PYTHONPATH=work/code:work/code/src:work/code/src/trend4u python "$EP" $ARGS > _out_4u/logs/single_stdout.txt 2> _out_4u/logs/single_stderr.txt
            RC=$?
            set -e
            echo "[RUN] rc=$RC"
          else
            echo "::warning::No entrypoint; skipping run"
          fi
      - name: Harvest outputs (recursive)
        run: |
          set -euo pipefail
          mkdir -p work/out/single
          for name in summary_cost.json summary.json gating_debug.json; do
            hit="$(find . -type f -name "$name" | head -n 1 || true)"
            if [ -n "$hit" ]; then
              echo "[HARVEST] $name <- $hit"
              cp -f "$hit" "work/out/single/$name"
            fi
          done
          hit="$(find . -type f -name 'trades.csv' | head -n 1 || true)"; [ -n "$hit" ] && cp -f "$hit" work/out/single/trades.csv || true
          hit="$(find . -type f -name 'preds_test.csv' | head -n 1 || true)"; [ -n "$hit" ] && cp -f "$hit" work/out/single/preds_test.csv || true
          [ -f work/out/single/summary.json ] || echo "{}" > work/out/single/summary.json
          [ -f work/out/single/gating_debug.json ] || echo "{}" > work/out/single/gating_debug.json
          [ -f work/out/single/trades.csv ] || printf "" > work/out/single/trades.csv
          [ -f work/out/single/preds_test.csv ] || printf "" > work/out/single/preds_test.csv
      - name: Zip artifacts
        run: |
          set -euo pipefail
          cd work/out && zip -qr ../single_results.zip single && cd ../..
          zip -qr work/logs_single.zip _out_4u/logs
          zip -qr work/debug_workspace.zip work
      - name: Upload artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: single_results
          path: |
            work/single_results.zip
            work/logs_single.zip
            work/debug_workspace.zip
          if-no-files-found: warn
