name: WFO_Session_Local

on:
  workflow_dispatch:
    inputs:
      CODE_ZIP_PATH:
        description: "Path to code zip in repo"
        required: false
        default: "strategy_v2_codepack_v2.1.3.zip"
        type: string
      DATA_ZIP_PATH:
        description: "Path to data zip in repo"
        required: false
        default: "ETHUSDT_1min_2020_2025.zip"
        type: string
      CSV_GLOB:
        description: "CSV glob pattern inside data zip"
        required: false
        default: "**/*ETHUSDT*1min*2020*2025*.csv"
        type: string
      FEES_BPS:
        description: "Trading fee in bps (e.g., 7.5)"
        required: false
        default: "7.5"
        type: string
      CHAMPION_CONFIG:
        description: "Champion config string"
        required: false
        default: "grid_p0.83_tp2.2_sl0.45_cd34_mh12_ofi0.42_thi0.74"
        type: string
      SPLITS:
        description: "Number of WFO splits"
        required: false
        default: "4"
        type: string
      TZ:
        description: "IANA timezone for session split"
        required: false
        default: "Asia/Seoul"
        type: string
      ENTRYPOINT:
        description: "Python path to run (e.g., work/code/run.py). Leave 'auto' to autodetect."
        required: false
        default: "auto"
        type: string
      ENTRY_ARGS:
        description: "Extra CLI args for ENTRYPOINT (e.g., --config conf/config.effective.yml)"
        required: false
        default: ""
        type: string

jobs:
  validate_shas:
    runs-on: ubuntu-latest
    env:
      CHECKOUT_SHA: "08c6903cd8c0fde910a37f88322edcfb5dd907a8"
      SETUP_PYTHON_SHA: "a26af69be951a213d495a4c3e4e4022e16d87065"
      UPLOAD_ARTIFACT_SHA: "ea165f8d65b6e75b540449e92b4886f43607fa02"
    steps:
      - name: Validate pinned SHAs exist
        run: |
          set -euo pipefail
          echo "[PIN] validating SHAs by fetching commits..."
          mkdir -p _pincheck && cd _pincheck
          git -c init.defaultBranch=main init checkout && cd checkout
          git fetch --depth 1 https://github.com/actions/checkout "${CHECKOUT_SHA}"
          [ "$(git cat-file -t "${CHECKOUT_SHA}")" = "commit" ] || { echo "::error::checkout SHA not a commit"; exit 2; }
          cd ..
          git -c init.defaultBranch=main init setup_python && cd setup_python
          git fetch --depth 1 https://github.com/actions/setup-python "${SETUP_PYTHON_SHA}"
          [ "$(git cat-file -t "${SETUP_PYTHON_SHA}")" = "commit" ] || { echo "::error::setup-python SHA not a commit"; exit 2; }
          cd ..
          git -c init.defaultBranch=main init upload_artifact && cd upload_artifact
          git fetch --depth 1 https://github.com/actions/upload-artifact "${UPLOAD_ARTIFACT_SHA}"
          [ "$(git cat-file -t "${UPLOAD_ARTIFACT_SHA}")" = "commit" ] || { echo "::error::upload-artifact SHA not a commit"; exit 2; }
          cd ..
          echo "[PIN] ok"

  single_run:
    needs: validate_shas
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (pinned)
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8
      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: "3.11"
      - name: Install base deps
        run: |
          set -euo pipefail
          python -V
          pip install --upgrade pip
          pip install pandas numpy scikit-learn pyyaml pytz
      - name: Prepare workspace
        run: |
          set -euo pipefail
          WORK=work
          mkdir -p "${WORK}/code" "${WORK}/data" "${WORK}/out/single" "_out_4u/run" "_out_4u/logs"
          cp -f "${{ inputs.CODE_ZIP_PATH }}" "${WORK}/code.zip"
          cp -f "${{ inputs.DATA_ZIP_PATH }}" "${WORK}/data.zip"
          unzip -q "${WORK}/code.zip" -d "${WORK}/code"
          unzip -q "${WORK}/data.zip" -d "${WORK}/data"
          echo "[TREE] work/code:"
          find work/code -maxdepth 3 -type f | sort | sed 's/^/  /'
      - name: Preflight
        run: |
          set -euo pipefail
          python - <<'PY'
import os,sys,glob,json,pandas as pd, pathlib
def find_csv(root,patt):
  g=glob.glob(os.path.join(root,patt),recursive=True)
  if not g: raise SystemExit("CSVDetect: no csv")
  return g[0]
def read_df(path):
  df=pd.read_csv(path)
  req={"open_time","open","high","low","close","volume"}
  if not req.issubset(df.columns): raise SystemExit("Preflight: missing columns")
  ot=df["open_time"]
  try:
    dt=pd.to_datetime(ot,unit="ms",utc=True) if pd.api.types.is_numeric_dtype(ot) else pd.to_datetime(ot,utc=True)
  except Exception:
    dt=pd.to_datetime(ot,utc=True,errors="coerce")
  df["dt_utc"]=dt
  return df
root="work/data"; patt=os.environ.get("CSV_GLOB","**/*.csv")
fee=os.environ.get("FEES_BPS","7.5"); champ=os.environ.get("CHAMPION_CONFIG","")
csv=find_csv(root,patt); df=read_df(csv)
out_csv="work/input.csv"; df.to_csv(out_csv,index=False)
pathlib.Path("conf").mkdir(parents=True,exist_ok=True)
open("conf/config.effective.yml","w").write(f"data_path: '{out_csv}'\nfee_bps: {fee}\nchampion_config: '{champ}'\n")
print("[PREFLIGHT] csv:", csv, "rows:", len(df))
PY
      - name: Run (with ENTRYPOINT/ARGS)
        run: |
          set -euo pipefail
          EP_INPUT="${{ inputs.ENTRYPOINT }}"
          ARGS="${{ inputs.ENTRY_ARGS }}"
          if [ "$EP_INPUT" = "auto" ]; then
            EP=""
            [ -f work/code/run_4u.py ] && EP="work/code/run_4u.py"
            [ -z "$EP" ] && [ -f work/code/backtest/run_4u.py ] && EP="work/code/backtest/run_4u.py"
            [ -z "$EP" ] && [ -f work/code/run.py ] && EP="work/code/run.py"
            [ -z "$EP" ] && [ -f work/code/backtest/runner.py ] && EP="work/code/backtest/runner.py"
          else
            EP="$EP_INPUT"
          fi
          echo "[RUN] entrypoint=$EP args=$ARGS"
          if [ -n "$EP" ]; then
            set +e
            PYTHONPATH=work/code:work/code/src:work/code/src/trend4u python "$EP" $ARGS > _out_4u/logs/single_stdout.txt 2> _out_4u/logs/single_stderr.txt
            RC=$?
            set -e
            echo "[RUN] rc=$RC"
          else
            echo "::warning::No entrypoint; skipping run"
          fi
      - name: Harvest outputs (recursive)
        run: |
          set -euo pipefail
          mkdir -p work/out/single
          # Copy best-effort files if found anywhere under repo
          for name in summary_cost.json summary.json gating_debug.json; do
            hit="$(find . -type f -name "$name" | head -n 1 || true)"
            if [ -n "$hit" ]; then
              echo "[HARVEST] $name <- $hit"
              cp -f "$hit" "work/out/single/$name"
            fi
          done
          # trades/preds (allow any prefix)
          hit="$(find . -type f -name 'trades.csv' | head -n 1 || true)"; [ -n "$hit" ] && cp -f "$hit" work/out/single/trades.csv || true
          hit="$(find . -type f -name 'preds_test.csv' | head -n 1 || true)"; [ -n "$hit" ] && cp -f "$hit" work/out/single/preds_test.csv || true
          # If still nothing, create placeholders
          [ -f work/out/single/summary.json ] || echo "{}" > work/out/single/summary.json
          [ -f work/out/single/gating_debug.json ] || echo "{}" > work/out/single/gating_debug.json
          [ -f work/out/single/trades.csv ] || printf "" > work/out/single/trades.csv
          [ -f work/out/single/preds_test.csv ] || printf "" > work/out/single/preds_test.csv
      - name: Zip artifacts
        run: |
          set -euo pipefail
          cd work/out && zip -qr ../single_results.zip single && cd ../..
          zip -qr work/logs_single.zip _out_4u/logs
          zip -qr work/debug_workspace.zip work
      - name: Upload artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: single_results
          path: |
            work/single_results.zip
            work/logs_single.zip
            work/debug_workspace.zip
          if-no-files-found: warn
