name: WFO All-in-One V2.1.3 (hardened-harvest)

on:
  workflow_dispatch:
    inputs:
      PARAMS_FILE:
        description: "params path (dot preferred, fallback underscore)"
        required: false
        default: "conf/params.v2.yml"
      DATA_ZIP:
        description: "data zip at repo root (optional)"
        required: false
        default: "ETHUSDT_1min_2020_2025.zip"
      CSV_GLOB:
        description: "csv glob override (if no zip)"
        required: false
        default: "**/*ETHUSDT*1min*2020*2025*.csv"
      ENTRYPOINTS:
        description: "python entrypoints (| separated)"
        required: false
        default: "run_4u.py|backtest/run_4u.py|run.py|backtest/runner.py"
      PY_VERSION:
        description: "python version"
        required: false
        default: "3.11"
      RUN_SINGLE:
        description: "also run single baseline? (true/false)"
        required: false
        default: "true"
      GRID_THR:
        description: "override thr list (comma)"
        required: false
        default: ""
      GRID_HOLD:
        description: "override hold list (comma)"
        required: false
        default: ""
      GRID_FILTER:
        description: "override filter list (comma)"
        required: false
        default: ""
      BUNDLE_NAME:
        description: "final single zip name (no .zip)"
        required: false
        default: "WFO_results_all"

jobs:
  prep:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.mk.outputs.matrix }}
      csv_glob: ${{ steps.mk.outputs.csv_glob }}
      params_used: ${{ steps.params_out.outputs.PF }}
    steps:
      - name: Checkout (pinned)
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8
      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ github.event.inputs.PY_VERSION }}
      - name: Deps
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install pandas numpy pyyaml
      - name: Resolve params (dot -> underscore fallback)
        id: params_out
        run: |
          set -euo pipefail
          PF="${{ github.event.inputs.PARAMS_FILE }}"
          if [ ! -f "$PF" ] && [ "$PF" = "conf/params.v2.yml" ] && [ -f "conf/params_v2.yml" ]; then
            PF="conf/params_v2.yml"
          fi
          if [ ! -f "$PF" ]; then
            echo "Error: params file not found (conf/params.v2.yml or conf/params_v2.yml)"; exit 3
          fi
          echo "PF=$PF" >> "$GITHUB_OUTPUT"
      - name: Build matrix (+ overrides)
        id: mk
        env:
          PF: ${{ steps.params_out.outputs.PF }}
          CSV_GLOB_IN: ${{ github.event.inputs.CSV_GLOB }}
          GRID_THR: ${{ github.event.inputs.GRID_THR }}
          GRID_HOLD: ${{ github.event.inputs.GRID_HOLD }}
          GRID_FILTER: ${{ github.event.inputs.GRID_FILTER }}
        run: |
          set -euo pipefail
          : > _mk.py
          echo "import os,yaml,json" >> _mk.py
          echo "pf=os.environ['PF']" >> _mk.py
          echo "p=yaml.safe_load(open(pf,'r',encoding='utf-8'))" >> _mk.py
          echo "csvg=os.environ.get('CSV_GLOB_IN') or p.get('csv_glob','**/*.csv')" >> _mk.py
          echo "thr=(p.get('gate',{}) or {}).get('thr',[3.2,3.8])" >> _mk.py
          echo "hold=p.get('hold',[6,8])" >> _mk.py
          echo "filt=p.get('filter',['ema','none'])" >> _mk.py
          echo "def ov(env,cur,cast=float):" >> _mk.py
          echo "  v=os.environ.get(env,'').strip()" >> _mk.py
          echo "  if not v: return cur" >> _mk.py
          echo "  xs=[t.strip() for t in v.split(',') if t.strip()]" >> _mk.py
          echo "  if env!='GRID_FILTER':" >> _mk.py
          echo "    try: xs=[cast(x) for x in xs]" >> _mk.py
          echo "    except Exception: pass" >> _mk.py
          echo "  return xs or cur" >> _mk.py
          echo "thr=ov('GRID_THR',thr,float)" >> _mk.py
          echo "hold=ov('GRID_HOLD',hold,int)" >> _mk.py
          echo "filt=ov('GRID_FILTER',filt,str)" >> _mk.py
          echo "open('matrix.json','w',encoding='utf-8').write(json.dumps({'thr':thr,'hold':hold,'filter':filt}))" >> _mk.py
          echo "open('csv_glob.txt','w',encoding='utf-8').write(str(csvg))" >> _mk.py
          python _mk.py
          echo "matrix=$(cat matrix.json)" >> "$GITHUB_OUTPUT"
          echo "csv_glob=$(cat csv_glob.txt)" >> "$GITHUB_OUTPUT"

  single:
    if: ${{ github.event.inputs.RUN_SINGLE == 'true' }}
    needs: prep
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (pinned)
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8
      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ github.event.inputs.PY_VERSION }}
      - name: Deps
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install pandas numpy pyyaml
      - name: Unzip data if present
        run: |
          set -euo pipefail
          if [ -f "${{ github.event.inputs.DATA_ZIP }}" ]; then unzip -o "${{ github.event.inputs.DATA_ZIP }}" || true; fi
      - name: Preflight (auto-detect new/legacy)
        run: |
          set -euo pipefail
          PFS=""
          if [ -f "ci/preflight_strict.py" ]; then
            PFS="ci/preflight_strict.py"
          elif [ -f "preflight_strict.py" ]; then
            PFS="preflight_strict.py"
          fi
          if [ -n "${PFS}" ]; then
            if grep -q -- "--data-root" "${PFS}"; then
              mkdir -p _preflight_out
              python "${PFS}" \
                --data-root "${GITHUB_WORKSPACE}" \
                --csv-glob "${{ needs.prep.outputs.csv_glob }}" \
                --outdir "_preflight_out"
            else
              python "${PFS}" "${{ needs.prep.outputs.csv_glob }}"
            fi
          else
            : > _pre.py
            echo "import sys,glob,pandas as pd" >> _pre.py
            echo "g=sys.argv[1]" >> _pre.py
            echo "paths=glob.glob(g,recursive=True)" >> _pre.py
            echo "assert paths, f'No CSV found by glob: {g}'" >> _pre.py
            echo "df=pd.read_csv(paths[0],nrows=5)" >> _pre.py
            echo "req=['open_time','open','high','low','close','volume']" >> _pre.py
            echo "miss=[c for c in req if c not in df.columns]" >> _pre.py
            echo "assert not miss, f'Missing columns: {miss} in {paths[0]}'" >> _pre.py
            python _pre.py "${{ needs.prep.outputs.csv_glob }}"
          fi
      - name: Run single (entrypoint scan)
        env:
          ENTRYPOINTS: ${{ github.event.inputs.ENTRYPOINTS }}
        run: |
          set -euo pipefail
          IFS='|' read -ra EPS <<< "${ENTRYPOINTS}"
          found=0
          for ep in "${EPS[@]}"; do
            if [ -f "$ep" ]; then
              set +e
              python "$ep"
              rc=$?
              set -e
              if [ $rc -eq 0 ]; then found=1; break; fi
            fi
          done
          if [ $found -eq 0 ]; then echo "Warning: no entrypoint succeeded" >&2; fi
      - name: HARVEST single -> standardize & zip
        env:
          PF: ${{ needs.prep.outputs.params_used }}
        run: |
          set -euo pipefail
          OUT="out_single"
          rm -rf "$OUT"; mkdir -p "$OUT"
          fcopy() {
            pat="$1"; dst="$2"
            set +e
            X=$(find . -type f -iname "$pat" ! -path "./$OUT/*" | head -n1)
            set -e
            if [ -n "$X" ]; then
              if [ -f "$OUT/$dst" ] && [ "$X" -ef "$OUT/$dst" ]; then
                :
              else
                cp -f "$X" "$OUT/$dst" 2>/dev/null || true
              fi
            fi
          }
          fcopy "trades.csv" "trades.csv"
          fcopy "*trade*.csv" "trades.csv"
          fcopy "summary.json" "summary.json"
          fcopy "*summary*.json" "summary.json"
          fcopy "preds_test.csv" "preds_test.csv"
          fcopy "*pred*.csv" "preds_test.csv"
          fcopy "gating_debug.json" "gating_debug.json"
          fcopy "*gating*.json" "gating_debug.json"
          [ -f "$OUT/summary.json" ] || echo "{}" > "$OUT/summary.json"
          [ -f "$OUT/gating_debug.json" ] || echo "{}" > "$OUT/gating_debug.json"
          [ -f "$OUT/preds_test.csv" ] || echo "empty" > "$OUT/preds_test.csv"
          [ -f "$OUT/trades.csv" ] || echo "empty" > "$OUT/trades.csv"
          echo "{\"run\":\"single\",\"ts\":\"$(date -Iseconds)\"}" > "$OUT/manifest.json"
          [ -f "$PF" ] && cp -f "$PF" "$OUT/params_used.yml" || true
          ( cd "$OUT" && zip -rq ../bundle_single.zip . )
      - name: Upload bundle_single.zip
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: bundle_single
          path: bundle_single.zip
          if-no-files-found: warn

  wfo:
    needs: prep
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 4
      matrix: ${{ fromJson(needs.prep.outputs.matrix) }}
    steps:
      - name: Checkout (pinned)
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8
      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: ${{ github.event.inputs.PY_VERSION }}
      - name: Deps
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install pandas numpy pyyaml
      - name: Unzip data if present
        run: |
          set -euo pipefail
          if [ -f "${{ github.event.inputs.DATA_ZIP }}" ]; then unzip -o "${{ github.event.inputs.DATA_ZIP }}" || true; fi
      - name: Preflight (auto-detect new/legacy)
        run: |
          set -euo pipefail
          PFS=""
          if [ -f "ci/preflight_strict.py" ]; then
            PFS="ci/preflight_strict.py"
          elif [ -f "preflight_strict.py" ]; then
            PFS="preflight_strict.py"
          fi
          if [ -n "${PFS}" ]; then
            if grep -q -- "--data-root" "${PFS}"; then
              mkdir -p _preflight_out
              python "${PFS}" \
                --data-root "${GITHUB_WORKSPACE}" \
                --csv-glob "${{ needs.prep.outputs.csv_glob }}" \
                --outdir "_preflight_out"
            else
              python "${PFS}" "${{ needs.prep.outputs.csv_glob }}"
            fi
          else
            : > _pre.py
            echo "import sys,glob,pandas as pd" >> _pre.py
            echo "g=sys.argv[1]" >> _pre.py
            echo "paths=glob.glob(g,recursive=True)" >> _pre.py
            echo "assert paths, f'No CSV found by glob: {g}'" >> _pre.py
            echo "df=pd.read_csv(paths[0],nrows=5)" >> _pre.py
            echo "req=['open_time','open','high','low','close','volume']" >> _pre.py
            echo "miss=[c for c in req if c not in df.columns]" >> _pre.py
            echo "assert not miss, f'Missing columns: {miss} in {paths[0]}'" >> _pre.py
            python _pre.py "${{ needs.prep.outputs.csv_glob }}"
          fi
      - name: Run WFO member
        env:
          THR: ${{ matrix.thr }}
          HOLD: ${{ matrix.hold }}
          FILTER: ${{ matrix.filter }}
          ENTRYPOINTS: ${{ github.event.inputs.ENTRYPOINTS }}
        run: |
          set -euo pipefail
          IFS='|' read -ra EPS <<< "${ENTRYPOINTS}"
          found=0
          for ep in "${EPS[@]}"; do
            if [ -f "$ep" ]; then
              set +e
              python "$ep"
              rc=$?
              set -e
              if [ $rc -eq 0 ]; then found=1; break; fi
            fi
          done
          if [ $found -eq 0 ]; then echo "Warning: no entrypoint succeeded" >&2; fi
      - name: HARVEST WFO -> standardize & zip
        env:
          THR: ${{ matrix.thr }}
          HOLD: ${{ matrix.hold }}
          FILTER: ${{ matrix.filter }}
          PF: ${{ needs.prep.outputs.params_used }}
        run: |
          set -euo pipefail
          OUT="out_${THR}_${HOLD}_${FILTER}"
          rm -rf "$OUT"; mkdir -p "$OUT"
          fcopy() {
            pat="$1"; dst="$2"
            set +e
            X=$(find . -type f -iname "$pat" ! -path "./$OUT/*" | head -n1)
            set -e
            if [ -n "$X" ]; then
              if [ -f "$OUT/$dst" ] && [ "$X" -ef "$OUT/$dst" ]; then
                :
              else
                cp -f "$X" "$OUT/$dst" 2>/dev/null || true
              fi
            fi
          }
          fcopy "trades.csv" "trades.csv"
          fcopy "*trade*.csv" "trades.csv"
          fcopy "summary.json" "summary.json"
          fcopy "*summary*.json" "summary.json"
          fcopy "preds_test.csv" "preds_test.csv"
          fcopy "*pred*.csv" "preds_test.csv"
          fcopy "gating_debug.json" "gating_debug.json"
          fcopy "*gating*.json" "gating_debug.json"
          [ -f "$OUT/summary.json" ] || echo "{}" > "$OUT/summary.json"
          [ -f "$OUT/gating_debug.json" ] || echo "{}" > "$OUT/gating_debug.json"
          [ -f "$OUT/preds_test.csv" ] || echo "empty" > "$OUT/preds_test.csv"
          [ -f "$OUT/trades.csv" ] || echo "empty" > "$OUT/trades.csv"
          echo "{\"thr\":$THR,\"hold\":$HOLD,\"filter\":\"$FILTER\",\"ts\":\"$(date -Iseconds)\"}" > "$OUT/manifest.json"
          [ -f "$PF" ] && cp -f "$PF" "$OUT/params_used.yml" || true
          ( cd "$OUT" && zip -rq "../bundle_${THR}_${HOLD}_${FILTER}.zip" . )
      - name: Upload WFO bundle
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: bundle_${{ matrix.thr }}_${{ matrix.hold }}_${{ matrix.filter }}
          path: bundle_${{ matrix.thr }}_${{ matrix.hold }}_${{ matrix.filter }}.zip
          if-no-files-found: warn

  finalize:
    needs: [wfo]
    runs-on: ubuntu-latest
    steps:
      - name: Setup Python (pinned)
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: "3.11"
      - name: Deps (finalize aggregation)
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install pandas numpy
      - name: Download all artifacts (pinned)
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0
        with:
          path: all_artifacts
      - name: Debug list (tree + sizes)
        run: |
          set -euo pipefail
          echo "==== all_artifacts tree ===="
          ls -R all_artifacts || true
          echo "============================"
          echo "ZIP files found:"
          find all_artifacts -type f -name "*.zip" -printf "%p (%k KB)\n" | sort || true
      - name: Aggregate & Pack FINAL ZIP
        env:
          BND: ${{ github.event.inputs.BUNDLE_NAME }}
        run: |
          set -euo pipefail
          : > _agg.py
          echo "import os,zipfile,glob,json,math" >> _agg.py
          echo "import pandas as pd" >> _agg.py
          echo "import numpy as np" >> _agg.py
          echo "ROOT='all_artifacts'" >> _agg.py
          echo "bundles=glob.glob(os.path.join(ROOT,'**','*.zip'),recursive=True)" >> _agg.py
          echo "std_dirs=[]" >> _agg.py
          echo "for d in glob.glob(os.path.join(ROOT,'**'),recursive=True):" >> _agg.py
          echo "  if os.path.isdir(d):" >> _agg.py
          echo "    need=['trades.csv','summary.json','preds_test.csv','gating_debug.json']" >> _agg.py
          echo "    if all(os.path.exists(os.path.join(d,f)) for f in need): std_dirs.append(d)" >> _agg.py
          echo "os.makedirs('final_pack',exist_ok=True)" >> _agg.py
          echo "rows=[]" >> _agg.py
          echo "def safe_read_csv(p):" >> _agg.py
          echo "  try: return pd.read_csv(p)" >> _agg.py
          echo "  except: return pd.DataFrame()" >> _agg.py
          echo "def compute_trade_metrics(df):" >> _agg.py
          echo "  n=len(df); r={'n_trades':n}" >> _agg.py
          echo "  if n==0: r.update({'win_rate':np.nan,'cum_pnl':0.0,'avg_pnl':np.nan,'median_pnl':np.nan}); return r" >> _agg.py
          echo "  pnl_col=None" >> _agg.py
          echo "  for c in ['pnl_close_based','pnl','pnl_value','pnl_usd','pnl_krw','pnl_pct','pnl_percent']:" >> _agg.py
          echo "    if c in df.columns: pnl_col=c; break" >> _agg.py
          echo "  if pnl_col is None: r.update({'win_rate':np.nan,'cum_pnl':np.nan,'avg_pnl':np.nan,'median_pnl':np.nan}); return r" >> _agg.py
          echo "  pnl=pd.to_numeric(df[pnl_col],errors='coerce').fillna(0.0)" >> _agg.py
          echo "  r['cum_pnl']=float(pnl.sum()); r['avg_pnl']=float(pnl.mean()); r['median_pnl']=float(pnl.median());" >> _agg.py
          echo "  r['win_rate']=float((pnl>0).sum())/max(n,1); return r" >> _agg.py
          echo "def compute_mcc(df):" >> _agg.py
          echo "  if df is None or df.empty: return {}" >> _agg.py
          echo "  m={c.lower():c for c in df.columns}" >> _agg.py
          echo "  yt=next((m[k] for k in ['y_true','true','label','target'] if k in m),None)" >> _agg.py
          echo "  yp=next((m[k] for k in ['y_pred','pred','prediction','pred_label'] if k in m),None)" >> _agg.py
          echo "  if not yt or not yp: return {}" >> _agg.py
          echo "  Yt=df[yt].values; Yp=df[yp].values" >> _agg.py
          echo "  if df[yp].dtype.kind in 'f': Yp=(Yp>=0.5).astype(int)" >> _agg.py
          echo "  tp=int(((Yt==1)&(Yp==1)).sum()); tn=int(((Yt==0)&(Yp==0)).sum())" >> _agg.py
          echo "  fp=int(((Yt==0)&(Yp==1)).sum()); fn=int(((Yt==1)&(Yp==0)).sum())" >> _agg.py
          echo "  den=(tp+fp)*(tp+fn)*(tn+fp)*(tn+fn); den=math.sqrt(den) if den else 0" >> _agg.py
          echo "  mcc=(tp*tn - fp*fn)/den if den else float('nan')" >> _agg.py
          echo "  return {'mcc':float(mcc),'tp':tp,'tn':tn,'fp':fp,'fn':fn}" >> _agg.py
          echo "def infer_run_id(name):" >> _agg.py
          echo "  import re" >> _agg.py
          echo "  m=re.search(r'(?:bundle|out)[-_]([0-9.]+)[-_]([0-9]+)[-_]([A-Za-z0-9]+)',name)" >> _agg.py
          echo "  if m: return f'thr={m.group(1)},hold={m.group(2)},filter={m.group(3)}'" >> _agg.py
          echo "  if 'single' in name: return 'single'" >> _agg.py
          echo "  return name" >> _agg.py
          echo "TMP='tmp_extract'; os.makedirs(TMP,exist_ok=True)" >> _agg.py
          echo "def harvest_dir(d, run_id):" >> _agg.py
          echo "  r={'run_id':run_id}" >> _agg.py
          echo "  t=os.path.join(d,'trades.csv'); s=os.path.join(d,'summary.json'); p=os.path.join(d,'preds_test.csv')" >> _agg.py
          echo "  if os.path.exists(t): r.update(compute_trade_metrics(safe_read_csv(t)))" >> _agg.py
          echo "  if os.path.exists(s):" >> _agg.py
          echo "    try:" >> _agg.py
          echo "      summ=json.load(open(s,'r',encoding='utf-8'))" >> _agg.py
          echo "      for k in ['entries','exits','cum_pnl_close_based','avg_gatep','sharpe','mdd','profit_factor','win_rate']:" >> _agg.py
          echo "        if k in summ and (k!='win_rate' or pd.isna(r.get('win_rate',float('nan')))):" >> _agg.py
          echo "          r[k]=summ[k]" >> _agg.py
          echo "    except: pass" >> _agg.py
          echo "  if os.path.exists(p): r.update(compute_mcc(safe_read_csv(p)))" >> _agg.py
          echo "  rows.append(r)" >> _agg.py
          echo "for zp in bundles:" >> _agg.py
          echo "  nm=os.path.splitext(os.path.basename(zp))[0]" >> _agg.py
          echo "  rid=infer_run_id(nm)" >> _agg.py
          echo "  od=os.path.join(TMP,nm); os.makedirs(od,exist_ok=True)" >> _agg.py
          echo "  try:" >> _agg.py
          echo "    with zipfile.ZipFile(zp,'r') as z: z.extractall(od)" >> _agg.py
          echo "    harvest_dir(od,rid)" >> _agg.py
          echo "  except: pass" >> _agg.py
          echo "for d in std_dirs: harvest_dir(d, infer_run_id(os.path.basename(d)))" >> _agg.py
          echo "df=pd.DataFrame(rows)" >> _agg.py
          echo "cols=['run_id','n_trades','win_rate','cum_pnl','avg_pnl','median_pnl','entries','exits','avg_gatep','profit_factor','sharpe','mdd','mcc','tp','tn','fp','fn']" >> _agg.py
          echo "for c in cols:" >> _agg.py
          echo "  if c not in df.columns: df[c]=np.nan" >> _agg.py
          echo "df=df[cols]" >> _agg.py
          echo "df['cum_pnl']=pd.to_numeric(df['cum_pnl'],errors='coerce')" >> _agg.py
          echo "df['win_rate']=pd.to_numeric(df['win_rate'],errors='coerce')" >> _agg.py
          echo "df['mcc']=pd.to_numeric(df['mcc'],errors='coerce')" >> _agg.py
          echo "df=df.sort_values(by=['cum_pnl','win_rate','mcc'],ascending=[False,False,False],na_position='last')" >> _agg.py
          echo "os.makedirs('final_pack',exist_ok=True)" >> _agg.py
          echo "df.to_csv('final_pack/WFO_aggregated_summary.csv',index=False)" >> _agg.py
          echo "bnd=os.environ.get('BND','WFO_results_all')" >> _agg.py
          echo "FINAL=f'{bnd}.zip'" >> _agg.py
          echo "with zipfile.ZipFile(FINAL,'w',zipfile.ZIP_DEFLATED) as z:" >> _agg.py
          echo "  for base,dirs,files in os.walk('all_artifacts'):" >> _agg.py
          echo "    for fn in files:" >> _agg.py
          echo "      p=os.path.join(base,fn)" >> _agg.py
          echo "      z.write(p, os.path.relpath(p,'all_artifacts'))" >> _agg.py
          echo "  z.write('final_pack/WFO_aggregated_summary.csv','WFO_aggregated_summary.csv')" >> _agg.py
          echo "  z.writestr('README.txt','This package includes all member bundles and WFO_aggregated_summary.csv\\n')" >> _agg.py
          python _agg.py
      - name: Upload FINAL ZIP (pinned)
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: ${{ github.event.inputs.BUNDLE_NAME }}
          path: ${{ github.event.inputs.BUNDLE_NAME }}.zip
          if-no-files-found: error
